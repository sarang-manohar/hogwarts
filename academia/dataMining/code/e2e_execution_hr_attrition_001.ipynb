{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "e2e_execution_hr_attrition_001.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "55a39db2-7389-444a-a894-be9ff9cc343e"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, classification_report, confusion_matrix\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "id": "55a39db2-7389-444a-a894-be9ff9cc343e",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "8018fa01-7bef-454b-abf6-6be090bb3316",
        "outputId": "ae137e66-0c48-4587-fc19-c60ff2af4e97"
      },
      "source": [
        "raw_data = pd.read_csv(r'HR_Employee_Attrition_Data.csv')\n",
        "raw_data.head()"
      ],
      "id": "8018fa01-7bef-454b-abf6-6be090bb3316",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Attrition</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EmployeeCount</th>\n",
              "      <th>EmployeeNumber</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>JobLevel</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>MonthlyRate</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>PercentSalaryHike</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StandardHours</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>1102</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>94</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5993</td>\n",
              "      <td>19479</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>279</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>61</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5130</td>\n",
              "      <td>24907</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>1373</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>92</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2090</td>\n",
              "      <td>2396</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>1392</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>56</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2909</td>\n",
              "      <td>23159</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>591</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3468</td>\n",
              "      <td>16632</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age  Attrition  ...  YearsSinceLastPromotion  YearsWithCurrManager\n",
              "0   41          1  ...                        0                     5\n",
              "1   49          0  ...                        1                     7\n",
              "2   37          1  ...                        0                     0\n",
              "3   33          0  ...                        3                     0\n",
              "4   27          0  ...                        2                     2\n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac5238e0-4e0a-4b6e-b90c-2cbf006e8ed1",
        "outputId": "12c7910b-ee4e-4d8f-c768-3e3d433be5ae"
      },
      "source": [
        "raw_data.info()"
      ],
      "id": "ac5238e0-4e0a-4b6e-b90c-2cbf006e8ed1",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2940 entries, 0 to 2939\n",
            "Data columns (total 27 columns):\n",
            " #   Column                    Non-Null Count  Dtype\n",
            "---  ------                    --------------  -----\n",
            " 0   Age                       2940 non-null   int64\n",
            " 1   Attrition                 2940 non-null   int64\n",
            " 2   DailyRate                 2940 non-null   int64\n",
            " 3   DistanceFromHome          2940 non-null   int64\n",
            " 4   Education                 2940 non-null   int64\n",
            " 5   EmployeeCount             2940 non-null   int64\n",
            " 6   EmployeeNumber            2940 non-null   int64\n",
            " 7   EnvironmentSatisfaction   2940 non-null   int64\n",
            " 8   HourlyRate                2940 non-null   int64\n",
            " 9   JobInvolvement            2940 non-null   int64\n",
            " 10  JobLevel                  2940 non-null   int64\n",
            " 11  JobSatisfaction           2940 non-null   int64\n",
            " 12  MonthlyIncome             2940 non-null   int64\n",
            " 13  MonthlyRate               2940 non-null   int64\n",
            " 14  NumCompaniesWorked        2940 non-null   int64\n",
            " 15  PercentSalaryHike         2940 non-null   int64\n",
            " 16  PerformanceRating         2940 non-null   int64\n",
            " 17  RelationshipSatisfaction  2940 non-null   int64\n",
            " 18  StandardHours             2940 non-null   int64\n",
            " 19  StockOptionLevel          2940 non-null   int64\n",
            " 20  TotalWorkingYears         2940 non-null   int64\n",
            " 21  TrainingTimesLastYear     2940 non-null   int64\n",
            " 22  WorkLifeBalance           2940 non-null   int64\n",
            " 23  YearsAtCompany            2940 non-null   int64\n",
            " 24  YearsInCurrentRole        2940 non-null   int64\n",
            " 25  YearsSinceLastPromotion   2940 non-null   int64\n",
            " 26  YearsWithCurrManager      2940 non-null   int64\n",
            "dtypes: int64(27)\n",
            "memory usage: 620.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d75fa6b-6631-4f7b-a8d9-0cd461adc829"
      },
      "source": [
        "raw_data = raw_data.drop(['EmployeeCount','EmployeeNumber'], axis=1)"
      ],
      "id": "6d75fa6b-6631-4f7b-a8d9-0cd461adc829",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26430b62-0e83-4eb2-8707-d4ce44e452fc",
        "outputId": "143c8c9a-e701-4151-eb8e-f778f4eb6436"
      },
      "source": [
        "raw_data.shape"
      ],
      "id": "26430b62-0e83-4eb2-8707-d4ce44e452fc",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2940, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c596eda-2164-4a25-83ff-fabe7aea668e"
      },
      "source": [
        "X = raw_data.drop(['Attrition'], axis=1)\n",
        "y = raw_data.pop('Attrition')"
      ],
      "id": "5c596eda-2164-4a25-83ff-fabe7aea668e",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29a31ffa-7d93-4fc0-9411-25b02b5300f1"
      },
      "source": [
        "X_train, X_test, train_labels, test_labels = train_test_split(X,y,test_size=0.3, random_state=1)"
      ],
      "id": "29a31ffa-7d93-4fc0-9411-25b02b5300f1",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7230a55-8b55-4b35-b5a5-f643e7bb641f"
      },
      "source": [
        "dt = DecisionTreeClassifier(criterion='gini')"
      ],
      "id": "d7230a55-8b55-4b35-b5a5-f643e7bb641f",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9cf9115-90b9-40d5-bb9f-c327c7527871",
        "outputId": "e5f12c6e-86e1-45bc-c996-5a03cb339828"
      },
      "source": [
        "dt.fit(X_train, train_labels)"
      ],
      "id": "f9cf9115-90b9-40d5-bb9f-c327c7527871",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66454820-5f08-4c9f-9822-b51df824c42b"
      },
      "source": [
        "from sklearn import tree"
      ],
      "id": "66454820-5f08-4c9f-9822-b51df824c42b",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fe93856-26d7-45cd-8780-9e070ffe3eae"
      },
      "source": [
        "train_char_labels = ['No','Yes']\n",
        "\n",
        "tree_graph = open(r'./hr_attrition_dt.dot','w')\n",
        "\n",
        "dot_data = tree.export_graphviz(dt, out_file = tree_graph, feature_names = list(X_train), class_names = train_char_labels)\n",
        "\n",
        "tree_graph.close()"
      ],
      "id": "4fe93856-26d7-45cd-8780-9e070ffe3eae",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "id": "bbc983d2-593f-4935-8509-337a7b85d127",
        "outputId": "f2dfe47b-7e90-47bb-8341-0d8745f80b75"
      },
      "source": [
        "importances = pd.DataFrame(dt.feature_importances_, columns = ['Imp'], index = X_train.columns)\n",
        "importances['features'] = pd.DataFrame(dt.feature_importances_, columns = ['Imp'], index = X_train.columns).index\n",
        "importances.reset_index\n",
        "\n",
        "importances = importances.sort_values(by='Imp', ascending=False)\n",
        "importances.set_index(np.arange(0,importances.shape[0]),inplace = True)\n",
        "\n",
        "importances['cumsum'] = np.cumsum(importances.Imp)\n",
        "x_vals = list(range(len(importances)))\n",
        "\n",
        "sns.barplot(data = importances, x='features', y='Imp')\n",
        "plt.xticks(x_vals, importances['features'], rotation='vertical')\n",
        "plt.ylabel('Importance'); plt.xlabel('Features'); plt.title('Feature Importance');\n",
        "plt.show()\n",
        "\n",
        "plt.plot(x_vals, importances['cumsum'], 'g-')\n",
        "plt.hlines(y = 0.95, xmin=0, xmax=len(importances), color = 'r', linestyles = 'dashed')\n",
        "plt.xticks(x_vals, importances['features'], rotation='vertical')\n",
        "plt.ylabel('Importance'); plt.xlabel('Features'); plt.title('Cumulative Importance');\n",
        "plt.show()"
      ],
      "id": "bbc983d2-593f-4935-8509-337a7b85d127",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65d26ccb-47c4-4bc5-8ce5-69408264b8f2"
      },
      "source": [
        "dt_param_grid = {\n",
        "    'max_depth' : [5,6,7,8,9,10,11,12],\n",
        "    'min_samples_leaf' : [15,20,25,30],\n",
        "    'min_samples_split' : [50,60,75,90,100]\n",
        "}"
      ],
      "id": "65d26ccb-47c4-4bc5-8ce5-69408264b8f2",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "037c2d2f-358f-4211-91fe-007a35cceb53"
      },
      "source": [
        "dt_ht = DecisionTreeClassifier()"
      ],
      "id": "037c2d2f-358f-4211-91fe-007a35cceb53",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f64ba3e1-a662-4770-bd52-330451e41120"
      },
      "source": [
        "dt_gs = GridSearchCV(estimator=dt_ht, param_grid=dt_param_grid, cv = 3)"
      ],
      "id": "f64ba3e1-a662-4770-bd52-330451e41120",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "368d56b0-126e-40d4-9def-e777a0e78390",
        "outputId": "309b9f38-6d91-4159-d691-3e6640a0a159"
      },
      "source": [
        "dt_gs.fit(X_train, train_labels)"
      ],
      "id": "368d56b0-126e-40d4-9def-e777a0e78390",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features=None,\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              presort='deprecated',\n",
              "                                              random_state=None,\n",
              "                                              splitter='best'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'max_depth': [5, 6, 7, 8, 9, 10, 11, 12],\n",
              "                         'min_samples_leaf': [15, 20, 25, 30],\n",
              "                         'min_samples_split': [50, 60, 75, 90, 100]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdb93f86-b9ab-465c-8315-1a2c77e90705",
        "outputId": "2d28ca77-e8cc-4229-b623-73d63d516939"
      },
      "source": [
        "dt_gs.best_params_"
      ],
      "id": "cdb93f86-b9ab-465c-8315-1a2c77e90705",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 6, 'min_samples_leaf': 20, 'min_samples_split': 50}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5650ffb-b04a-45d4-a13e-24144cb5b97c"
      },
      "source": [
        "best_dt = dt_gs.best_estimator_"
      ],
      "id": "d5650ffb-b04a-45d4-a13e-24144cb5b97c",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b145b80-7bdf-4104-86f0-71f65aa2ccbe"
      },
      "source": [
        "ytrain_predict = best_dt.predict(X_train)\n",
        "ytest_predict = best_dt.predict(X_test)"
      ],
      "id": "6b145b80-7bdf-4104-86f0-71f65aa2ccbe",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd8aedd7-3504-4166-b6f9-93cf1306576d",
        "outputId": "97d498a8-4204-4184-b7a9-73505b56eabf"
      },
      "source": [
        "#Train data Confusion Matrix\n",
        "print(confusion_matrix(train_labels, ytrain_predict))\n",
        "#Train Data Accuracy\n",
        "print(best_dt.score(X_train,train_labels) )\n",
        "print(classification_report(train_labels, ytrain_predict))"
      ],
      "id": "bd8aedd7-3504-4166-b6f9-93cf1306576d",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1691   46]\n",
            " [ 226   95]]\n",
            "0.8678328474246841\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.93      1737\n",
            "           1       0.67      0.30      0.41       321\n",
            "\n",
            "    accuracy                           0.87      2058\n",
            "   macro avg       0.78      0.63      0.67      2058\n",
            "weighted avg       0.85      0.87      0.85      2058\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f14f508-c72a-454e-b969-3434abb83acb",
        "outputId": "cf34d582-7186-4bbf-d4a6-f9853c29c1fb"
      },
      "source": [
        "#Test data Confusion Matrix\n",
        "print(confusion_matrix(test_labels, ytest_predict))\n",
        "#Test Data Accuracy\n",
        "print(best_dt.score(X_test,test_labels) )\n",
        "print(classification_report(test_labels, ytest_predict))"
      ],
      "id": "7f14f508-c72a-454e-b969-3434abb83acb",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[701  28]\n",
            " [122  31]]\n",
            "0.8299319727891157\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.96      0.90       729\n",
            "           1       0.53      0.20      0.29       153\n",
            "\n",
            "    accuracy                           0.83       882\n",
            "   macro avg       0.69      0.58      0.60       882\n",
            "weighted avg       0.80      0.83      0.80       882\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "505a8928-422e-427e-bc6e-f6e1856cf132",
        "outputId": "5a5b5025-bb7a-4f6e-9812-be98c70ebad1"
      },
      "source": [
        "probs = best_dt.predict_proba(X_train)[:,1]\n",
        "auc_dev = roc_auc_score(train_labels, probs)\n",
        "print(auc_dev)\n",
        "fpr, tpr, thresholds = roc_curve(train_labels, probs)"
      ],
      "id": "505a8928-422e-427e-bc6e-f6e1856cf132",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8705595819052794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7288a344-4bfc-481e-89e2-0447dd7204e9",
        "outputId": "871ab16b-7fb1-4137-8e62-2047984361db"
      },
      "source": [
        "# calculate the g-mean for each threshold\n",
        "gmeans = np.sqrt(tpr * (1-fpr))\n",
        "# locate the index of the largest g-mean\n",
        "ix = np.argmax(gmeans)\n",
        "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))"
      ],
      "id": "7288a344-4bfc-481e-89e2-0447dd7204e9",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold=0.208333, G-Mean=0.800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "cee31cfa-6d19-481c-9d47-2ae7b5f3a5ed",
        "outputId": "adae22bc-ecd4-4af1-8d18-05d053cb6ec6"
      },
      "source": [
        "# plot the roc curve for the model\n",
        "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
        "plt.plot(fpr, tpr, marker='.', label='Logistic')\n",
        "plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
        "# axis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "id": "cee31cfa-6d19-481c-9d47-2ae7b5f3a5ed",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64e30271-30db-43a3-8dbe-a4df2b273633"
      },
      "source": [
        "rf_param_grid = {\n",
        "    'max_depth' : [5,6],\n",
        "    'min_samples_leaf' : [10,15,20,30],\n",
        "    'min_samples_split' : [40,50,60],\n",
        "    'max_features' : [5,6],\n",
        "    'n_estimators' : [100]\n",
        "}"
      ],
      "id": "64e30271-30db-43a3-8dbe-a4df2b273633",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a0e889a-a0a7-4e08-bb32-a1a8de6dfa83",
        "outputId": "ffcb4e8e-b534-4642-f493-c37166bc9c67"
      },
      "source": [
        "rf_ht = RandomForestClassifier()\n",
        "rf_gs = GridSearchCV(estimator=rf_ht, param_grid=rf_param_grid, cv = 3)\n",
        "rf_gs.fit(X_train, train_labels)"
      ],
      "id": "8a0e889a-a0a7-4e08-bb32-a1a8de6dfa83",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'max_depth': [5, 6], 'max_features': [5, 6],\n",
              "                         'min_samples_leaf': [10, 15, 20, 30],\n",
              "                         'min_samples_split': [40, 50, 60],\n",
              "                         'n_estimators': [100]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf9408af-927c-4062-be04-8db3553327cc",
        "outputId": "5e9f99ba-10d1-4dd9-b5c3-05d6c9a32877"
      },
      "source": [
        "rf_gs.best_params_"
      ],
      "id": "bf9408af-927c-4062-be04-8db3553327cc",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 6,\n",
              " 'max_features': 6,\n",
              " 'min_samples_leaf': 10,\n",
              " 'min_samples_split': 40,\n",
              " 'n_estimators': 100}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "632d2ad6-0c51-46b8-923b-52c9f1a9617f"
      },
      "source": [
        "best_rf = rf_gs.best_estimator_"
      ],
      "id": "632d2ad6-0c51-46b8-923b-52c9f1a9617f",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdb431d5-bf4f-4376-886a-54b45a4e7027"
      },
      "source": [
        "ytrain_predict = best_rf.predict(X_train)\n",
        "ytest_predict = best_rf.predict(X_test)"
      ],
      "id": "bdb431d5-bf4f-4376-886a-54b45a4e7027",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a5c679a-476d-4c80-a37b-ec405315323b",
        "outputId": "b96b6ded-6eb7-450d-b2e3-b9053b2ba548"
      },
      "source": [
        "#Train data Confusion Matrix\n",
        "print(confusion_matrix(train_labels, ytrain_predict))\n",
        "#Train Data Accuracy\n",
        "print(best_rf.score(X_train,train_labels) )\n",
        "print(classification_report(train_labels, ytrain_predict))"
      ],
      "id": "8a5c679a-476d-4c80-a37b-ec405315323b",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1733    4]\n",
            " [ 280   41]]\n",
            "0.8620019436345967\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      1.00      0.92      1737\n",
            "           1       0.91      0.13      0.22       321\n",
            "\n",
            "    accuracy                           0.86      2058\n",
            "   macro avg       0.89      0.56      0.57      2058\n",
            "weighted avg       0.87      0.86      0.82      2058\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a0c4b5f-fdd7-42c6-92ad-052ec03f1b56",
        "outputId": "08bd3992-af89-4afb-a77d-080c238786d1"
      },
      "source": [
        "#Test data Confusion Matrix\n",
        "print(confusion_matrix(test_labels, ytest_predict))\n",
        "#Test Data Accuracy\n",
        "print(best_rf.score(X_test,test_labels) )\n",
        "print(classification_report(test_labels, ytest_predict))"
      ],
      "id": "4a0c4b5f-fdd7-42c6-92ad-052ec03f1b56",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[725   4]\n",
            " [136  17]]\n",
            "0.8412698412698413\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.99      0.91       729\n",
            "           1       0.81      0.11      0.20       153\n",
            "\n",
            "    accuracy                           0.84       882\n",
            "   macro avg       0.83      0.55      0.55       882\n",
            "weighted avg       0.84      0.84      0.79       882\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c792f04c-a1b9-4195-9e6b-ede5185419c4",
        "outputId": "1ff1fbb9-85b7-4204-def2-36c2ff8385c2"
      },
      "source": [
        "probs = best_rf.predict_proba(X_train)[:,1]\n",
        "auc_dev = roc_auc_score(train_labels, probs)\n",
        "print(auc_dev)\n",
        "fpr, tpr, thresholds = roc_curve(train_labels, probs)"
      ],
      "id": "c792f04c-a1b9-4195-9e6b-ede5185419c4",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9173262168274516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "656330b2-c261-4cc9-be41-ba9e32489823",
        "outputId": "974eed6c-8595-4d63-b9f9-cd1871b52147"
      },
      "source": [
        "# calculate the g-mean for each threshold\n",
        "gmeans = np.sqrt(tpr * (1-fpr))\n",
        "# locate the index of the largest g-mean\n",
        "ix = np.argmax(gmeans)\n",
        "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))"
      ],
      "id": "656330b2-c261-4cc9-be41-ba9e32489823",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold=0.180213, G-Mean=0.846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "2a3725c9-cd0a-4536-9570-56420ab8c09d",
        "outputId": "2c082342-42ff-4bf0-cf5c-2085bfe5b190"
      },
      "source": [
        "# plot the roc curve for the model\n",
        "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
        "plt.plot(fpr, tpr, marker='.', label='Logistic')\n",
        "plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
        "# axis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "id": "2a3725c9-cd0a-4536-9570-56420ab8c09d",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4212c0a4-4a90-49c7-8c47-00a7f9d421f4"
      },
      "source": [
        "ss = StandardScaler()"
      ],
      "id": "4212c0a4-4a90-49c7-8c47-00a7f9d421f4",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2744fae-49c1-4757-b908-5453e466d6c5"
      },
      "source": [
        "X_train_s = ss.fit_transform(X_train)"
      ],
      "id": "e2744fae-49c1-4757-b908-5453e466d6c5",
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0193b0d-3fd7-400d-ad3e-ec542b555a7b"
      },
      "source": [
        "X_test_s = ss.transform(X_test)"
      ],
      "id": "d0193b0d-3fd7-400d-ad3e-ec542b555a7b",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b91f62b2-8879-4ba2-bf02-7edc51522c78",
        "outputId": "82206e28-5d6a-4978-a6d3-8f078eacbade"
      },
      "source": [
        "X_train_s"
      ],
      "id": "b91f62b2-8879-4ba2-bf02-7edc51522c78",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.75904517,  1.04289644, -0.27238444, ...,  0.76397248,\n",
              "         0.56720724,  0.82525338],\n",
              "       [ 0.2198339 , -1.64621765, -0.76671175, ..., -0.33955822,\n",
              "         0.25683434,  0.54043509],\n",
              "       [-0.10999708, -0.5899575 ,  1.08701567, ..., -1.16720624,\n",
              "        -0.67428439, -1.16847464],\n",
              "       ...,\n",
              "       [ 0.32977756,  0.23516808, -0.39596627, ...,  0.76397248,\n",
              "         1.49832597,  0.82525338],\n",
              "       [ 0.65960855,  0.57317133,  0.83985201, ...,  2.41926852,\n",
              "        -0.36391148,  1.39488995],\n",
              "       [-1.42932103,  0.06616646,  0.46910653, ..., -1.16720624,\n",
              "        -0.67428439, -1.16847464]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3f29f02-3703-4337-9ad7-fc91b393db40"
      },
      "source": [
        "nn_param_grid = {\n",
        "    'hidden_layer_sizes' : [100],\n",
        "    'activation' : ['relu'],\n",
        "    'solver' : ['sgd','adam'],\n",
        "    'max_iter' : [10000],\n",
        "    'tol' : [0.0001],\n",
        "    'verbose' : [True]\n",
        "}"
      ],
      "id": "f3f29f02-3703-4337-9ad7-fc91b393db40",
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6439aafe-99bb-402c-9c9d-455eed4e76da",
        "outputId": "40db5e85-dfe0-4d82-87ca-790e41b6ef9c"
      },
      "source": [
        "nn_ht = MLPClassifier()\n",
        "nn_gs = GridSearchCV(estimator=nn_ht, param_grid=nn_param_grid, cv = 3)\n",
        "nn_gs.fit(X_train_s, train_labels)"
      ],
      "id": "6439aafe-99bb-402c-9c9d-455eed4e76da",
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Iteration 258, loss = 0.34026146\n",
            "Iteration 259, loss = 0.34012740\n",
            "Iteration 260, loss = 0.33996013\n",
            "Iteration 261, loss = 0.33980254\n",
            "Iteration 262, loss = 0.33965062\n",
            "Iteration 263, loss = 0.33947268\n",
            "Iteration 264, loss = 0.33934228\n",
            "Iteration 265, loss = 0.33917287\n",
            "Iteration 266, loss = 0.33901476\n",
            "Iteration 267, loss = 0.33885731\n",
            "Iteration 268, loss = 0.33872472\n",
            "Iteration 269, loss = 0.33855275\n",
            "Iteration 270, loss = 0.33839331\n",
            "Iteration 271, loss = 0.33825857\n",
            "Iteration 272, loss = 0.33809140\n",
            "Iteration 273, loss = 0.33793891\n",
            "Iteration 274, loss = 0.33779285\n",
            "Iteration 275, loss = 0.33763890\n",
            "Iteration 276, loss = 0.33749089\n",
            "Iteration 277, loss = 0.33734537\n",
            "Iteration 278, loss = 0.33720209\n",
            "Iteration 279, loss = 0.33704224\n",
            "Iteration 280, loss = 0.33688794\n",
            "Iteration 281, loss = 0.33673360\n",
            "Iteration 282, loss = 0.33658836\n",
            "Iteration 283, loss = 0.33645093\n",
            "Iteration 284, loss = 0.33628757\n",
            "Iteration 285, loss = 0.33614658\n",
            "Iteration 286, loss = 0.33599467\n",
            "Iteration 287, loss = 0.33584487\n",
            "Iteration 288, loss = 0.33571279\n",
            "Iteration 289, loss = 0.33553831\n",
            "Iteration 290, loss = 0.33539481\n",
            "Iteration 291, loss = 0.33524734\n",
            "Iteration 292, loss = 0.33510137\n",
            "Iteration 293, loss = 0.33498153\n",
            "Iteration 294, loss = 0.33480724\n",
            "Iteration 295, loss = 0.33467108\n",
            "Iteration 296, loss = 0.33452476\n",
            "Iteration 297, loss = 0.33437290\n",
            "Iteration 298, loss = 0.33423640\n",
            "Iteration 299, loss = 0.33408565\n",
            "Iteration 300, loss = 0.33394571\n",
            "Iteration 301, loss = 0.33379342\n",
            "Iteration 302, loss = 0.33366467\n",
            "Iteration 303, loss = 0.33350704\n",
            "Iteration 304, loss = 0.33335889\n",
            "Iteration 305, loss = 0.33322381\n",
            "Iteration 306, loss = 0.33306771\n",
            "Iteration 307, loss = 0.33292497\n",
            "Iteration 308, loss = 0.33280439\n",
            "Iteration 309, loss = 0.33264795\n",
            "Iteration 310, loss = 0.33250098\n",
            "Iteration 311, loss = 0.33235556\n",
            "Iteration 312, loss = 0.33222233\n",
            "Iteration 313, loss = 0.33208117\n",
            "Iteration 314, loss = 0.33195230\n",
            "Iteration 315, loss = 0.33182091\n",
            "Iteration 316, loss = 0.33166173\n",
            "Iteration 317, loss = 0.33152026\n",
            "Iteration 318, loss = 0.33138359\n",
            "Iteration 319, loss = 0.33123885\n",
            "Iteration 320, loss = 0.33111735\n",
            "Iteration 321, loss = 0.33095663\n",
            "Iteration 322, loss = 0.33082350\n",
            "Iteration 323, loss = 0.33068673\n",
            "Iteration 324, loss = 0.33055212\n",
            "Iteration 325, loss = 0.33042543\n",
            "Iteration 326, loss = 0.33029886\n",
            "Iteration 327, loss = 0.33014658\n",
            "Iteration 328, loss = 0.33000271\n",
            "Iteration 329, loss = 0.32987715\n",
            "Iteration 330, loss = 0.32974395\n",
            "Iteration 331, loss = 0.32962417\n",
            "Iteration 332, loss = 0.32946568\n",
            "Iteration 333, loss = 0.32934719\n",
            "Iteration 334, loss = 0.32921777\n",
            "Iteration 335, loss = 0.32906946\n",
            "Iteration 336, loss = 0.32893334\n",
            "Iteration 337, loss = 0.32879779\n",
            "Iteration 338, loss = 0.32865818\n",
            "Iteration 339, loss = 0.32854436\n",
            "Iteration 340, loss = 0.32838719\n",
            "Iteration 341, loss = 0.32829015\n",
            "Iteration 342, loss = 0.32814434\n",
            "Iteration 343, loss = 0.32801322\n",
            "Iteration 344, loss = 0.32788300\n",
            "Iteration 345, loss = 0.32773415\n",
            "Iteration 346, loss = 0.32761684\n",
            "Iteration 347, loss = 0.32747055\n",
            "Iteration 348, loss = 0.32735954\n",
            "Iteration 349, loss = 0.32723188\n",
            "Iteration 350, loss = 0.32710005\n",
            "Iteration 351, loss = 0.32695469\n",
            "Iteration 352, loss = 0.32682346\n",
            "Iteration 353, loss = 0.32671985\n",
            "Iteration 354, loss = 0.32657395\n",
            "Iteration 355, loss = 0.32644323\n",
            "Iteration 356, loss = 0.32631094\n",
            "Iteration 357, loss = 0.32617732\n",
            "Iteration 358, loss = 0.32605051\n",
            "Iteration 359, loss = 0.32592274\n",
            "Iteration 360, loss = 0.32579245\n",
            "Iteration 361, loss = 0.32566952\n",
            "Iteration 362, loss = 0.32555231\n",
            "Iteration 363, loss = 0.32541011\n",
            "Iteration 364, loss = 0.32527880\n",
            "Iteration 365, loss = 0.32515668\n",
            "Iteration 366, loss = 0.32501609\n",
            "Iteration 367, loss = 0.32488289\n",
            "Iteration 368, loss = 0.32475520\n",
            "Iteration 369, loss = 0.32463013\n",
            "Iteration 370, loss = 0.32451471\n",
            "Iteration 371, loss = 0.32437372\n",
            "Iteration 372, loss = 0.32424088\n",
            "Iteration 373, loss = 0.32411655\n",
            "Iteration 374, loss = 0.32398791\n",
            "Iteration 375, loss = 0.32387060\n",
            "Iteration 376, loss = 0.32372931\n",
            "Iteration 377, loss = 0.32360674\n",
            "Iteration 378, loss = 0.32347719\n",
            "Iteration 379, loss = 0.32336364\n",
            "Iteration 380, loss = 0.32324247\n",
            "Iteration 381, loss = 0.32310969\n",
            "Iteration 382, loss = 0.32296744\n",
            "Iteration 383, loss = 0.32284838\n",
            "Iteration 384, loss = 0.32271730\n",
            "Iteration 385, loss = 0.32262345\n",
            "Iteration 386, loss = 0.32248067\n",
            "Iteration 387, loss = 0.32234343\n",
            "Iteration 388, loss = 0.32222098\n",
            "Iteration 389, loss = 0.32209924\n",
            "Iteration 390, loss = 0.32197867\n",
            "Iteration 391, loss = 0.32185279\n",
            "Iteration 392, loss = 0.32172899\n",
            "Iteration 393, loss = 0.32159034\n",
            "Iteration 394, loss = 0.32148487\n",
            "Iteration 395, loss = 0.32135990\n",
            "Iteration 396, loss = 0.32122192\n",
            "Iteration 397, loss = 0.32110445\n",
            "Iteration 398, loss = 0.32097890\n",
            "Iteration 399, loss = 0.32088052\n",
            "Iteration 400, loss = 0.32075242\n",
            "Iteration 401, loss = 0.32060062\n",
            "Iteration 402, loss = 0.32048702\n",
            "Iteration 403, loss = 0.32036070\n",
            "Iteration 404, loss = 0.32023166\n",
            "Iteration 405, loss = 0.32011183\n",
            "Iteration 406, loss = 0.31998695\n",
            "Iteration 407, loss = 0.31988877\n",
            "Iteration 408, loss = 0.31974598\n",
            "Iteration 409, loss = 0.31961419\n",
            "Iteration 410, loss = 0.31949673\n",
            "Iteration 411, loss = 0.31936471\n",
            "Iteration 412, loss = 0.31925154\n",
            "Iteration 413, loss = 0.31912670\n",
            "Iteration 414, loss = 0.31901444\n",
            "Iteration 415, loss = 0.31887991\n",
            "Iteration 416, loss = 0.31878820\n",
            "Iteration 417, loss = 0.31863419\n",
            "Iteration 418, loss = 0.31853309\n",
            "Iteration 419, loss = 0.31839775\n",
            "Iteration 420, loss = 0.31827338\n",
            "Iteration 421, loss = 0.31816663\n",
            "Iteration 422, loss = 0.31803349\n",
            "Iteration 423, loss = 0.31791448\n",
            "Iteration 424, loss = 0.31778417\n",
            "Iteration 425, loss = 0.31767154\n",
            "Iteration 426, loss = 0.31755068\n",
            "Iteration 427, loss = 0.31744450\n",
            "Iteration 428, loss = 0.31732414\n",
            "Iteration 429, loss = 0.31719209\n",
            "Iteration 430, loss = 0.31706861\n",
            "Iteration 431, loss = 0.31696410\n",
            "Iteration 432, loss = 0.31684484\n",
            "Iteration 433, loss = 0.31672431\n",
            "Iteration 434, loss = 0.31660215\n",
            "Iteration 435, loss = 0.31648803\n",
            "Iteration 436, loss = 0.31637597\n",
            "Iteration 437, loss = 0.31624239\n",
            "Iteration 438, loss = 0.31612857\n",
            "Iteration 439, loss = 0.31602149\n",
            "Iteration 440, loss = 0.31590045\n",
            "Iteration 441, loss = 0.31578144\n",
            "Iteration 442, loss = 0.31565977\n",
            "Iteration 443, loss = 0.31554858\n",
            "Iteration 444, loss = 0.31542118\n",
            "Iteration 445, loss = 0.31532133\n",
            "Iteration 446, loss = 0.31519478\n",
            "Iteration 447, loss = 0.31507378\n",
            "Iteration 448, loss = 0.31494595\n",
            "Iteration 449, loss = 0.31482011\n",
            "Iteration 450, loss = 0.31471196\n",
            "Iteration 451, loss = 0.31459615\n",
            "Iteration 452, loss = 0.31447770\n",
            "Iteration 453, loss = 0.31436395\n",
            "Iteration 454, loss = 0.31423234\n",
            "Iteration 455, loss = 0.31411524\n",
            "Iteration 456, loss = 0.31400078\n",
            "Iteration 457, loss = 0.31387312\n",
            "Iteration 458, loss = 0.31375984\n",
            "Iteration 459, loss = 0.31364670\n",
            "Iteration 460, loss = 0.31351955\n",
            "Iteration 461, loss = 0.31340344\n",
            "Iteration 462, loss = 0.31329922\n",
            "Iteration 463, loss = 0.31316718\n",
            "Iteration 464, loss = 0.31304609\n",
            "Iteration 465, loss = 0.31293300\n",
            "Iteration 466, loss = 0.31281777\n",
            "Iteration 467, loss = 0.31268494\n",
            "Iteration 468, loss = 0.31257042\n",
            "Iteration 469, loss = 0.31245265\n",
            "Iteration 470, loss = 0.31233582\n",
            "Iteration 471, loss = 0.31222603\n",
            "Iteration 472, loss = 0.31211166\n",
            "Iteration 473, loss = 0.31199650\n",
            "Iteration 474, loss = 0.31189045\n",
            "Iteration 475, loss = 0.31175073\n",
            "Iteration 476, loss = 0.31163390\n",
            "Iteration 477, loss = 0.31151214\n",
            "Iteration 478, loss = 0.31139484\n",
            "Iteration 479, loss = 0.31127375\n",
            "Iteration 480, loss = 0.31115392\n",
            "Iteration 481, loss = 0.31103204\n",
            "Iteration 482, loss = 0.31092169\n",
            "Iteration 483, loss = 0.31081380\n",
            "Iteration 484, loss = 0.31068012\n",
            "Iteration 485, loss = 0.31056824\n",
            "Iteration 486, loss = 0.31044763\n",
            "Iteration 487, loss = 0.31033217\n",
            "Iteration 488, loss = 0.31021718\n",
            "Iteration 489, loss = 0.31008616\n",
            "Iteration 490, loss = 0.30996946\n",
            "Iteration 491, loss = 0.30987386\n",
            "Iteration 492, loss = 0.30973052\n",
            "Iteration 493, loss = 0.30962615\n",
            "Iteration 494, loss = 0.30951382\n",
            "Iteration 495, loss = 0.30939146\n",
            "Iteration 496, loss = 0.30928273\n",
            "Iteration 497, loss = 0.30914958\n",
            "Iteration 498, loss = 0.30903937\n",
            "Iteration 499, loss = 0.30892472\n",
            "Iteration 500, loss = 0.30880665\n",
            "Iteration 501, loss = 0.30868539\n",
            "Iteration 502, loss = 0.30859009\n",
            "Iteration 503, loss = 0.30846533\n",
            "Iteration 504, loss = 0.30834386\n",
            "Iteration 505, loss = 0.30823192\n",
            "Iteration 506, loss = 0.30812842\n",
            "Iteration 507, loss = 0.30799774\n",
            "Iteration 508, loss = 0.30788254\n",
            "Iteration 509, loss = 0.30777494\n",
            "Iteration 510, loss = 0.30765302\n",
            "Iteration 511, loss = 0.30754278\n",
            "Iteration 512, loss = 0.30743256\n",
            "Iteration 513, loss = 0.30732729\n",
            "Iteration 514, loss = 0.30719949\n",
            "Iteration 515, loss = 0.30708878\n",
            "Iteration 516, loss = 0.30697454\n",
            "Iteration 517, loss = 0.30685979\n",
            "Iteration 518, loss = 0.30675505\n",
            "Iteration 519, loss = 0.30663971\n",
            "Iteration 520, loss = 0.30651444\n",
            "Iteration 521, loss = 0.30639583\n",
            "Iteration 522, loss = 0.30628011\n",
            "Iteration 523, loss = 0.30616499\n",
            "Iteration 524, loss = 0.30605354\n",
            "Iteration 525, loss = 0.30594567\n",
            "Iteration 526, loss = 0.30583613\n",
            "Iteration 527, loss = 0.30571202\n",
            "Iteration 528, loss = 0.30558597\n",
            "Iteration 529, loss = 0.30549468\n",
            "Iteration 530, loss = 0.30536553\n",
            "Iteration 531, loss = 0.30524376\n",
            "Iteration 532, loss = 0.30514551\n",
            "Iteration 533, loss = 0.30502045\n",
            "Iteration 534, loss = 0.30491571\n",
            "Iteration 535, loss = 0.30479041\n",
            "Iteration 536, loss = 0.30468174\n",
            "Iteration 537, loss = 0.30456591\n",
            "Iteration 538, loss = 0.30445014\n",
            "Iteration 539, loss = 0.30434669\n",
            "Iteration 540, loss = 0.30421565\n",
            "Iteration 541, loss = 0.30412195\n",
            "Iteration 542, loss = 0.30399611\n",
            "Iteration 543, loss = 0.30387631\n",
            "Iteration 544, loss = 0.30378113\n",
            "Iteration 545, loss = 0.30366209\n",
            "Iteration 546, loss = 0.30355630\n",
            "Iteration 547, loss = 0.30344336\n",
            "Iteration 548, loss = 0.30333040\n",
            "Iteration 549, loss = 0.30320684\n",
            "Iteration 550, loss = 0.30308869\n",
            "Iteration 551, loss = 0.30298286\n",
            "Iteration 552, loss = 0.30287422\n",
            "Iteration 553, loss = 0.30274719\n",
            "Iteration 554, loss = 0.30264278\n",
            "Iteration 555, loss = 0.30253312\n",
            "Iteration 556, loss = 0.30244167\n",
            "Iteration 557, loss = 0.30231221\n",
            "Iteration 558, loss = 0.30219652\n",
            "Iteration 559, loss = 0.30207703\n",
            "Iteration 560, loss = 0.30196479\n",
            "Iteration 561, loss = 0.30187054\n",
            "Iteration 562, loss = 0.30174575\n",
            "Iteration 563, loss = 0.30164937\n",
            "Iteration 564, loss = 0.30152098\n",
            "Iteration 565, loss = 0.30142475\n",
            "Iteration 566, loss = 0.30129679\n",
            "Iteration 567, loss = 0.30118145\n",
            "Iteration 568, loss = 0.30107929\n",
            "Iteration 569, loss = 0.30097107\n",
            "Iteration 570, loss = 0.30086469\n",
            "Iteration 571, loss = 0.30076655\n",
            "Iteration 572, loss = 0.30063035\n",
            "Iteration 573, loss = 0.30053281\n",
            "Iteration 574, loss = 0.30041073\n",
            "Iteration 575, loss = 0.30030045\n",
            "Iteration 576, loss = 0.30021189\n",
            "Iteration 577, loss = 0.30008590\n",
            "Iteration 578, loss = 0.29995999\n",
            "Iteration 579, loss = 0.29986029\n",
            "Iteration 580, loss = 0.29973832\n",
            "Iteration 581, loss = 0.29963768\n",
            "Iteration 582, loss = 0.29953376\n",
            "Iteration 583, loss = 0.29943218\n",
            "Iteration 584, loss = 0.29931193\n",
            "Iteration 585, loss = 0.29918528\n",
            "Iteration 586, loss = 0.29908854\n",
            "Iteration 587, loss = 0.29899689\n",
            "Iteration 588, loss = 0.29887431\n",
            "Iteration 589, loss = 0.29875470\n",
            "Iteration 590, loss = 0.29863861\n",
            "Iteration 591, loss = 0.29854318\n",
            "Iteration 592, loss = 0.29842285\n",
            "Iteration 593, loss = 0.29832119\n",
            "Iteration 594, loss = 0.29820338\n",
            "Iteration 595, loss = 0.29809327\n",
            "Iteration 596, loss = 0.29797878\n",
            "Iteration 597, loss = 0.29786429\n",
            "Iteration 598, loss = 0.29775508\n",
            "Iteration 599, loss = 0.29764266\n",
            "Iteration 600, loss = 0.29753861\n",
            "Iteration 601, loss = 0.29742109\n",
            "Iteration 602, loss = 0.29732223\n",
            "Iteration 603, loss = 0.29721008\n",
            "Iteration 604, loss = 0.29708779\n",
            "Iteration 605, loss = 0.29699103\n",
            "Iteration 606, loss = 0.29686840\n",
            "Iteration 607, loss = 0.29677578\n",
            "Iteration 608, loss = 0.29665847\n",
            "Iteration 609, loss = 0.29654043\n",
            "Iteration 610, loss = 0.29643380\n",
            "Iteration 611, loss = 0.29632000\n",
            "Iteration 612, loss = 0.29620891\n",
            "Iteration 613, loss = 0.29612134\n",
            "Iteration 614, loss = 0.29599692\n",
            "Iteration 615, loss = 0.29587637\n",
            "Iteration 616, loss = 0.29577923\n",
            "Iteration 617, loss = 0.29567613\n",
            "Iteration 618, loss = 0.29555945\n",
            "Iteration 619, loss = 0.29544462\n",
            "Iteration 620, loss = 0.29532785\n",
            "Iteration 621, loss = 0.29522250\n",
            "Iteration 622, loss = 0.29511541\n",
            "Iteration 623, loss = 0.29500958\n",
            "Iteration 624, loss = 0.29489357\n",
            "Iteration 625, loss = 0.29479002\n",
            "Iteration 626, loss = 0.29467134\n",
            "Iteration 627, loss = 0.29455674\n",
            "Iteration 628, loss = 0.29446125\n",
            "Iteration 629, loss = 0.29435753\n",
            "Iteration 630, loss = 0.29423862\n",
            "Iteration 631, loss = 0.29414147\n",
            "Iteration 632, loss = 0.29402838\n",
            "Iteration 633, loss = 0.29390982\n",
            "Iteration 634, loss = 0.29380427\n",
            "Iteration 635, loss = 0.29369258\n",
            "Iteration 636, loss = 0.29357829\n",
            "Iteration 637, loss = 0.29348983\n",
            "Iteration 638, loss = 0.29337467\n",
            "Iteration 639, loss = 0.29326281\n",
            "Iteration 640, loss = 0.29314187\n",
            "Iteration 641, loss = 0.29304519\n",
            "Iteration 642, loss = 0.29292683\n",
            "Iteration 643, loss = 0.29281987\n",
            "Iteration 644, loss = 0.29271820\n",
            "Iteration 645, loss = 0.29259293\n",
            "Iteration 646, loss = 0.29250231\n",
            "Iteration 647, loss = 0.29238341\n",
            "Iteration 648, loss = 0.29225818\n",
            "Iteration 649, loss = 0.29216623\n",
            "Iteration 650, loss = 0.29205494\n",
            "Iteration 651, loss = 0.29195667\n",
            "Iteration 652, loss = 0.29182733\n",
            "Iteration 653, loss = 0.29172268\n",
            "Iteration 654, loss = 0.29160397\n",
            "Iteration 655, loss = 0.29149775\n",
            "Iteration 656, loss = 0.29139332\n",
            "Iteration 657, loss = 0.29127920\n",
            "Iteration 658, loss = 0.29117797\n",
            "Iteration 659, loss = 0.29105787\n",
            "Iteration 660, loss = 0.29096637\n",
            "Iteration 661, loss = 0.29083936\n",
            "Iteration 662, loss = 0.29075193\n",
            "Iteration 663, loss = 0.29062491\n",
            "Iteration 664, loss = 0.29052991\n",
            "Iteration 665, loss = 0.29040584\n",
            "Iteration 666, loss = 0.29029543\n",
            "Iteration 667, loss = 0.29018075\n",
            "Iteration 668, loss = 0.29009799\n",
            "Iteration 669, loss = 0.28997806\n",
            "Iteration 670, loss = 0.28985684\n",
            "Iteration 671, loss = 0.28974284\n",
            "Iteration 672, loss = 0.28964336\n",
            "Iteration 673, loss = 0.28952552\n",
            "Iteration 674, loss = 0.28941520\n",
            "Iteration 675, loss = 0.28930703\n",
            "Iteration 676, loss = 0.28919603\n",
            "Iteration 677, loss = 0.28909463\n",
            "Iteration 678, loss = 0.28898018\n",
            "Iteration 679, loss = 0.28886297\n",
            "Iteration 680, loss = 0.28876138\n",
            "Iteration 681, loss = 0.28865694\n",
            "Iteration 682, loss = 0.28855460\n",
            "Iteration 683, loss = 0.28843820\n",
            "Iteration 684, loss = 0.28832033\n",
            "Iteration 685, loss = 0.28821416\n",
            "Iteration 686, loss = 0.28812559\n",
            "Iteration 687, loss = 0.28798866\n",
            "Iteration 688, loss = 0.28788845\n",
            "Iteration 689, loss = 0.28778002\n",
            "Iteration 690, loss = 0.28767785\n",
            "Iteration 691, loss = 0.28757380\n",
            "Iteration 692, loss = 0.28746306\n",
            "Iteration 693, loss = 0.28735166\n",
            "Iteration 694, loss = 0.28722943\n",
            "Iteration 695, loss = 0.28712091\n",
            "Iteration 696, loss = 0.28701555\n",
            "Iteration 697, loss = 0.28693441\n",
            "Iteration 698, loss = 0.28680274\n",
            "Iteration 699, loss = 0.28670195\n",
            "Iteration 700, loss = 0.28657763\n",
            "Iteration 701, loss = 0.28647802\n",
            "Iteration 702, loss = 0.28637280\n",
            "Iteration 703, loss = 0.28625648\n",
            "Iteration 704, loss = 0.28615768\n",
            "Iteration 705, loss = 0.28604015\n",
            "Iteration 706, loss = 0.28594026\n",
            "Iteration 707, loss = 0.28581890\n",
            "Iteration 708, loss = 0.28571674\n",
            "Iteration 709, loss = 0.28561489\n",
            "Iteration 710, loss = 0.28549513\n",
            "Iteration 711, loss = 0.28539167\n",
            "Iteration 712, loss = 0.28527607\n",
            "Iteration 713, loss = 0.28517209\n",
            "Iteration 714, loss = 0.28506250\n",
            "Iteration 715, loss = 0.28495376\n",
            "Iteration 716, loss = 0.28485288\n",
            "Iteration 717, loss = 0.28475275\n",
            "Iteration 718, loss = 0.28464095\n",
            "Iteration 719, loss = 0.28451101\n",
            "Iteration 720, loss = 0.28442126\n",
            "Iteration 721, loss = 0.28430275\n",
            "Iteration 722, loss = 0.28419840\n",
            "Iteration 723, loss = 0.28409888\n",
            "Iteration 724, loss = 0.28399072\n",
            "Iteration 725, loss = 0.28389232\n",
            "Iteration 726, loss = 0.28376303\n",
            "Iteration 727, loss = 0.28366327\n",
            "Iteration 728, loss = 0.28354724\n",
            "Iteration 729, loss = 0.28344550\n",
            "Iteration 730, loss = 0.28334379\n",
            "Iteration 731, loss = 0.28321667\n",
            "Iteration 732, loss = 0.28311872\n",
            "Iteration 733, loss = 0.28300680\n",
            "Iteration 734, loss = 0.28289259\n",
            "Iteration 735, loss = 0.28277152\n",
            "Iteration 736, loss = 0.28265837\n",
            "Iteration 737, loss = 0.28255303\n",
            "Iteration 738, loss = 0.28245117\n",
            "Iteration 739, loss = 0.28233980\n",
            "Iteration 740, loss = 0.28223156\n",
            "Iteration 741, loss = 0.28211441\n",
            "Iteration 742, loss = 0.28200661\n",
            "Iteration 743, loss = 0.28187886\n",
            "Iteration 744, loss = 0.28177355\n",
            "Iteration 745, loss = 0.28166179\n",
            "Iteration 746, loss = 0.28154705\n",
            "Iteration 747, loss = 0.28145394\n",
            "Iteration 748, loss = 0.28131767\n",
            "Iteration 749, loss = 0.28120002\n",
            "Iteration 750, loss = 0.28110144\n",
            "Iteration 751, loss = 0.28098897\n",
            "Iteration 752, loss = 0.28086989\n",
            "Iteration 753, loss = 0.28075941\n",
            "Iteration 754, loss = 0.28065310\n",
            "Iteration 755, loss = 0.28053239\n",
            "Iteration 756, loss = 0.28042742\n",
            "Iteration 757, loss = 0.28031731\n",
            "Iteration 758, loss = 0.28020158\n",
            "Iteration 759, loss = 0.28009049\n",
            "Iteration 760, loss = 0.27996970\n",
            "Iteration 761, loss = 0.27985490\n",
            "Iteration 762, loss = 0.27974474\n",
            "Iteration 763, loss = 0.27964037\n",
            "Iteration 764, loss = 0.27951799\n",
            "Iteration 765, loss = 0.27942317\n",
            "Iteration 766, loss = 0.27929605\n",
            "Iteration 767, loss = 0.27918522\n",
            "Iteration 768, loss = 0.27907226\n",
            "Iteration 769, loss = 0.27894989\n",
            "Iteration 770, loss = 0.27883237\n",
            "Iteration 771, loss = 0.27871233\n",
            "Iteration 772, loss = 0.27860630\n",
            "Iteration 773, loss = 0.27850249\n",
            "Iteration 774, loss = 0.27837111\n",
            "Iteration 775, loss = 0.27826150\n",
            "Iteration 776, loss = 0.27814325\n",
            "Iteration 777, loss = 0.27805168\n",
            "Iteration 778, loss = 0.27790893\n",
            "Iteration 779, loss = 0.27779904\n",
            "Iteration 780, loss = 0.27770020\n",
            "Iteration 781, loss = 0.27758442\n",
            "Iteration 782, loss = 0.27745258\n",
            "Iteration 783, loss = 0.27734199\n",
            "Iteration 784, loss = 0.27723446\n",
            "Iteration 785, loss = 0.27711113\n",
            "Iteration 786, loss = 0.27700407\n",
            "Iteration 787, loss = 0.27688152\n",
            "Iteration 788, loss = 0.27677923\n",
            "Iteration 789, loss = 0.27666883\n",
            "Iteration 790, loss = 0.27654169\n",
            "Iteration 791, loss = 0.27642125\n",
            "Iteration 792, loss = 0.27632515\n",
            "Iteration 793, loss = 0.27619740\n",
            "Iteration 794, loss = 0.27609284\n",
            "Iteration 795, loss = 0.27596722\n",
            "Iteration 796, loss = 0.27586791\n",
            "Iteration 797, loss = 0.27575701\n",
            "Iteration 798, loss = 0.27563594\n",
            "Iteration 799, loss = 0.27551694\n",
            "Iteration 800, loss = 0.27541643\n",
            "Iteration 801, loss = 0.27530177\n",
            "Iteration 802, loss = 0.27517584\n",
            "Iteration 803, loss = 0.27507392\n",
            "Iteration 804, loss = 0.27495259\n",
            "Iteration 805, loss = 0.27483938\n",
            "Iteration 806, loss = 0.27473432\n",
            "Iteration 807, loss = 0.27461975\n",
            "Iteration 808, loss = 0.27449633\n",
            "Iteration 809, loss = 0.27440073\n",
            "Iteration 810, loss = 0.27427849\n",
            "Iteration 811, loss = 0.27416311\n",
            "Iteration 812, loss = 0.27405902\n",
            "Iteration 813, loss = 0.27395614\n",
            "Iteration 814, loss = 0.27382070\n",
            "Iteration 815, loss = 0.27373276\n",
            "Iteration 816, loss = 0.27358651\n",
            "Iteration 817, loss = 0.27347486\n",
            "Iteration 818, loss = 0.27336618\n",
            "Iteration 819, loss = 0.27326748\n",
            "Iteration 820, loss = 0.27313415\n",
            "Iteration 821, loss = 0.27302117\n",
            "Iteration 822, loss = 0.27291648\n",
            "Iteration 823, loss = 0.27280489\n",
            "Iteration 824, loss = 0.27268635\n",
            "Iteration 825, loss = 0.27258550\n",
            "Iteration 826, loss = 0.27247096\n",
            "Iteration 827, loss = 0.27237248\n",
            "Iteration 828, loss = 0.27224524\n",
            "Iteration 829, loss = 0.27214832\n",
            "Iteration 830, loss = 0.27202829\n",
            "Iteration 831, loss = 0.27190107\n",
            "Iteration 832, loss = 0.27179624\n",
            "Iteration 833, loss = 0.27167817\n",
            "Iteration 834, loss = 0.27156855\n",
            "Iteration 835, loss = 0.27146053\n",
            "Iteration 836, loss = 0.27133676\n",
            "Iteration 837, loss = 0.27123454\n",
            "Iteration 838, loss = 0.27112458\n",
            "Iteration 839, loss = 0.27099919\n",
            "Iteration 840, loss = 0.27089986\n",
            "Iteration 841, loss = 0.27078166\n",
            "Iteration 842, loss = 0.27066642\n",
            "Iteration 843, loss = 0.27056300\n",
            "Iteration 844, loss = 0.27045067\n",
            "Iteration 845, loss = 0.27034399\n",
            "Iteration 846, loss = 0.27022983\n",
            "Iteration 847, loss = 0.27012654\n",
            "Iteration 848, loss = 0.27002148\n",
            "Iteration 849, loss = 0.26988835\n",
            "Iteration 850, loss = 0.26977734\n",
            "Iteration 851, loss = 0.26968879\n",
            "Iteration 852, loss = 0.26957294\n",
            "Iteration 853, loss = 0.26943994\n",
            "Iteration 854, loss = 0.26934806\n",
            "Iteration 855, loss = 0.26921576\n",
            "Iteration 856, loss = 0.26910463\n",
            "Iteration 857, loss = 0.26901905\n",
            "Iteration 858, loss = 0.26887293\n",
            "Iteration 859, loss = 0.26877038\n",
            "Iteration 860, loss = 0.26865298\n",
            "Iteration 861, loss = 0.26854628\n",
            "Iteration 862, loss = 0.26843725\n",
            "Iteration 863, loss = 0.26829638\n",
            "Iteration 864, loss = 0.26818968\n",
            "Iteration 865, loss = 0.26807405\n",
            "Iteration 866, loss = 0.26795819\n",
            "Iteration 867, loss = 0.26786147\n",
            "Iteration 868, loss = 0.26773302\n",
            "Iteration 869, loss = 0.26760606\n",
            "Iteration 870, loss = 0.26750305\n",
            "Iteration 871, loss = 0.26738074\n",
            "Iteration 872, loss = 0.26728686\n",
            "Iteration 873, loss = 0.26717598\n",
            "Iteration 874, loss = 0.26705244\n",
            "Iteration 875, loss = 0.26699097\n",
            "Iteration 876, loss = 0.26683044\n",
            "Iteration 877, loss = 0.26670278\n",
            "Iteration 878, loss = 0.26662433\n",
            "Iteration 879, loss = 0.26648182\n",
            "Iteration 880, loss = 0.26638232\n",
            "Iteration 881, loss = 0.26625739\n",
            "Iteration 882, loss = 0.26616571\n",
            "Iteration 883, loss = 0.26601780\n",
            "Iteration 884, loss = 0.26591877\n",
            "Iteration 885, loss = 0.26580293\n",
            "Iteration 886, loss = 0.26569691\n",
            "Iteration 887, loss = 0.26557564\n",
            "Iteration 888, loss = 0.26546629\n",
            "Iteration 889, loss = 0.26534716\n",
            "Iteration 890, loss = 0.26522781\n",
            "Iteration 891, loss = 0.26512213\n",
            "Iteration 892, loss = 0.26501224\n",
            "Iteration 893, loss = 0.26490761\n",
            "Iteration 894, loss = 0.26478583\n",
            "Iteration 895, loss = 0.26468154\n",
            "Iteration 896, loss = 0.26454777\n",
            "Iteration 897, loss = 0.26444853\n",
            "Iteration 898, loss = 0.26433326\n",
            "Iteration 899, loss = 0.26421625\n",
            "Iteration 900, loss = 0.26409980\n",
            "Iteration 901, loss = 0.26398988\n",
            "Iteration 902, loss = 0.26387764\n",
            "Iteration 903, loss = 0.26376149\n",
            "Iteration 904, loss = 0.26367242\n",
            "Iteration 905, loss = 0.26353464\n",
            "Iteration 906, loss = 0.26343034\n",
            "Iteration 907, loss = 0.26331648\n",
            "Iteration 908, loss = 0.26321445\n",
            "Iteration 909, loss = 0.26309238\n",
            "Iteration 910, loss = 0.26299396\n",
            "Iteration 911, loss = 0.26285884\n",
            "Iteration 912, loss = 0.26275537\n",
            "Iteration 913, loss = 0.26265057\n",
            "Iteration 914, loss = 0.26252711\n",
            "Iteration 915, loss = 0.26241015\n",
            "Iteration 916, loss = 0.26230330\n",
            "Iteration 917, loss = 0.26219380\n",
            "Iteration 918, loss = 0.26208261\n",
            "Iteration 919, loss = 0.26197589\n",
            "Iteration 920, loss = 0.26188632\n",
            "Iteration 921, loss = 0.26176328\n",
            "Iteration 922, loss = 0.26165150\n",
            "Iteration 923, loss = 0.26157970\n",
            "Iteration 924, loss = 0.26143087\n",
            "Iteration 925, loss = 0.26132708\n",
            "Iteration 926, loss = 0.26121203\n",
            "Iteration 927, loss = 0.26110366\n",
            "Iteration 928, loss = 0.26099535\n",
            "Iteration 929, loss = 0.26087822\n",
            "Iteration 930, loss = 0.26079685\n",
            "Iteration 931, loss = 0.26066185\n",
            "Iteration 932, loss = 0.26055979\n",
            "Iteration 933, loss = 0.26043795\n",
            "Iteration 934, loss = 0.26034438\n",
            "Iteration 935, loss = 0.26023408\n",
            "Iteration 936, loss = 0.26013451\n",
            "Iteration 937, loss = 0.26001564\n",
            "Iteration 938, loss = 0.25991454\n",
            "Iteration 939, loss = 0.25979657\n",
            "Iteration 940, loss = 0.25968590\n",
            "Iteration 941, loss = 0.25959299\n",
            "Iteration 942, loss = 0.25946917\n",
            "Iteration 943, loss = 0.25937781\n",
            "Iteration 944, loss = 0.25924943\n",
            "Iteration 945, loss = 0.25915618\n",
            "Iteration 946, loss = 0.25903815\n",
            "Iteration 947, loss = 0.25892553\n",
            "Iteration 948, loss = 0.25882503\n",
            "Iteration 949, loss = 0.25871300\n",
            "Iteration 950, loss = 0.25862510\n",
            "Iteration 951, loss = 0.25849491\n",
            "Iteration 952, loss = 0.25840454\n",
            "Iteration 953, loss = 0.25827249\n",
            "Iteration 954, loss = 0.25817372\n",
            "Iteration 955, loss = 0.25807695\n",
            "Iteration 956, loss = 0.25798322\n",
            "Iteration 957, loss = 0.25786370\n",
            "Iteration 958, loss = 0.25774458\n",
            "Iteration 959, loss = 0.25763512\n",
            "Iteration 960, loss = 0.25753964\n",
            "Iteration 961, loss = 0.25744010\n",
            "Iteration 962, loss = 0.25731488\n",
            "Iteration 963, loss = 0.25721974\n",
            "Iteration 964, loss = 0.25711707\n",
            "Iteration 965, loss = 0.25699914\n",
            "Iteration 966, loss = 0.25688947\n",
            "Iteration 967, loss = 0.25678603\n",
            "Iteration 968, loss = 0.25668977\n",
            "Iteration 969, loss = 0.25658804\n",
            "Iteration 970, loss = 0.25646353\n",
            "Iteration 971, loss = 0.25639517\n",
            "Iteration 972, loss = 0.25628688\n",
            "Iteration 973, loss = 0.25615357\n",
            "Iteration 974, loss = 0.25604481\n",
            "Iteration 975, loss = 0.25594926\n",
            "Iteration 976, loss = 0.25584071\n",
            "Iteration 977, loss = 0.25572738\n",
            "Iteration 978, loss = 0.25562323\n",
            "Iteration 979, loss = 0.25552893\n",
            "Iteration 980, loss = 0.25542380\n",
            "Iteration 981, loss = 0.25531862\n",
            "Iteration 982, loss = 0.25520943\n",
            "Iteration 983, loss = 0.25510745\n",
            "Iteration 984, loss = 0.25501510\n",
            "Iteration 985, loss = 0.25492332\n",
            "Iteration 986, loss = 0.25480080\n",
            "Iteration 987, loss = 0.25470517\n",
            "Iteration 988, loss = 0.25458756\n",
            "Iteration 989, loss = 0.25448774\n",
            "Iteration 990, loss = 0.25438258\n",
            "Iteration 991, loss = 0.25427982\n",
            "Iteration 992, loss = 0.25417960\n",
            "Iteration 993, loss = 0.25407255\n",
            "Iteration 994, loss = 0.25396371\n",
            "Iteration 995, loss = 0.25386973\n",
            "Iteration 996, loss = 0.25376789\n",
            "Iteration 997, loss = 0.25366645\n",
            "Iteration 998, loss = 0.25355787\n",
            "Iteration 999, loss = 0.25345229\n",
            "Iteration 1000, loss = 0.25334403\n",
            "Iteration 1001, loss = 0.25324124\n",
            "Iteration 1002, loss = 0.25314588\n",
            "Iteration 1003, loss = 0.25304641\n",
            "Iteration 1004, loss = 0.25294787\n",
            "Iteration 1005, loss = 0.25285956\n",
            "Iteration 1006, loss = 0.25273959\n",
            "Iteration 1007, loss = 0.25262554\n",
            "Iteration 1008, loss = 0.25252323\n",
            "Iteration 1009, loss = 0.25241602\n",
            "Iteration 1010, loss = 0.25232743\n",
            "Iteration 1011, loss = 0.25222120\n",
            "Iteration 1012, loss = 0.25211691\n",
            "Iteration 1013, loss = 0.25201263\n",
            "Iteration 1014, loss = 0.25191610\n",
            "Iteration 1015, loss = 0.25181772\n",
            "Iteration 1016, loss = 0.25169074\n",
            "Iteration 1017, loss = 0.25160507\n",
            "Iteration 1018, loss = 0.25148261\n",
            "Iteration 1019, loss = 0.25138283\n",
            "Iteration 1020, loss = 0.25129037\n",
            "Iteration 1021, loss = 0.25119082\n",
            "Iteration 1022, loss = 0.25108999\n",
            "Iteration 1023, loss = 0.25099880\n",
            "Iteration 1024, loss = 0.25088064\n",
            "Iteration 1025, loss = 0.25078820\n",
            "Iteration 1026, loss = 0.25066855\n",
            "Iteration 1027, loss = 0.25057992\n",
            "Iteration 1028, loss = 0.25046219\n",
            "Iteration 1029, loss = 0.25036427\n",
            "Iteration 1030, loss = 0.25025967\n",
            "Iteration 1031, loss = 0.25017321\n",
            "Iteration 1032, loss = 0.25005721\n",
            "Iteration 1033, loss = 0.24996515\n",
            "Iteration 1034, loss = 0.24987055\n",
            "Iteration 1035, loss = 0.24976113\n",
            "Iteration 1036, loss = 0.24965556\n",
            "Iteration 1037, loss = 0.24955247\n",
            "Iteration 1038, loss = 0.24945363\n",
            "Iteration 1039, loss = 0.24934665\n",
            "Iteration 1040, loss = 0.24922694\n",
            "Iteration 1041, loss = 0.24915073\n",
            "Iteration 1042, loss = 0.24905354\n",
            "Iteration 1043, loss = 0.24892992\n",
            "Iteration 1044, loss = 0.24884387\n",
            "Iteration 1045, loss = 0.24873600\n",
            "Iteration 1046, loss = 0.24864815\n",
            "Iteration 1047, loss = 0.24853501\n",
            "Iteration 1048, loss = 0.24845501\n",
            "Iteration 1049, loss = 0.24834675\n",
            "Iteration 1050, loss = 0.24823008\n",
            "Iteration 1051, loss = 0.24811888\n",
            "Iteration 1052, loss = 0.24806016\n",
            "Iteration 1053, loss = 0.24793057\n",
            "Iteration 1054, loss = 0.24783625\n",
            "Iteration 1055, loss = 0.24774551\n",
            "Iteration 1056, loss = 0.24767996\n",
            "Iteration 1057, loss = 0.24752977\n",
            "Iteration 1058, loss = 0.24743249\n",
            "Iteration 1059, loss = 0.24735028\n",
            "Iteration 1060, loss = 0.24724504\n",
            "Iteration 1061, loss = 0.24713207\n",
            "Iteration 1062, loss = 0.24703383\n",
            "Iteration 1063, loss = 0.24693409\n",
            "Iteration 1064, loss = 0.24685185\n",
            "Iteration 1065, loss = 0.24674446\n",
            "Iteration 1066, loss = 0.24663258\n",
            "Iteration 1067, loss = 0.24653676\n",
            "Iteration 1068, loss = 0.24644197\n",
            "Iteration 1069, loss = 0.24634902\n",
            "Iteration 1070, loss = 0.24624554\n",
            "Iteration 1071, loss = 0.24613452\n",
            "Iteration 1072, loss = 0.24604034\n",
            "Iteration 1073, loss = 0.24595892\n",
            "Iteration 1074, loss = 0.24584988\n",
            "Iteration 1075, loss = 0.24574669\n",
            "Iteration 1076, loss = 0.24564359\n",
            "Iteration 1077, loss = 0.24555231\n",
            "Iteration 1078, loss = 0.24544268\n",
            "Iteration 1079, loss = 0.24536875\n",
            "Iteration 1080, loss = 0.24525095\n",
            "Iteration 1081, loss = 0.24515513\n",
            "Iteration 1082, loss = 0.24508427\n",
            "Iteration 1083, loss = 0.24495749\n",
            "Iteration 1084, loss = 0.24485052\n",
            "Iteration 1085, loss = 0.24474435\n",
            "Iteration 1086, loss = 0.24466266\n",
            "Iteration 1087, loss = 0.24455732\n",
            "Iteration 1088, loss = 0.24447537\n",
            "Iteration 1089, loss = 0.24435415\n",
            "Iteration 1090, loss = 0.24426946\n",
            "Iteration 1091, loss = 0.24417322\n",
            "Iteration 1092, loss = 0.24406162\n",
            "Iteration 1093, loss = 0.24397666\n",
            "Iteration 1094, loss = 0.24387486\n",
            "Iteration 1095, loss = 0.24376961\n",
            "Iteration 1096, loss = 0.24367713\n",
            "Iteration 1097, loss = 0.24357416\n",
            "Iteration 1098, loss = 0.24347869\n",
            "Iteration 1099, loss = 0.24337806\n",
            "Iteration 1100, loss = 0.24328621\n",
            "Iteration 1101, loss = 0.24318906\n",
            "Iteration 1102, loss = 0.24309291\n",
            "Iteration 1103, loss = 0.24298028\n",
            "Iteration 1104, loss = 0.24287331\n",
            "Iteration 1105, loss = 0.24280058\n",
            "Iteration 1106, loss = 0.24269461\n",
            "Iteration 1107, loss = 0.24261321\n",
            "Iteration 1108, loss = 0.24250910\n",
            "Iteration 1109, loss = 0.24239959\n",
            "Iteration 1110, loss = 0.24230189\n",
            "Iteration 1111, loss = 0.24221065\n",
            "Iteration 1112, loss = 0.24212485\n",
            "Iteration 1113, loss = 0.24203284\n",
            "Iteration 1114, loss = 0.24192333\n",
            "Iteration 1115, loss = 0.24182554\n",
            "Iteration 1116, loss = 0.24172883\n",
            "Iteration 1117, loss = 0.24161719\n",
            "Iteration 1118, loss = 0.24154316\n",
            "Iteration 1119, loss = 0.24144782\n",
            "Iteration 1120, loss = 0.24132455\n",
            "Iteration 1121, loss = 0.24125575\n",
            "Iteration 1122, loss = 0.24114817\n",
            "Iteration 1123, loss = 0.24104167\n",
            "Iteration 1124, loss = 0.24094925\n",
            "Iteration 1125, loss = 0.24085452\n",
            "Iteration 1126, loss = 0.24075819\n",
            "Iteration 1127, loss = 0.24066217\n",
            "Iteration 1128, loss = 0.24058097\n",
            "Iteration 1129, loss = 0.24047134\n",
            "Iteration 1130, loss = 0.24036984\n",
            "Iteration 1131, loss = 0.24028459\n",
            "Iteration 1132, loss = 0.24017896\n",
            "Iteration 1133, loss = 0.24009693\n",
            "Iteration 1134, loss = 0.23999248\n",
            "Iteration 1135, loss = 0.23991561\n",
            "Iteration 1136, loss = 0.23981849\n",
            "Iteration 1137, loss = 0.23971642\n",
            "Iteration 1138, loss = 0.23962332\n",
            "Iteration 1139, loss = 0.23951681\n",
            "Iteration 1140, loss = 0.23941727\n",
            "Iteration 1141, loss = 0.23937430\n",
            "Iteration 1142, loss = 0.23923660\n",
            "Iteration 1143, loss = 0.23912975\n",
            "Iteration 1144, loss = 0.23904048\n",
            "Iteration 1145, loss = 0.23895095\n",
            "Iteration 1146, loss = 0.23886530\n",
            "Iteration 1147, loss = 0.23875120\n",
            "Iteration 1148, loss = 0.23867139\n",
            "Iteration 1149, loss = 0.23856774\n",
            "Iteration 1150, loss = 0.23847615\n",
            "Iteration 1151, loss = 0.23838241\n",
            "Iteration 1152, loss = 0.23828444\n",
            "Iteration 1153, loss = 0.23820864\n",
            "Iteration 1154, loss = 0.23809489\n",
            "Iteration 1155, loss = 0.23802174\n",
            "Iteration 1156, loss = 0.23792400\n",
            "Iteration 1157, loss = 0.23781980\n",
            "Iteration 1158, loss = 0.23775174\n",
            "Iteration 1159, loss = 0.23763809\n",
            "Iteration 1160, loss = 0.23753578\n",
            "Iteration 1161, loss = 0.23746064\n",
            "Iteration 1162, loss = 0.23736011\n",
            "Iteration 1163, loss = 0.23726265\n",
            "Iteration 1164, loss = 0.23718367\n",
            "Iteration 1165, loss = 0.23708124\n",
            "Iteration 1166, loss = 0.23698966\n",
            "Iteration 1167, loss = 0.23688556\n",
            "Iteration 1168, loss = 0.23680342\n",
            "Iteration 1169, loss = 0.23671519\n",
            "Iteration 1170, loss = 0.23660942\n",
            "Iteration 1171, loss = 0.23651529\n",
            "Iteration 1172, loss = 0.23643302\n",
            "Iteration 1173, loss = 0.23635340\n",
            "Iteration 1174, loss = 0.23625157\n",
            "Iteration 1175, loss = 0.23613963\n",
            "Iteration 1176, loss = 0.23607269\n",
            "Iteration 1177, loss = 0.23598397\n",
            "Iteration 1178, loss = 0.23586667\n",
            "Iteration 1179, loss = 0.23578251\n",
            "Iteration 1180, loss = 0.23569275\n",
            "Iteration 1181, loss = 0.23560739\n",
            "Iteration 1182, loss = 0.23551188\n",
            "Iteration 1183, loss = 0.23541689\n",
            "Iteration 1184, loss = 0.23532401\n",
            "Iteration 1185, loss = 0.23522303\n",
            "Iteration 1186, loss = 0.23513842\n",
            "Iteration 1187, loss = 0.23504962\n",
            "Iteration 1188, loss = 0.23495260\n",
            "Iteration 1189, loss = 0.23487088\n",
            "Iteration 1190, loss = 0.23477739\n",
            "Iteration 1191, loss = 0.23470109\n",
            "Iteration 1192, loss = 0.23458604\n",
            "Iteration 1193, loss = 0.23451174\n",
            "Iteration 1194, loss = 0.23439191\n",
            "Iteration 1195, loss = 0.23430884\n",
            "Iteration 1196, loss = 0.23421813\n",
            "Iteration 1197, loss = 0.23412467\n",
            "Iteration 1198, loss = 0.23403422\n",
            "Iteration 1199, loss = 0.23394044\n",
            "Iteration 1200, loss = 0.23387983\n",
            "Iteration 1201, loss = 0.23375720\n",
            "Iteration 1202, loss = 0.23368776\n",
            "Iteration 1203, loss = 0.23358975\n",
            "Iteration 1204, loss = 0.23349256\n",
            "Iteration 1205, loss = 0.23339092\n",
            "Iteration 1206, loss = 0.23330371\n",
            "Iteration 1207, loss = 0.23321365\n",
            "Iteration 1208, loss = 0.23313692\n",
            "Iteration 1209, loss = 0.23303454\n",
            "Iteration 1210, loss = 0.23294813\n",
            "Iteration 1211, loss = 0.23286664\n",
            "Iteration 1212, loss = 0.23277447\n",
            "Iteration 1213, loss = 0.23270206\n",
            "Iteration 1214, loss = 0.23259574\n",
            "Iteration 1215, loss = 0.23251331\n",
            "Iteration 1216, loss = 0.23240109\n",
            "Iteration 1217, loss = 0.23231492\n",
            "Iteration 1218, loss = 0.23224103\n",
            "Iteration 1219, loss = 0.23214666\n",
            "Iteration 1220, loss = 0.23204254\n",
            "Iteration 1221, loss = 0.23195170\n",
            "Iteration 1222, loss = 0.23187858\n",
            "Iteration 1223, loss = 0.23178724\n",
            "Iteration 1224, loss = 0.23169277\n",
            "Iteration 1225, loss = 0.23160566\n",
            "Iteration 1226, loss = 0.23151204\n",
            "Iteration 1227, loss = 0.23143522\n",
            "Iteration 1228, loss = 0.23132773\n",
            "Iteration 1229, loss = 0.23124666\n",
            "Iteration 1230, loss = 0.23116016\n",
            "Iteration 1231, loss = 0.23106481\n",
            "Iteration 1232, loss = 0.23098611\n",
            "Iteration 1233, loss = 0.23089113\n",
            "Iteration 1234, loss = 0.23079754\n",
            "Iteration 1235, loss = 0.23070035\n",
            "Iteration 1236, loss = 0.23061550\n",
            "Iteration 1237, loss = 0.23053666\n",
            "Iteration 1238, loss = 0.23044568\n",
            "Iteration 1239, loss = 0.23035059\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.81587230\n",
            "Iteration 2, loss = 0.76558163\n",
            "Iteration 3, loss = 0.70248734\n",
            "Iteration 4, loss = 0.64228130\n",
            "Iteration 5, loss = 0.59430420\n",
            "Iteration 6, loss = 0.55726319\n",
            "Iteration 7, loss = 0.52785788\n",
            "Iteration 8, loss = 0.50583287\n",
            "Iteration 9, loss = 0.48963097\n",
            "Iteration 10, loss = 0.47745789\n",
            "Iteration 11, loss = 0.46776664\n",
            "Iteration 12, loss = 0.46003413\n",
            "Iteration 13, loss = 0.45365092\n",
            "Iteration 14, loss = 0.44846402\n",
            "Iteration 15, loss = 0.44425265\n",
            "Iteration 16, loss = 0.44075448\n",
            "Iteration 17, loss = 0.43748000\n",
            "Iteration 18, loss = 0.43474614\n",
            "Iteration 19, loss = 0.43232890\n",
            "Iteration 20, loss = 0.43002735\n",
            "Iteration 21, loss = 0.42811272\n",
            "Iteration 22, loss = 0.42643181\n",
            "Iteration 23, loss = 0.42471566\n",
            "Iteration 24, loss = 0.42309582\n",
            "Iteration 25, loss = 0.42168424\n",
            "Iteration 26, loss = 0.42032423\n",
            "Iteration 27, loss = 0.41901540\n",
            "Iteration 28, loss = 0.41780946\n",
            "Iteration 29, loss = 0.41667208\n",
            "Iteration 30, loss = 0.41554841\n",
            "Iteration 31, loss = 0.41448042\n",
            "Iteration 32, loss = 0.41339448\n",
            "Iteration 33, loss = 0.41240124\n",
            "Iteration 34, loss = 0.41145696\n",
            "Iteration 35, loss = 0.41051656\n",
            "Iteration 36, loss = 0.40960215\n",
            "Iteration 37, loss = 0.40871180\n",
            "Iteration 38, loss = 0.40785412\n",
            "Iteration 39, loss = 0.40702072\n",
            "Iteration 40, loss = 0.40618328\n",
            "Iteration 41, loss = 0.40539260\n",
            "Iteration 42, loss = 0.40462314\n",
            "Iteration 43, loss = 0.40382542\n",
            "Iteration 44, loss = 0.40306663\n",
            "Iteration 45, loss = 0.40235655\n",
            "Iteration 46, loss = 0.40161137\n",
            "Iteration 47, loss = 0.40093434\n",
            "Iteration 48, loss = 0.40019660\n",
            "Iteration 49, loss = 0.39950569\n",
            "Iteration 50, loss = 0.39884244\n",
            "Iteration 51, loss = 0.39817035\n",
            "Iteration 52, loss = 0.39748289\n",
            "Iteration 53, loss = 0.39684952\n",
            "Iteration 54, loss = 0.39621390\n",
            "Iteration 55, loss = 0.39557015\n",
            "Iteration 56, loss = 0.39496692\n",
            "Iteration 57, loss = 0.39436418\n",
            "Iteration 58, loss = 0.39375598\n",
            "Iteration 59, loss = 0.39315805\n",
            "Iteration 60, loss = 0.39258197\n",
            "Iteration 61, loss = 0.39199309\n",
            "Iteration 62, loss = 0.39143675\n",
            "Iteration 63, loss = 0.39088266\n",
            "Iteration 64, loss = 0.39030357\n",
            "Iteration 65, loss = 0.38978944\n",
            "Iteration 66, loss = 0.38923847\n",
            "Iteration 67, loss = 0.38870906\n",
            "Iteration 68, loss = 0.38818535\n",
            "Iteration 69, loss = 0.38764298\n",
            "Iteration 70, loss = 0.38712912\n",
            "Iteration 71, loss = 0.38663067\n",
            "Iteration 72, loss = 0.38612366\n",
            "Iteration 73, loss = 0.38560730\n",
            "Iteration 74, loss = 0.38512149\n",
            "Iteration 75, loss = 0.38465297\n",
            "Iteration 76, loss = 0.38416182\n",
            "Iteration 77, loss = 0.38367581\n",
            "Iteration 78, loss = 0.38321718\n",
            "Iteration 79, loss = 0.38273807\n",
            "Iteration 80, loss = 0.38230296\n",
            "Iteration 81, loss = 0.38181505\n",
            "Iteration 82, loss = 0.38137528\n",
            "Iteration 83, loss = 0.38089748\n",
            "Iteration 84, loss = 0.38045947\n",
            "Iteration 85, loss = 0.38000689\n",
            "Iteration 86, loss = 0.37957262\n",
            "Iteration 87, loss = 0.37913597\n",
            "Iteration 88, loss = 0.37870633\n",
            "Iteration 89, loss = 0.37827566\n",
            "Iteration 90, loss = 0.37785721\n",
            "Iteration 91, loss = 0.37743161\n",
            "Iteration 92, loss = 0.37702075\n",
            "Iteration 93, loss = 0.37660032\n",
            "Iteration 94, loss = 0.37618676\n",
            "Iteration 95, loss = 0.37578962\n",
            "Iteration 96, loss = 0.37538097\n",
            "Iteration 97, loss = 0.37498261\n",
            "Iteration 98, loss = 0.37458438\n",
            "Iteration 99, loss = 0.37419103\n",
            "Iteration 100, loss = 0.37380021\n",
            "Iteration 101, loss = 0.37344007\n",
            "Iteration 102, loss = 0.37302319\n",
            "Iteration 103, loss = 0.37264721\n",
            "Iteration 104, loss = 0.37227154\n",
            "Iteration 105, loss = 0.37191294\n",
            "Iteration 106, loss = 0.37153263\n",
            "Iteration 107, loss = 0.37116518\n",
            "Iteration 108, loss = 0.37080115\n",
            "Iteration 109, loss = 0.37043164\n",
            "Iteration 110, loss = 0.37009038\n",
            "Iteration 111, loss = 0.36971963\n",
            "Iteration 112, loss = 0.36936873\n",
            "Iteration 113, loss = 0.36901902\n",
            "Iteration 114, loss = 0.36865277\n",
            "Iteration 115, loss = 0.36830513\n",
            "Iteration 116, loss = 0.36797078\n",
            "Iteration 117, loss = 0.36763993\n",
            "Iteration 118, loss = 0.36730412\n",
            "Iteration 119, loss = 0.36693768\n",
            "Iteration 120, loss = 0.36662175\n",
            "Iteration 121, loss = 0.36627399\n",
            "Iteration 122, loss = 0.36594137\n",
            "Iteration 123, loss = 0.36560283\n",
            "Iteration 124, loss = 0.36528979\n",
            "Iteration 125, loss = 0.36496747\n",
            "Iteration 126, loss = 0.36464180\n",
            "Iteration 127, loss = 0.36432423\n",
            "Iteration 128, loss = 0.36400574\n",
            "Iteration 129, loss = 0.36368596\n",
            "Iteration 130, loss = 0.36336883\n",
            "Iteration 131, loss = 0.36305744\n",
            "Iteration 132, loss = 0.36276234\n",
            "Iteration 133, loss = 0.36244054\n",
            "Iteration 134, loss = 0.36211345\n",
            "Iteration 135, loss = 0.36182528\n",
            "Iteration 136, loss = 0.36152771\n",
            "Iteration 137, loss = 0.36121713\n",
            "Iteration 138, loss = 0.36090727\n",
            "Iteration 139, loss = 0.36061226\n",
            "Iteration 140, loss = 0.36032414\n",
            "Iteration 141, loss = 0.36000350\n",
            "Iteration 142, loss = 0.35972194\n",
            "Iteration 143, loss = 0.35943256\n",
            "Iteration 144, loss = 0.35914190\n",
            "Iteration 145, loss = 0.35884908\n",
            "Iteration 146, loss = 0.35857749\n",
            "Iteration 147, loss = 0.35828743\n",
            "Iteration 148, loss = 0.35800130\n",
            "Iteration 149, loss = 0.35773922\n",
            "Iteration 150, loss = 0.35744021\n",
            "Iteration 151, loss = 0.35717153\n",
            "Iteration 152, loss = 0.35688263\n",
            "Iteration 153, loss = 0.35661634\n",
            "Iteration 154, loss = 0.35634688\n",
            "Iteration 155, loss = 0.35607678\n",
            "Iteration 156, loss = 0.35579904\n",
            "Iteration 157, loss = 0.35553231\n",
            "Iteration 158, loss = 0.35526139\n",
            "Iteration 159, loss = 0.35500464\n",
            "Iteration 160, loss = 0.35474425\n",
            "Iteration 161, loss = 0.35448337\n",
            "Iteration 162, loss = 0.35422519\n",
            "Iteration 163, loss = 0.35396694\n",
            "Iteration 164, loss = 0.35371082\n",
            "Iteration 165, loss = 0.35345402\n",
            "Iteration 166, loss = 0.35320079\n",
            "Iteration 167, loss = 0.35293175\n",
            "Iteration 168, loss = 0.35268107\n",
            "Iteration 169, loss = 0.35242281\n",
            "Iteration 170, loss = 0.35217451\n",
            "Iteration 171, loss = 0.35193458\n",
            "Iteration 172, loss = 0.35167904\n",
            "Iteration 173, loss = 0.35144033\n",
            "Iteration 174, loss = 0.35118641\n",
            "Iteration 175, loss = 0.35095787\n",
            "Iteration 176, loss = 0.35070888\n",
            "Iteration 177, loss = 0.35046184\n",
            "Iteration 178, loss = 0.35024428\n",
            "Iteration 179, loss = 0.34998416\n",
            "Iteration 180, loss = 0.34975950\n",
            "Iteration 181, loss = 0.34951412\n",
            "Iteration 182, loss = 0.34927528\n",
            "Iteration 183, loss = 0.34904020\n",
            "Iteration 184, loss = 0.34881638\n",
            "Iteration 185, loss = 0.34856549\n",
            "Iteration 186, loss = 0.34834319\n",
            "Iteration 187, loss = 0.34812196\n",
            "Iteration 188, loss = 0.34786945\n",
            "Iteration 189, loss = 0.34763991\n",
            "Iteration 190, loss = 0.34742664\n",
            "Iteration 191, loss = 0.34717934\n",
            "Iteration 192, loss = 0.34695379\n",
            "Iteration 193, loss = 0.34673596\n",
            "Iteration 194, loss = 0.34651997\n",
            "Iteration 195, loss = 0.34629380\n",
            "Iteration 196, loss = 0.34606780\n",
            "Iteration 197, loss = 0.34584762\n",
            "Iteration 198, loss = 0.34564569\n",
            "Iteration 199, loss = 0.34542804\n",
            "Iteration 200, loss = 0.34521386\n",
            "Iteration 201, loss = 0.34499607\n",
            "Iteration 202, loss = 0.34478488\n",
            "Iteration 203, loss = 0.34458990\n",
            "Iteration 204, loss = 0.34435327\n",
            "Iteration 205, loss = 0.34415344\n",
            "Iteration 206, loss = 0.34395036\n",
            "Iteration 207, loss = 0.34376012\n",
            "Iteration 208, loss = 0.34353239\n",
            "Iteration 209, loss = 0.34332987\n",
            "Iteration 210, loss = 0.34312729\n",
            "Iteration 211, loss = 0.34292435\n",
            "Iteration 212, loss = 0.34272894\n",
            "Iteration 213, loss = 0.34251391\n",
            "Iteration 214, loss = 0.34231176\n",
            "Iteration 215, loss = 0.34211803\n",
            "Iteration 216, loss = 0.34191180\n",
            "Iteration 217, loss = 0.34171272\n",
            "Iteration 218, loss = 0.34152518\n",
            "Iteration 219, loss = 0.34131196\n",
            "Iteration 220, loss = 0.34111919\n",
            "Iteration 221, loss = 0.34093793\n",
            "Iteration 222, loss = 0.34072206\n",
            "Iteration 223, loss = 0.34053602\n",
            "Iteration 224, loss = 0.34034188\n",
            "Iteration 225, loss = 0.34014503\n",
            "Iteration 226, loss = 0.33995785\n",
            "Iteration 227, loss = 0.33976573\n",
            "Iteration 228, loss = 0.33957804\n",
            "Iteration 229, loss = 0.33939298\n",
            "Iteration 230, loss = 0.33920223\n",
            "Iteration 231, loss = 0.33901897\n",
            "Iteration 232, loss = 0.33883058\n",
            "Iteration 233, loss = 0.33866122\n",
            "Iteration 234, loss = 0.33845780\n",
            "Iteration 235, loss = 0.33828172\n",
            "Iteration 236, loss = 0.33810081\n",
            "Iteration 237, loss = 0.33791960\n",
            "Iteration 238, loss = 0.33774124\n",
            "Iteration 239, loss = 0.33756837\n",
            "Iteration 240, loss = 0.33737871\n",
            "Iteration 241, loss = 0.33722690\n",
            "Iteration 242, loss = 0.33703589\n",
            "Iteration 243, loss = 0.33686197\n",
            "Iteration 244, loss = 0.33669815\n",
            "Iteration 245, loss = 0.33653020\n",
            "Iteration 246, loss = 0.33633960\n",
            "Iteration 247, loss = 0.33616192\n",
            "Iteration 248, loss = 0.33599851\n",
            "Iteration 249, loss = 0.33581979\n",
            "Iteration 250, loss = 0.33565663\n",
            "Iteration 251, loss = 0.33549082\n",
            "Iteration 252, loss = 0.33531903\n",
            "Iteration 253, loss = 0.33515040\n",
            "Iteration 254, loss = 0.33498925\n",
            "Iteration 255, loss = 0.33479845\n",
            "Iteration 256, loss = 0.33464626\n",
            "Iteration 257, loss = 0.33447132\n",
            "Iteration 258, loss = 0.33430233\n",
            "Iteration 259, loss = 0.33413520\n",
            "Iteration 260, loss = 0.33397098\n",
            "Iteration 261, loss = 0.33379894\n",
            "Iteration 262, loss = 0.33364655\n",
            "Iteration 263, loss = 0.33346441\n",
            "Iteration 264, loss = 0.33331461\n",
            "Iteration 265, loss = 0.33313993\n",
            "Iteration 266, loss = 0.33299552\n",
            "Iteration 267, loss = 0.33281781\n",
            "Iteration 268, loss = 0.33266407\n",
            "Iteration 269, loss = 0.33248586\n",
            "Iteration 270, loss = 0.33233419\n",
            "Iteration 271, loss = 0.33217063\n",
            "Iteration 272, loss = 0.33200188\n",
            "Iteration 273, loss = 0.33183888\n",
            "Iteration 274, loss = 0.33168353\n",
            "Iteration 275, loss = 0.33153279\n",
            "Iteration 276, loss = 0.33136599\n",
            "Iteration 277, loss = 0.33120967\n",
            "Iteration 278, loss = 0.33105918\n",
            "Iteration 279, loss = 0.33088851\n",
            "Iteration 280, loss = 0.33075859\n",
            "Iteration 281, loss = 0.33057547\n",
            "Iteration 282, loss = 0.33042561\n",
            "Iteration 283, loss = 0.33026605\n",
            "Iteration 284, loss = 0.33012046\n",
            "Iteration 285, loss = 0.32996405\n",
            "Iteration 286, loss = 0.32980309\n",
            "Iteration 287, loss = 0.32966118\n",
            "Iteration 288, loss = 0.32949768\n",
            "Iteration 289, loss = 0.32934177\n",
            "Iteration 290, loss = 0.32921426\n",
            "Iteration 291, loss = 0.32904151\n",
            "Iteration 292, loss = 0.32888729\n",
            "Iteration 293, loss = 0.32873803\n",
            "Iteration 294, loss = 0.32862401\n",
            "Iteration 295, loss = 0.32843168\n",
            "Iteration 296, loss = 0.32829122\n",
            "Iteration 297, loss = 0.32813144\n",
            "Iteration 298, loss = 0.32797998\n",
            "Iteration 299, loss = 0.32782229\n",
            "Iteration 300, loss = 0.32769171\n",
            "Iteration 301, loss = 0.32753872\n",
            "Iteration 302, loss = 0.32738315\n",
            "Iteration 303, loss = 0.32723592\n",
            "Iteration 304, loss = 0.32708085\n",
            "Iteration 305, loss = 0.32692704\n",
            "Iteration 306, loss = 0.32678373\n",
            "Iteration 307, loss = 0.32663340\n",
            "Iteration 308, loss = 0.32649577\n",
            "Iteration 309, loss = 0.32634852\n",
            "Iteration 310, loss = 0.32620282\n",
            "Iteration 311, loss = 0.32605214\n",
            "Iteration 312, loss = 0.32590758\n",
            "Iteration 313, loss = 0.32575126\n",
            "Iteration 314, loss = 0.32560216\n",
            "Iteration 315, loss = 0.32545080\n",
            "Iteration 316, loss = 0.32531327\n",
            "Iteration 317, loss = 0.32517129\n",
            "Iteration 318, loss = 0.32502709\n",
            "Iteration 319, loss = 0.32487374\n",
            "Iteration 320, loss = 0.32474648\n",
            "Iteration 321, loss = 0.32460290\n",
            "Iteration 322, loss = 0.32446161\n",
            "Iteration 323, loss = 0.32431410\n",
            "Iteration 324, loss = 0.32416636\n",
            "Iteration 325, loss = 0.32402437\n",
            "Iteration 326, loss = 0.32389178\n",
            "Iteration 327, loss = 0.32375234\n",
            "Iteration 328, loss = 0.32360805\n",
            "Iteration 329, loss = 0.32346854\n",
            "Iteration 330, loss = 0.32332986\n",
            "Iteration 331, loss = 0.32319255\n",
            "Iteration 332, loss = 0.32306548\n",
            "Iteration 333, loss = 0.32291858\n",
            "Iteration 334, loss = 0.32278267\n",
            "Iteration 335, loss = 0.32264677\n",
            "Iteration 336, loss = 0.32251293\n",
            "Iteration 337, loss = 0.32236835\n",
            "Iteration 338, loss = 0.32224596\n",
            "Iteration 339, loss = 0.32209387\n",
            "Iteration 340, loss = 0.32197188\n",
            "Iteration 341, loss = 0.32183066\n",
            "Iteration 342, loss = 0.32170003\n",
            "Iteration 343, loss = 0.32157346\n",
            "Iteration 344, loss = 0.32144403\n",
            "Iteration 345, loss = 0.32129168\n",
            "Iteration 346, loss = 0.32115842\n",
            "Iteration 347, loss = 0.32103240\n",
            "Iteration 348, loss = 0.32089807\n",
            "Iteration 349, loss = 0.32076543\n",
            "Iteration 350, loss = 0.32064206\n",
            "Iteration 351, loss = 0.32049633\n",
            "Iteration 352, loss = 0.32038073\n",
            "Iteration 353, loss = 0.32024098\n",
            "Iteration 354, loss = 0.32011246\n",
            "Iteration 355, loss = 0.31998143\n",
            "Iteration 356, loss = 0.31985369\n",
            "Iteration 357, loss = 0.31972507\n",
            "Iteration 358, loss = 0.31958004\n",
            "Iteration 359, loss = 0.31945839\n",
            "Iteration 360, loss = 0.31933128\n",
            "Iteration 361, loss = 0.31920005\n",
            "Iteration 362, loss = 0.31905824\n",
            "Iteration 363, loss = 0.31892710\n",
            "Iteration 364, loss = 0.31880647\n",
            "Iteration 365, loss = 0.31867189\n",
            "Iteration 366, loss = 0.31854363\n",
            "Iteration 367, loss = 0.31841846\n",
            "Iteration 368, loss = 0.31830028\n",
            "Iteration 369, loss = 0.31815507\n",
            "Iteration 370, loss = 0.31802778\n",
            "Iteration 371, loss = 0.31790525\n",
            "Iteration 372, loss = 0.31778200\n",
            "Iteration 373, loss = 0.31764831\n",
            "Iteration 374, loss = 0.31753201\n",
            "Iteration 375, loss = 0.31739361\n",
            "Iteration 376, loss = 0.31727328\n",
            "Iteration 377, loss = 0.31715790\n",
            "Iteration 378, loss = 0.31702191\n",
            "Iteration 379, loss = 0.31689046\n",
            "Iteration 380, loss = 0.31678061\n",
            "Iteration 381, loss = 0.31664258\n",
            "Iteration 382, loss = 0.31652757\n",
            "Iteration 383, loss = 0.31638984\n",
            "Iteration 384, loss = 0.31626980\n",
            "Iteration 385, loss = 0.31613459\n",
            "Iteration 386, loss = 0.31601714\n",
            "Iteration 387, loss = 0.31589698\n",
            "Iteration 388, loss = 0.31576778\n",
            "Iteration 389, loss = 0.31564458\n",
            "Iteration 390, loss = 0.31552903\n",
            "Iteration 391, loss = 0.31539919\n",
            "Iteration 392, loss = 0.31526920\n",
            "Iteration 393, loss = 0.31514913\n",
            "Iteration 394, loss = 0.31502391\n",
            "Iteration 395, loss = 0.31490216\n",
            "Iteration 396, loss = 0.31477458\n",
            "Iteration 397, loss = 0.31464999\n",
            "Iteration 398, loss = 0.31452710\n",
            "Iteration 399, loss = 0.31440776\n",
            "Iteration 400, loss = 0.31428286\n",
            "Iteration 401, loss = 0.31417041\n",
            "Iteration 402, loss = 0.31403562\n",
            "Iteration 403, loss = 0.31391295\n",
            "Iteration 404, loss = 0.31378571\n",
            "Iteration 405, loss = 0.31366235\n",
            "Iteration 406, loss = 0.31354604\n",
            "Iteration 407, loss = 0.31342834\n",
            "Iteration 408, loss = 0.31331464\n",
            "Iteration 409, loss = 0.31318235\n",
            "Iteration 410, loss = 0.31304965\n",
            "Iteration 411, loss = 0.31293286\n",
            "Iteration 412, loss = 0.31281085\n",
            "Iteration 413, loss = 0.31267581\n",
            "Iteration 414, loss = 0.31256732\n",
            "Iteration 415, loss = 0.31243099\n",
            "Iteration 416, loss = 0.31230695\n",
            "Iteration 417, loss = 0.31220369\n",
            "Iteration 418, loss = 0.31207777\n",
            "Iteration 419, loss = 0.31193704\n",
            "Iteration 420, loss = 0.31182176\n",
            "Iteration 421, loss = 0.31169055\n",
            "Iteration 422, loss = 0.31158226\n",
            "Iteration 423, loss = 0.31144190\n",
            "Iteration 424, loss = 0.31132081\n",
            "Iteration 425, loss = 0.31119361\n",
            "Iteration 426, loss = 0.31107758\n",
            "Iteration 427, loss = 0.31095471\n",
            "Iteration 428, loss = 0.31082727\n",
            "Iteration 429, loss = 0.31071186\n",
            "Iteration 430, loss = 0.31059225\n",
            "Iteration 431, loss = 0.31047546\n",
            "Iteration 432, loss = 0.31034767\n",
            "Iteration 433, loss = 0.31022846\n",
            "Iteration 434, loss = 0.31010945\n",
            "Iteration 435, loss = 0.30998589\n",
            "Iteration 436, loss = 0.30985577\n",
            "Iteration 437, loss = 0.30974583\n",
            "Iteration 438, loss = 0.30961629\n",
            "Iteration 439, loss = 0.30950135\n",
            "Iteration 440, loss = 0.30936907\n",
            "Iteration 441, loss = 0.30925123\n",
            "Iteration 442, loss = 0.30914004\n",
            "Iteration 443, loss = 0.30900849\n",
            "Iteration 444, loss = 0.30890064\n",
            "Iteration 445, loss = 0.30879038\n",
            "Iteration 446, loss = 0.30866045\n",
            "Iteration 447, loss = 0.30854706\n",
            "Iteration 448, loss = 0.30842138\n",
            "Iteration 449, loss = 0.30830996\n",
            "Iteration 450, loss = 0.30818863\n",
            "Iteration 451, loss = 0.30807861\n",
            "Iteration 452, loss = 0.30795810\n",
            "Iteration 453, loss = 0.30783655\n",
            "Iteration 454, loss = 0.30770725\n",
            "Iteration 455, loss = 0.30759869\n",
            "Iteration 456, loss = 0.30747534\n",
            "Iteration 457, loss = 0.30736686\n",
            "Iteration 458, loss = 0.30725402\n",
            "Iteration 459, loss = 0.30713412\n",
            "Iteration 460, loss = 0.30699991\n",
            "Iteration 461, loss = 0.30690589\n",
            "Iteration 462, loss = 0.30676488\n",
            "Iteration 463, loss = 0.30665183\n",
            "Iteration 464, loss = 0.30653783\n",
            "Iteration 465, loss = 0.30643256\n",
            "Iteration 466, loss = 0.30630382\n",
            "Iteration 467, loss = 0.30619232\n",
            "Iteration 468, loss = 0.30606623\n",
            "Iteration 469, loss = 0.30594578\n",
            "Iteration 470, loss = 0.30583439\n",
            "Iteration 471, loss = 0.30572044\n",
            "Iteration 472, loss = 0.30560813\n",
            "Iteration 473, loss = 0.30548194\n",
            "Iteration 474, loss = 0.30537018\n",
            "Iteration 475, loss = 0.30524398\n",
            "Iteration 476, loss = 0.30513840\n",
            "Iteration 477, loss = 0.30501911\n",
            "Iteration 478, loss = 0.30491295\n",
            "Iteration 479, loss = 0.30477807\n",
            "Iteration 480, loss = 0.30466907\n",
            "Iteration 481, loss = 0.30455416\n",
            "Iteration 482, loss = 0.30442486\n",
            "Iteration 483, loss = 0.30433266\n",
            "Iteration 484, loss = 0.30420660\n",
            "Iteration 485, loss = 0.30408207\n",
            "Iteration 486, loss = 0.30396152\n",
            "Iteration 487, loss = 0.30385659\n",
            "Iteration 488, loss = 0.30374477\n",
            "Iteration 489, loss = 0.30362612\n",
            "Iteration 490, loss = 0.30351347\n",
            "Iteration 491, loss = 0.30338765\n",
            "Iteration 492, loss = 0.30327124\n",
            "Iteration 493, loss = 0.30316478\n",
            "Iteration 494, loss = 0.30304362\n",
            "Iteration 495, loss = 0.30292900\n",
            "Iteration 496, loss = 0.30281285\n",
            "Iteration 497, loss = 0.30271128\n",
            "Iteration 498, loss = 0.30260905\n",
            "Iteration 499, loss = 0.30246664\n",
            "Iteration 500, loss = 0.30236021\n",
            "Iteration 501, loss = 0.30224759\n",
            "Iteration 502, loss = 0.30213189\n",
            "Iteration 503, loss = 0.30201238\n",
            "Iteration 504, loss = 0.30189845\n",
            "Iteration 505, loss = 0.30180239\n",
            "Iteration 506, loss = 0.30166967\n",
            "Iteration 507, loss = 0.30155387\n",
            "Iteration 508, loss = 0.30144315\n",
            "Iteration 509, loss = 0.30134071\n",
            "Iteration 510, loss = 0.30121254\n",
            "Iteration 511, loss = 0.30109751\n",
            "Iteration 512, loss = 0.30097987\n",
            "Iteration 513, loss = 0.30087529\n",
            "Iteration 514, loss = 0.30076803\n",
            "Iteration 515, loss = 0.30064633\n",
            "Iteration 516, loss = 0.30052669\n",
            "Iteration 517, loss = 0.30044739\n",
            "Iteration 518, loss = 0.30030316\n",
            "Iteration 519, loss = 0.30020087\n",
            "Iteration 520, loss = 0.30009511\n",
            "Iteration 521, loss = 0.29999467\n",
            "Iteration 522, loss = 0.29985508\n",
            "Iteration 523, loss = 0.29974662\n",
            "Iteration 524, loss = 0.29963156\n",
            "Iteration 525, loss = 0.29952176\n",
            "Iteration 526, loss = 0.29940954\n",
            "Iteration 527, loss = 0.29929798\n",
            "Iteration 528, loss = 0.29919202\n",
            "Iteration 529, loss = 0.29908310\n",
            "Iteration 530, loss = 0.29895853\n",
            "Iteration 531, loss = 0.29885549\n",
            "Iteration 532, loss = 0.29873968\n",
            "Iteration 533, loss = 0.29862785\n",
            "Iteration 534, loss = 0.29850659\n",
            "Iteration 535, loss = 0.29839048\n",
            "Iteration 536, loss = 0.29826946\n",
            "Iteration 537, loss = 0.29816320\n",
            "Iteration 538, loss = 0.29805747\n",
            "Iteration 539, loss = 0.29793135\n",
            "Iteration 540, loss = 0.29782684\n",
            "Iteration 541, loss = 0.29773520\n",
            "Iteration 542, loss = 0.29759485\n",
            "Iteration 543, loss = 0.29748091\n",
            "Iteration 544, loss = 0.29736001\n",
            "Iteration 545, loss = 0.29724876\n",
            "Iteration 546, loss = 0.29714174\n",
            "Iteration 547, loss = 0.29702658\n",
            "Iteration 548, loss = 0.29691395\n",
            "Iteration 549, loss = 0.29679894\n",
            "Iteration 550, loss = 0.29669881\n",
            "Iteration 551, loss = 0.29657152\n",
            "Iteration 552, loss = 0.29645670\n",
            "Iteration 553, loss = 0.29635305\n",
            "Iteration 554, loss = 0.29624295\n",
            "Iteration 555, loss = 0.29612364\n",
            "Iteration 556, loss = 0.29600937\n",
            "Iteration 557, loss = 0.29591174\n",
            "Iteration 558, loss = 0.29579528\n",
            "Iteration 559, loss = 0.29569306\n",
            "Iteration 560, loss = 0.29556556\n",
            "Iteration 561, loss = 0.29545358\n",
            "Iteration 562, loss = 0.29534339\n",
            "Iteration 563, loss = 0.29522530\n",
            "Iteration 564, loss = 0.29512557\n",
            "Iteration 565, loss = 0.29501563\n",
            "Iteration 566, loss = 0.29490235\n",
            "Iteration 567, loss = 0.29479126\n",
            "Iteration 568, loss = 0.29468421\n",
            "Iteration 569, loss = 0.29455779\n",
            "Iteration 570, loss = 0.29444740\n",
            "Iteration 571, loss = 0.29433873\n",
            "Iteration 572, loss = 0.29423115\n",
            "Iteration 573, loss = 0.29411846\n",
            "Iteration 574, loss = 0.29400780\n",
            "Iteration 575, loss = 0.29389000\n",
            "Iteration 576, loss = 0.29377620\n",
            "Iteration 577, loss = 0.29366518\n",
            "Iteration 578, loss = 0.29354725\n",
            "Iteration 579, loss = 0.29344489\n",
            "Iteration 580, loss = 0.29334109\n",
            "Iteration 581, loss = 0.29321125\n",
            "Iteration 582, loss = 0.29310413\n",
            "Iteration 583, loss = 0.29299560\n",
            "Iteration 584, loss = 0.29288617\n",
            "Iteration 585, loss = 0.29277106\n",
            "Iteration 586, loss = 0.29265512\n",
            "Iteration 587, loss = 0.29256417\n",
            "Iteration 588, loss = 0.29242802\n",
            "Iteration 589, loss = 0.29232532\n",
            "Iteration 590, loss = 0.29220603\n",
            "Iteration 591, loss = 0.29210389\n",
            "Iteration 592, loss = 0.29198226\n",
            "Iteration 593, loss = 0.29188164\n",
            "Iteration 594, loss = 0.29177467\n",
            "Iteration 595, loss = 0.29165336\n",
            "Iteration 596, loss = 0.29154808\n",
            "Iteration 597, loss = 0.29142897\n",
            "Iteration 598, loss = 0.29132346\n",
            "Iteration 599, loss = 0.29120960\n",
            "Iteration 600, loss = 0.29110369\n",
            "Iteration 601, loss = 0.29099658\n",
            "Iteration 602, loss = 0.29087477\n",
            "Iteration 603, loss = 0.29076724\n",
            "Iteration 604, loss = 0.29066433\n",
            "Iteration 605, loss = 0.29054103\n",
            "Iteration 606, loss = 0.29043990\n",
            "Iteration 607, loss = 0.29032807\n",
            "Iteration 608, loss = 0.29021640\n",
            "Iteration 609, loss = 0.29011075\n",
            "Iteration 610, loss = 0.29000362\n",
            "Iteration 611, loss = 0.28988571\n",
            "Iteration 612, loss = 0.28977212\n",
            "Iteration 613, loss = 0.28966608\n",
            "Iteration 614, loss = 0.28957540\n",
            "Iteration 615, loss = 0.28944819\n",
            "Iteration 616, loss = 0.28933988\n",
            "Iteration 617, loss = 0.28923131\n",
            "Iteration 618, loss = 0.28913047\n",
            "Iteration 619, loss = 0.28900446\n",
            "Iteration 620, loss = 0.28891129\n",
            "Iteration 621, loss = 0.28879345\n",
            "Iteration 622, loss = 0.28869812\n",
            "Iteration 623, loss = 0.28859131\n",
            "Iteration 624, loss = 0.28847261\n",
            "Iteration 625, loss = 0.28836467\n",
            "Iteration 626, loss = 0.28826448\n",
            "Iteration 627, loss = 0.28814262\n",
            "Iteration 628, loss = 0.28804257\n",
            "Iteration 629, loss = 0.28793186\n",
            "Iteration 630, loss = 0.28783173\n",
            "Iteration 631, loss = 0.28772352\n",
            "Iteration 632, loss = 0.28762423\n",
            "Iteration 633, loss = 0.28750387\n",
            "Iteration 634, loss = 0.28740568\n",
            "Iteration 635, loss = 0.28729770\n",
            "Iteration 636, loss = 0.28719373\n",
            "Iteration 637, loss = 0.28707847\n",
            "Iteration 638, loss = 0.28698730\n",
            "Iteration 639, loss = 0.28686726\n",
            "Iteration 640, loss = 0.28674963\n",
            "Iteration 641, loss = 0.28665067\n",
            "Iteration 642, loss = 0.28654806\n",
            "Iteration 643, loss = 0.28643355\n",
            "Iteration 644, loss = 0.28633340\n",
            "Iteration 645, loss = 0.28622006\n",
            "Iteration 646, loss = 0.28612063\n",
            "Iteration 647, loss = 0.28600972\n",
            "Iteration 648, loss = 0.28592969\n",
            "Iteration 649, loss = 0.28579776\n",
            "Iteration 650, loss = 0.28569754\n",
            "Iteration 651, loss = 0.28558811\n",
            "Iteration 652, loss = 0.28549293\n",
            "Iteration 653, loss = 0.28539960\n",
            "Iteration 654, loss = 0.28529171\n",
            "Iteration 655, loss = 0.28516913\n",
            "Iteration 656, loss = 0.28506263\n",
            "Iteration 657, loss = 0.28495836\n",
            "Iteration 658, loss = 0.28485843\n",
            "Iteration 659, loss = 0.28475195\n",
            "Iteration 660, loss = 0.28465104\n",
            "Iteration 661, loss = 0.28455359\n",
            "Iteration 662, loss = 0.28444649\n",
            "Iteration 663, loss = 0.28433088\n",
            "Iteration 664, loss = 0.28423181\n",
            "Iteration 665, loss = 0.28412640\n",
            "Iteration 666, loss = 0.28402771\n",
            "Iteration 667, loss = 0.28391622\n",
            "Iteration 668, loss = 0.28381759\n",
            "Iteration 669, loss = 0.28372321\n",
            "Iteration 670, loss = 0.28359668\n",
            "Iteration 671, loss = 0.28351354\n",
            "Iteration 672, loss = 0.28340280\n",
            "Iteration 673, loss = 0.28329427\n",
            "Iteration 674, loss = 0.28318629\n",
            "Iteration 675, loss = 0.28308307\n",
            "Iteration 676, loss = 0.28298278\n",
            "Iteration 677, loss = 0.28288030\n",
            "Iteration 678, loss = 0.28277004\n",
            "Iteration 679, loss = 0.28266801\n",
            "Iteration 680, loss = 0.28256539\n",
            "Iteration 681, loss = 0.28245797\n",
            "Iteration 682, loss = 0.28234988\n",
            "Iteration 683, loss = 0.28226118\n",
            "Iteration 684, loss = 0.28214887\n",
            "Iteration 685, loss = 0.28206314\n",
            "Iteration 686, loss = 0.28195636\n",
            "Iteration 687, loss = 0.28183688\n",
            "Iteration 688, loss = 0.28175600\n",
            "Iteration 689, loss = 0.28164576\n",
            "Iteration 690, loss = 0.28154118\n",
            "Iteration 691, loss = 0.28144178\n",
            "Iteration 692, loss = 0.28132950\n",
            "Iteration 693, loss = 0.28122954\n",
            "Iteration 694, loss = 0.28111509\n",
            "Iteration 695, loss = 0.28102648\n",
            "Iteration 696, loss = 0.28091500\n",
            "Iteration 697, loss = 0.28081132\n",
            "Iteration 698, loss = 0.28071652\n",
            "Iteration 699, loss = 0.28060258\n",
            "Iteration 700, loss = 0.28050426\n",
            "Iteration 701, loss = 0.28040228\n",
            "Iteration 702, loss = 0.28030133\n",
            "Iteration 703, loss = 0.28021145\n",
            "Iteration 704, loss = 0.28009222\n",
            "Iteration 705, loss = 0.28000384\n",
            "Iteration 706, loss = 0.27988790\n",
            "Iteration 707, loss = 0.27977988\n",
            "Iteration 708, loss = 0.27969431\n",
            "Iteration 709, loss = 0.27958496\n",
            "Iteration 710, loss = 0.27948617\n",
            "Iteration 711, loss = 0.27937274\n",
            "Iteration 712, loss = 0.27928246\n",
            "Iteration 713, loss = 0.27916709\n",
            "Iteration 714, loss = 0.27906700\n",
            "Iteration 715, loss = 0.27897667\n",
            "Iteration 716, loss = 0.27887201\n",
            "Iteration 717, loss = 0.27876937\n",
            "Iteration 718, loss = 0.27866190\n",
            "Iteration 719, loss = 0.27856873\n",
            "Iteration 720, loss = 0.27846575\n",
            "Iteration 721, loss = 0.27834978\n",
            "Iteration 722, loss = 0.27825936\n",
            "Iteration 723, loss = 0.27815802\n",
            "Iteration 724, loss = 0.27804764\n",
            "Iteration 725, loss = 0.27796056\n",
            "Iteration 726, loss = 0.27784572\n",
            "Iteration 727, loss = 0.27775323\n",
            "Iteration 728, loss = 0.27765451\n",
            "Iteration 729, loss = 0.27754014\n",
            "Iteration 730, loss = 0.27744227\n",
            "Iteration 731, loss = 0.27734123\n",
            "Iteration 732, loss = 0.27724350\n",
            "Iteration 733, loss = 0.27713285\n",
            "Iteration 734, loss = 0.27702477\n",
            "Iteration 735, loss = 0.27694328\n",
            "Iteration 736, loss = 0.27683169\n",
            "Iteration 737, loss = 0.27674033\n",
            "Iteration 738, loss = 0.27662996\n",
            "Iteration 739, loss = 0.27651537\n",
            "Iteration 740, loss = 0.27642327\n",
            "Iteration 741, loss = 0.27633250\n",
            "Iteration 742, loss = 0.27620987\n",
            "Iteration 743, loss = 0.27612327\n",
            "Iteration 744, loss = 0.27603325\n",
            "Iteration 745, loss = 0.27590774\n",
            "Iteration 746, loss = 0.27581270\n",
            "Iteration 747, loss = 0.27571859\n",
            "Iteration 748, loss = 0.27560445\n",
            "Iteration 749, loss = 0.27550089\n",
            "Iteration 750, loss = 0.27540523\n",
            "Iteration 751, loss = 0.27530626\n",
            "Iteration 752, loss = 0.27519258\n",
            "Iteration 753, loss = 0.27510311\n",
            "Iteration 754, loss = 0.27499873\n",
            "Iteration 755, loss = 0.27489596\n",
            "Iteration 756, loss = 0.27479045\n",
            "Iteration 757, loss = 0.27468746\n",
            "Iteration 758, loss = 0.27459333\n",
            "Iteration 759, loss = 0.27449570\n",
            "Iteration 760, loss = 0.27438632\n",
            "Iteration 761, loss = 0.27429506\n",
            "Iteration 762, loss = 0.27417692\n",
            "Iteration 763, loss = 0.27408958\n",
            "Iteration 764, loss = 0.27398698\n",
            "Iteration 765, loss = 0.27387213\n",
            "Iteration 766, loss = 0.27378023\n",
            "Iteration 767, loss = 0.27367655\n",
            "Iteration 768, loss = 0.27357804\n",
            "Iteration 769, loss = 0.27347341\n",
            "Iteration 770, loss = 0.27337193\n",
            "Iteration 771, loss = 0.27326891\n",
            "Iteration 772, loss = 0.27317467\n",
            "Iteration 773, loss = 0.27308880\n",
            "Iteration 774, loss = 0.27297186\n",
            "Iteration 775, loss = 0.27286896\n",
            "Iteration 776, loss = 0.27277502\n",
            "Iteration 777, loss = 0.27267336\n",
            "Iteration 778, loss = 0.27257330\n",
            "Iteration 779, loss = 0.27247427\n",
            "Iteration 780, loss = 0.27237533\n",
            "Iteration 781, loss = 0.27228230\n",
            "Iteration 782, loss = 0.27216501\n",
            "Iteration 783, loss = 0.27207366\n",
            "Iteration 784, loss = 0.27196811\n",
            "Iteration 785, loss = 0.27186348\n",
            "Iteration 786, loss = 0.27176758\n",
            "Iteration 787, loss = 0.27167656\n",
            "Iteration 788, loss = 0.27157556\n",
            "Iteration 789, loss = 0.27146756\n",
            "Iteration 790, loss = 0.27136549\n",
            "Iteration 791, loss = 0.27127125\n",
            "Iteration 792, loss = 0.27118599\n",
            "Iteration 793, loss = 0.27106021\n",
            "Iteration 794, loss = 0.27096769\n",
            "Iteration 795, loss = 0.27087285\n",
            "Iteration 796, loss = 0.27077778\n",
            "Iteration 797, loss = 0.27067517\n",
            "Iteration 798, loss = 0.27058738\n",
            "Iteration 799, loss = 0.27047897\n",
            "Iteration 800, loss = 0.27037430\n",
            "Iteration 801, loss = 0.27027648\n",
            "Iteration 802, loss = 0.27017363\n",
            "Iteration 803, loss = 0.27006839\n",
            "Iteration 804, loss = 0.26997441\n",
            "Iteration 805, loss = 0.26986917\n",
            "Iteration 806, loss = 0.26975935\n",
            "Iteration 807, loss = 0.26967371\n",
            "Iteration 808, loss = 0.26956196\n",
            "Iteration 809, loss = 0.26947665\n",
            "Iteration 810, loss = 0.26937338\n",
            "Iteration 811, loss = 0.26927839\n",
            "Iteration 812, loss = 0.26916574\n",
            "Iteration 813, loss = 0.26907046\n",
            "Iteration 814, loss = 0.26897018\n",
            "Iteration 815, loss = 0.26887368\n",
            "Iteration 816, loss = 0.26878835\n",
            "Iteration 817, loss = 0.26868198\n",
            "Iteration 818, loss = 0.26858400\n",
            "Iteration 819, loss = 0.26847678\n",
            "Iteration 820, loss = 0.26838296\n",
            "Iteration 821, loss = 0.26828209\n",
            "Iteration 822, loss = 0.26817270\n",
            "Iteration 823, loss = 0.26809198\n",
            "Iteration 824, loss = 0.26798564\n",
            "Iteration 825, loss = 0.26789056\n",
            "Iteration 826, loss = 0.26779096\n",
            "Iteration 827, loss = 0.26770666\n",
            "Iteration 828, loss = 0.26758736\n",
            "Iteration 829, loss = 0.26749769\n",
            "Iteration 830, loss = 0.26740224\n",
            "Iteration 831, loss = 0.26729553\n",
            "Iteration 832, loss = 0.26720812\n",
            "Iteration 833, loss = 0.26711565\n",
            "Iteration 834, loss = 0.26702862\n",
            "Iteration 835, loss = 0.26691672\n",
            "Iteration 836, loss = 0.26683419\n",
            "Iteration 837, loss = 0.26673080\n",
            "Iteration 838, loss = 0.26662518\n",
            "Iteration 839, loss = 0.26653010\n",
            "Iteration 840, loss = 0.26643581\n",
            "Iteration 841, loss = 0.26633955\n",
            "Iteration 842, loss = 0.26627203\n",
            "Iteration 843, loss = 0.26616390\n",
            "Iteration 844, loss = 0.26606225\n",
            "Iteration 845, loss = 0.26596737\n",
            "Iteration 846, loss = 0.26587572\n",
            "Iteration 847, loss = 0.26578260\n",
            "Iteration 848, loss = 0.26567389\n",
            "Iteration 849, loss = 0.26559816\n",
            "Iteration 850, loss = 0.26550422\n",
            "Iteration 851, loss = 0.26542267\n",
            "Iteration 852, loss = 0.26529480\n",
            "Iteration 853, loss = 0.26520648\n",
            "Iteration 854, loss = 0.26509563\n",
            "Iteration 855, loss = 0.26501330\n",
            "Iteration 856, loss = 0.26491411\n",
            "Iteration 857, loss = 0.26484488\n",
            "Iteration 858, loss = 0.26472629\n",
            "Iteration 859, loss = 0.26461462\n",
            "Iteration 860, loss = 0.26454207\n",
            "Iteration 861, loss = 0.26444230\n",
            "Iteration 862, loss = 0.26435106\n",
            "Iteration 863, loss = 0.26426925\n",
            "Iteration 864, loss = 0.26417278\n",
            "Iteration 865, loss = 0.26407334\n",
            "Iteration 866, loss = 0.26395859\n",
            "Iteration 867, loss = 0.26386654\n",
            "Iteration 868, loss = 0.26377501\n",
            "Iteration 869, loss = 0.26368235\n",
            "Iteration 870, loss = 0.26358094\n",
            "Iteration 871, loss = 0.26348606\n",
            "Iteration 872, loss = 0.26340828\n",
            "Iteration 873, loss = 0.26329789\n",
            "Iteration 874, loss = 0.26320024\n",
            "Iteration 875, loss = 0.26311566\n",
            "Iteration 876, loss = 0.26299995\n",
            "Iteration 877, loss = 0.26292369\n",
            "Iteration 878, loss = 0.26280294\n",
            "Iteration 879, loss = 0.26272723\n",
            "Iteration 880, loss = 0.26263947\n",
            "Iteration 881, loss = 0.26252765\n",
            "Iteration 882, loss = 0.26243852\n",
            "Iteration 883, loss = 0.26234607\n",
            "Iteration 884, loss = 0.26224809\n",
            "Iteration 885, loss = 0.26215018\n",
            "Iteration 886, loss = 0.26207196\n",
            "Iteration 887, loss = 0.26197337\n",
            "Iteration 888, loss = 0.26187459\n",
            "Iteration 889, loss = 0.26177553\n",
            "Iteration 890, loss = 0.26167108\n",
            "Iteration 891, loss = 0.26159488\n",
            "Iteration 892, loss = 0.26149817\n",
            "Iteration 893, loss = 0.26140876\n",
            "Iteration 894, loss = 0.26130571\n",
            "Iteration 895, loss = 0.26120474\n",
            "Iteration 896, loss = 0.26112040\n",
            "Iteration 897, loss = 0.26101781\n",
            "Iteration 898, loss = 0.26093327\n",
            "Iteration 899, loss = 0.26083852\n",
            "Iteration 900, loss = 0.26073643\n",
            "Iteration 901, loss = 0.26064787\n",
            "Iteration 902, loss = 0.26057221\n",
            "Iteration 903, loss = 0.26047079\n",
            "Iteration 904, loss = 0.26036079\n",
            "Iteration 905, loss = 0.26026856\n",
            "Iteration 906, loss = 0.26018667\n",
            "Iteration 907, loss = 0.26007523\n",
            "Iteration 908, loss = 0.25999212\n",
            "Iteration 909, loss = 0.25990219\n",
            "Iteration 910, loss = 0.25979757\n",
            "Iteration 911, loss = 0.25972429\n",
            "Iteration 912, loss = 0.25962852\n",
            "Iteration 913, loss = 0.25953215\n",
            "Iteration 914, loss = 0.25943458\n",
            "Iteration 915, loss = 0.25933775\n",
            "Iteration 916, loss = 0.25923637\n",
            "Iteration 917, loss = 0.25915183\n",
            "Iteration 918, loss = 0.25905225\n",
            "Iteration 919, loss = 0.25895759\n",
            "Iteration 920, loss = 0.25887999\n",
            "Iteration 921, loss = 0.25877476\n",
            "Iteration 922, loss = 0.25869031\n",
            "Iteration 923, loss = 0.25860303\n",
            "Iteration 924, loss = 0.25849655\n",
            "Iteration 925, loss = 0.25841852\n",
            "Iteration 926, loss = 0.25829819\n",
            "Iteration 927, loss = 0.25821972\n",
            "Iteration 928, loss = 0.25812441\n",
            "Iteration 929, loss = 0.25804484\n",
            "Iteration 930, loss = 0.25793745\n",
            "Iteration 931, loss = 0.25785422\n",
            "Iteration 932, loss = 0.25775678\n",
            "Iteration 933, loss = 0.25765913\n",
            "Iteration 934, loss = 0.25757073\n",
            "Iteration 935, loss = 0.25748359\n",
            "Iteration 936, loss = 0.25738218\n",
            "Iteration 937, loss = 0.25730173\n",
            "Iteration 938, loss = 0.25720883\n",
            "Iteration 939, loss = 0.25712922\n",
            "Iteration 940, loss = 0.25701055\n",
            "Iteration 941, loss = 0.25694213\n",
            "Iteration 942, loss = 0.25684768\n",
            "Iteration 943, loss = 0.25676183\n",
            "Iteration 944, loss = 0.25665924\n",
            "Iteration 945, loss = 0.25657646\n",
            "Iteration 946, loss = 0.25648977\n",
            "Iteration 947, loss = 0.25639208\n",
            "Iteration 948, loss = 0.25629517\n",
            "Iteration 949, loss = 0.25620823\n",
            "Iteration 950, loss = 0.25612115\n",
            "Iteration 951, loss = 0.25602431\n",
            "Iteration 952, loss = 0.25593953\n",
            "Iteration 953, loss = 0.25587222\n",
            "Iteration 954, loss = 0.25577969\n",
            "Iteration 955, loss = 0.25567373\n",
            "Iteration 956, loss = 0.25557734\n",
            "Iteration 957, loss = 0.25549188\n",
            "Iteration 958, loss = 0.25540960\n",
            "Iteration 959, loss = 0.25531773\n",
            "Iteration 960, loss = 0.25522414\n",
            "Iteration 961, loss = 0.25513219\n",
            "Iteration 962, loss = 0.25503816\n",
            "Iteration 963, loss = 0.25495775\n",
            "Iteration 964, loss = 0.25486779\n",
            "Iteration 965, loss = 0.25477754\n",
            "Iteration 966, loss = 0.25471414\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.72635651\n",
            "Iteration 2, loss = 0.68919997\n",
            "Iteration 3, loss = 0.64288750\n",
            "Iteration 4, loss = 0.59926658\n",
            "Iteration 5, loss = 0.56376119\n",
            "Iteration 6, loss = 0.53505924\n",
            "Iteration 7, loss = 0.51287952\n",
            "Iteration 8, loss = 0.49480326\n",
            "Iteration 9, loss = 0.48112421\n",
            "Iteration 10, loss = 0.47043655\n",
            "Iteration 11, loss = 0.46161268\n",
            "Iteration 12, loss = 0.45432607\n",
            "Iteration 13, loss = 0.44844157\n",
            "Iteration 14, loss = 0.44337578\n",
            "Iteration 15, loss = 0.43917982\n",
            "Iteration 16, loss = 0.43541298\n",
            "Iteration 17, loss = 0.43224144\n",
            "Iteration 18, loss = 0.42932841\n",
            "Iteration 19, loss = 0.42663253\n",
            "Iteration 20, loss = 0.42437883\n",
            "Iteration 21, loss = 0.42222349\n",
            "Iteration 22, loss = 0.42018283\n",
            "Iteration 23, loss = 0.41844475\n",
            "Iteration 24, loss = 0.41670565\n",
            "Iteration 25, loss = 0.41504404\n",
            "Iteration 26, loss = 0.41347063\n",
            "Iteration 27, loss = 0.41203997\n",
            "Iteration 28, loss = 0.41062213\n",
            "Iteration 29, loss = 0.40933343\n",
            "Iteration 30, loss = 0.40803940\n",
            "Iteration 31, loss = 0.40678254\n",
            "Iteration 32, loss = 0.40555340\n",
            "Iteration 33, loss = 0.40444592\n",
            "Iteration 34, loss = 0.40331522\n",
            "Iteration 35, loss = 0.40219054\n",
            "Iteration 36, loss = 0.40117286\n",
            "Iteration 37, loss = 0.40011506\n",
            "Iteration 38, loss = 0.39912744\n",
            "Iteration 39, loss = 0.39812396\n",
            "Iteration 40, loss = 0.39716609\n",
            "Iteration 41, loss = 0.39629486\n",
            "Iteration 42, loss = 0.39528853\n",
            "Iteration 43, loss = 0.39443450\n",
            "Iteration 44, loss = 0.39354681\n",
            "Iteration 45, loss = 0.39268075\n",
            "Iteration 46, loss = 0.39184087\n",
            "Iteration 47, loss = 0.39101090\n",
            "Iteration 48, loss = 0.39020351\n",
            "Iteration 49, loss = 0.38940306\n",
            "Iteration 50, loss = 0.38862771\n",
            "Iteration 51, loss = 0.38789056\n",
            "Iteration 52, loss = 0.38713129\n",
            "Iteration 53, loss = 0.38640608\n",
            "Iteration 54, loss = 0.38570686\n",
            "Iteration 55, loss = 0.38493889\n",
            "Iteration 56, loss = 0.38425974\n",
            "Iteration 57, loss = 0.38357269\n",
            "Iteration 58, loss = 0.38292686\n",
            "Iteration 59, loss = 0.38224751\n",
            "Iteration 60, loss = 0.38158668\n",
            "Iteration 61, loss = 0.38091407\n",
            "Iteration 62, loss = 0.38030103\n",
            "Iteration 63, loss = 0.37965888\n",
            "Iteration 64, loss = 0.37905293\n",
            "Iteration 65, loss = 0.37842365\n",
            "Iteration 66, loss = 0.37784839\n",
            "Iteration 67, loss = 0.37725320\n",
            "Iteration 68, loss = 0.37667343\n",
            "Iteration 69, loss = 0.37606843\n",
            "Iteration 70, loss = 0.37552683\n",
            "Iteration 71, loss = 0.37493638\n",
            "Iteration 72, loss = 0.37439180\n",
            "Iteration 73, loss = 0.37384368\n",
            "Iteration 74, loss = 0.37332752\n",
            "Iteration 75, loss = 0.37279296\n",
            "Iteration 76, loss = 0.37225468\n",
            "Iteration 77, loss = 0.37174127\n",
            "Iteration 78, loss = 0.37122437\n",
            "Iteration 79, loss = 0.37074130\n",
            "Iteration 80, loss = 0.37025589\n",
            "Iteration 81, loss = 0.36973323\n",
            "Iteration 82, loss = 0.36925159\n",
            "Iteration 83, loss = 0.36876667\n",
            "Iteration 84, loss = 0.36830775\n",
            "Iteration 85, loss = 0.36782000\n",
            "Iteration 86, loss = 0.36738690\n",
            "Iteration 87, loss = 0.36692292\n",
            "Iteration 88, loss = 0.36644401\n",
            "Iteration 89, loss = 0.36600939\n",
            "Iteration 90, loss = 0.36557944\n",
            "Iteration 91, loss = 0.36511041\n",
            "Iteration 92, loss = 0.36468897\n",
            "Iteration 93, loss = 0.36425412\n",
            "Iteration 94, loss = 0.36384072\n",
            "Iteration 95, loss = 0.36340209\n",
            "Iteration 96, loss = 0.36300592\n",
            "Iteration 97, loss = 0.36258325\n",
            "Iteration 98, loss = 0.36216484\n",
            "Iteration 99, loss = 0.36177538\n",
            "Iteration 100, loss = 0.36137272\n",
            "Iteration 101, loss = 0.36096643\n",
            "Iteration 102, loss = 0.36057768\n",
            "Iteration 103, loss = 0.36020324\n",
            "Iteration 104, loss = 0.35978280\n",
            "Iteration 105, loss = 0.35941031\n",
            "Iteration 106, loss = 0.35905607\n",
            "Iteration 107, loss = 0.35866584\n",
            "Iteration 108, loss = 0.35828898\n",
            "Iteration 109, loss = 0.35793240\n",
            "Iteration 110, loss = 0.35755762\n",
            "Iteration 111, loss = 0.35719885\n",
            "Iteration 112, loss = 0.35685554\n",
            "Iteration 113, loss = 0.35650471\n",
            "Iteration 114, loss = 0.35614877\n",
            "Iteration 115, loss = 0.35579919\n",
            "Iteration 116, loss = 0.35545955\n",
            "Iteration 117, loss = 0.35513124\n",
            "Iteration 118, loss = 0.35476409\n",
            "Iteration 119, loss = 0.35444979\n",
            "Iteration 120, loss = 0.35411086\n",
            "Iteration 121, loss = 0.35377416\n",
            "Iteration 122, loss = 0.35343607\n",
            "Iteration 123, loss = 0.35312738\n",
            "Iteration 124, loss = 0.35279978\n",
            "Iteration 125, loss = 0.35247283\n",
            "Iteration 126, loss = 0.35216079\n",
            "Iteration 127, loss = 0.35184947\n",
            "Iteration 128, loss = 0.35152481\n",
            "Iteration 129, loss = 0.35121376\n",
            "Iteration 130, loss = 0.35093227\n",
            "Iteration 131, loss = 0.35061295\n",
            "Iteration 132, loss = 0.35029143\n",
            "Iteration 133, loss = 0.35000756\n",
            "Iteration 134, loss = 0.34969292\n",
            "Iteration 135, loss = 0.34943055\n",
            "Iteration 136, loss = 0.34910921\n",
            "Iteration 137, loss = 0.34882363\n",
            "Iteration 138, loss = 0.34853080\n",
            "Iteration 139, loss = 0.34825031\n",
            "Iteration 140, loss = 0.34797376\n",
            "Iteration 141, loss = 0.34766902\n",
            "Iteration 142, loss = 0.34739464\n",
            "Iteration 143, loss = 0.34710925\n",
            "Iteration 144, loss = 0.34684369\n",
            "Iteration 145, loss = 0.34655392\n",
            "Iteration 146, loss = 0.34627444\n",
            "Iteration 147, loss = 0.34600965\n",
            "Iteration 148, loss = 0.34575445\n",
            "Iteration 149, loss = 0.34547767\n",
            "Iteration 150, loss = 0.34520739\n",
            "Iteration 151, loss = 0.34493272\n",
            "Iteration 152, loss = 0.34468239\n",
            "Iteration 153, loss = 0.34440857\n",
            "Iteration 154, loss = 0.34417981\n",
            "Iteration 155, loss = 0.34390492\n",
            "Iteration 156, loss = 0.34364359\n",
            "Iteration 157, loss = 0.34338521\n",
            "Iteration 158, loss = 0.34313935\n",
            "Iteration 159, loss = 0.34288130\n",
            "Iteration 160, loss = 0.34264189\n",
            "Iteration 161, loss = 0.34238233\n",
            "Iteration 162, loss = 0.34213874\n",
            "Iteration 163, loss = 0.34189171\n",
            "Iteration 164, loss = 0.34165925\n",
            "Iteration 165, loss = 0.34140688\n",
            "Iteration 166, loss = 0.34116396\n",
            "Iteration 167, loss = 0.34093283\n",
            "Iteration 168, loss = 0.34068968\n",
            "Iteration 169, loss = 0.34046419\n",
            "Iteration 170, loss = 0.34020999\n",
            "Iteration 171, loss = 0.33999968\n",
            "Iteration 172, loss = 0.33977813\n",
            "Iteration 173, loss = 0.33952700\n",
            "Iteration 174, loss = 0.33929575\n",
            "Iteration 175, loss = 0.33906760\n",
            "Iteration 176, loss = 0.33883457\n",
            "Iteration 177, loss = 0.33861928\n",
            "Iteration 178, loss = 0.33838162\n",
            "Iteration 179, loss = 0.33816417\n",
            "Iteration 180, loss = 0.33793935\n",
            "Iteration 181, loss = 0.33771524\n",
            "Iteration 182, loss = 0.33750357\n",
            "Iteration 183, loss = 0.33727489\n",
            "Iteration 184, loss = 0.33706659\n",
            "Iteration 185, loss = 0.33684562\n",
            "Iteration 186, loss = 0.33661735\n",
            "Iteration 187, loss = 0.33641594\n",
            "Iteration 188, loss = 0.33620744\n",
            "Iteration 189, loss = 0.33598631\n",
            "Iteration 190, loss = 0.33578258\n",
            "Iteration 191, loss = 0.33556940\n",
            "Iteration 192, loss = 0.33535619\n",
            "Iteration 193, loss = 0.33516556\n",
            "Iteration 194, loss = 0.33494685\n",
            "Iteration 195, loss = 0.33475183\n",
            "Iteration 196, loss = 0.33454632\n",
            "Iteration 197, loss = 0.33434303\n",
            "Iteration 198, loss = 0.33415032\n",
            "Iteration 199, loss = 0.33394286\n",
            "Iteration 200, loss = 0.33373172\n",
            "Iteration 201, loss = 0.33355162\n",
            "Iteration 202, loss = 0.33334689\n",
            "Iteration 203, loss = 0.33314459\n",
            "Iteration 204, loss = 0.33294928\n",
            "Iteration 205, loss = 0.33276249\n",
            "Iteration 206, loss = 0.33255672\n",
            "Iteration 207, loss = 0.33235761\n",
            "Iteration 208, loss = 0.33217136\n",
            "Iteration 209, loss = 0.33198099\n",
            "Iteration 210, loss = 0.33178182\n",
            "Iteration 211, loss = 0.33159478\n",
            "Iteration 212, loss = 0.33140935\n",
            "Iteration 213, loss = 0.33122397\n",
            "Iteration 214, loss = 0.33102769\n",
            "Iteration 215, loss = 0.33083779\n",
            "Iteration 216, loss = 0.33065863\n",
            "Iteration 217, loss = 0.33047177\n",
            "Iteration 218, loss = 0.33029770\n",
            "Iteration 219, loss = 0.33009581\n",
            "Iteration 220, loss = 0.32991004\n",
            "Iteration 221, loss = 0.32974133\n",
            "Iteration 222, loss = 0.32956054\n",
            "Iteration 223, loss = 0.32937473\n",
            "Iteration 224, loss = 0.32919141\n",
            "Iteration 225, loss = 0.32901905\n",
            "Iteration 226, loss = 0.32882494\n",
            "Iteration 227, loss = 0.32864684\n",
            "Iteration 228, loss = 0.32845721\n",
            "Iteration 229, loss = 0.32829068\n",
            "Iteration 230, loss = 0.32811565\n",
            "Iteration 231, loss = 0.32794049\n",
            "Iteration 232, loss = 0.32775084\n",
            "Iteration 233, loss = 0.32758500\n",
            "Iteration 234, loss = 0.32742151\n",
            "Iteration 235, loss = 0.32722546\n",
            "Iteration 236, loss = 0.32705319\n",
            "Iteration 237, loss = 0.32687380\n",
            "Iteration 238, loss = 0.32671366\n",
            "Iteration 239, loss = 0.32654134\n",
            "Iteration 240, loss = 0.32636089\n",
            "Iteration 241, loss = 0.32618630\n",
            "Iteration 242, loss = 0.32602538\n",
            "Iteration 243, loss = 0.32587086\n",
            "Iteration 244, loss = 0.32568644\n",
            "Iteration 245, loss = 0.32551244\n",
            "Iteration 246, loss = 0.32534938\n",
            "Iteration 247, loss = 0.32516781\n",
            "Iteration 248, loss = 0.32500448\n",
            "Iteration 249, loss = 0.32483057\n",
            "Iteration 250, loss = 0.32467102\n",
            "Iteration 251, loss = 0.32450119\n",
            "Iteration 252, loss = 0.32436811\n",
            "Iteration 253, loss = 0.32417781\n",
            "Iteration 254, loss = 0.32401711\n",
            "Iteration 255, loss = 0.32384976\n",
            "Iteration 256, loss = 0.32368819\n",
            "Iteration 257, loss = 0.32352906\n",
            "Iteration 258, loss = 0.32335072\n",
            "Iteration 259, loss = 0.32319652\n",
            "Iteration 260, loss = 0.32303900\n",
            "Iteration 261, loss = 0.32287135\n",
            "Iteration 262, loss = 0.32270020\n",
            "Iteration 263, loss = 0.32254482\n",
            "Iteration 264, loss = 0.32238695\n",
            "Iteration 265, loss = 0.32221848\n",
            "Iteration 266, loss = 0.32205545\n",
            "Iteration 267, loss = 0.32189206\n",
            "Iteration 268, loss = 0.32173862\n",
            "Iteration 269, loss = 0.32157234\n",
            "Iteration 270, loss = 0.32142661\n",
            "Iteration 271, loss = 0.32125690\n",
            "Iteration 272, loss = 0.32110532\n",
            "Iteration 273, loss = 0.32093076\n",
            "Iteration 274, loss = 0.32078404\n",
            "Iteration 275, loss = 0.32061970\n",
            "Iteration 276, loss = 0.32047366\n",
            "Iteration 277, loss = 0.32030819\n",
            "Iteration 278, loss = 0.32015490\n",
            "Iteration 279, loss = 0.32000671\n",
            "Iteration 280, loss = 0.31985567\n",
            "Iteration 281, loss = 0.31970515\n",
            "Iteration 282, loss = 0.31954074\n",
            "Iteration 283, loss = 0.31940083\n",
            "Iteration 284, loss = 0.31924479\n",
            "Iteration 285, loss = 0.31908249\n",
            "Iteration 286, loss = 0.31894102\n",
            "Iteration 287, loss = 0.31881547\n",
            "Iteration 288, loss = 0.31863255\n",
            "Iteration 289, loss = 0.31849378\n",
            "Iteration 290, loss = 0.31834470\n",
            "Iteration 291, loss = 0.31817956\n",
            "Iteration 292, loss = 0.31803898\n",
            "Iteration 293, loss = 0.31788922\n",
            "Iteration 294, loss = 0.31774615\n",
            "Iteration 295, loss = 0.31760619\n",
            "Iteration 296, loss = 0.31743586\n",
            "Iteration 297, loss = 0.31729448\n",
            "Iteration 298, loss = 0.31714641\n",
            "Iteration 299, loss = 0.31699847\n",
            "Iteration 300, loss = 0.31685380\n",
            "Iteration 301, loss = 0.31670975\n",
            "Iteration 302, loss = 0.31655955\n",
            "Iteration 303, loss = 0.31642819\n",
            "Iteration 304, loss = 0.31627871\n",
            "Iteration 305, loss = 0.31612182\n",
            "Iteration 306, loss = 0.31598266\n",
            "Iteration 307, loss = 0.31584092\n",
            "Iteration 308, loss = 0.31568876\n",
            "Iteration 309, loss = 0.31555421\n",
            "Iteration 310, loss = 0.31540465\n",
            "Iteration 311, loss = 0.31526140\n",
            "Iteration 312, loss = 0.31512401\n",
            "Iteration 313, loss = 0.31497836\n",
            "Iteration 314, loss = 0.31485070\n",
            "Iteration 315, loss = 0.31470738\n",
            "Iteration 316, loss = 0.31455664\n",
            "Iteration 317, loss = 0.31442802\n",
            "Iteration 318, loss = 0.31428513\n",
            "Iteration 319, loss = 0.31413671\n",
            "Iteration 320, loss = 0.31402334\n",
            "Iteration 321, loss = 0.31386713\n",
            "Iteration 322, loss = 0.31374236\n",
            "Iteration 323, loss = 0.31358309\n",
            "Iteration 324, loss = 0.31345350\n",
            "Iteration 325, loss = 0.31331468\n",
            "Iteration 326, loss = 0.31317234\n",
            "Iteration 327, loss = 0.31304712\n",
            "Iteration 328, loss = 0.31289932\n",
            "Iteration 329, loss = 0.31276976\n",
            "Iteration 330, loss = 0.31262369\n",
            "Iteration 331, loss = 0.31250610\n",
            "Iteration 332, loss = 0.31236014\n",
            "Iteration 333, loss = 0.31220741\n",
            "Iteration 334, loss = 0.31208382\n",
            "Iteration 335, loss = 0.31193606\n",
            "Iteration 336, loss = 0.31180275\n",
            "Iteration 337, loss = 0.31167188\n",
            "Iteration 338, loss = 0.31153255\n",
            "Iteration 339, loss = 0.31139413\n",
            "Iteration 340, loss = 0.31125229\n",
            "Iteration 341, loss = 0.31112866\n",
            "Iteration 342, loss = 0.31099013\n",
            "Iteration 343, loss = 0.31084509\n",
            "Iteration 344, loss = 0.31071327\n",
            "Iteration 345, loss = 0.31057501\n",
            "Iteration 346, loss = 0.31043764\n",
            "Iteration 347, loss = 0.31030218\n",
            "Iteration 348, loss = 0.31017513\n",
            "Iteration 349, loss = 0.31005522\n",
            "Iteration 350, loss = 0.30989708\n",
            "Iteration 351, loss = 0.30976571\n",
            "Iteration 352, loss = 0.30963429\n",
            "Iteration 353, loss = 0.30950153\n",
            "Iteration 354, loss = 0.30937660\n",
            "Iteration 355, loss = 0.30922875\n",
            "Iteration 356, loss = 0.30910802\n",
            "Iteration 357, loss = 0.30898490\n",
            "Iteration 358, loss = 0.30884264\n",
            "Iteration 359, loss = 0.30872293\n",
            "Iteration 360, loss = 0.30858581\n",
            "Iteration 361, loss = 0.30845542\n",
            "Iteration 362, loss = 0.30831634\n",
            "Iteration 363, loss = 0.30818110\n",
            "Iteration 364, loss = 0.30805178\n",
            "Iteration 365, loss = 0.30792525\n",
            "Iteration 366, loss = 0.30779572\n",
            "Iteration 367, loss = 0.30767175\n",
            "Iteration 368, loss = 0.30753128\n",
            "Iteration 369, loss = 0.30740901\n",
            "Iteration 370, loss = 0.30728748\n",
            "Iteration 371, loss = 0.30717379\n",
            "Iteration 372, loss = 0.30702180\n",
            "Iteration 373, loss = 0.30689906\n",
            "Iteration 374, loss = 0.30675969\n",
            "Iteration 375, loss = 0.30665221\n",
            "Iteration 376, loss = 0.30650489\n",
            "Iteration 377, loss = 0.30638306\n",
            "Iteration 378, loss = 0.30625056\n",
            "Iteration 379, loss = 0.30612786\n",
            "Iteration 380, loss = 0.30600803\n",
            "Iteration 381, loss = 0.30588159\n",
            "Iteration 382, loss = 0.30575799\n",
            "Iteration 383, loss = 0.30563755\n",
            "Iteration 384, loss = 0.30551225\n",
            "Iteration 385, loss = 0.30537185\n",
            "Iteration 386, loss = 0.30524276\n",
            "Iteration 387, loss = 0.30512941\n",
            "Iteration 388, loss = 0.30500194\n",
            "Iteration 389, loss = 0.30488058\n",
            "Iteration 390, loss = 0.30474744\n",
            "Iteration 391, loss = 0.30463811\n",
            "Iteration 392, loss = 0.30451396\n",
            "Iteration 393, loss = 0.30438053\n",
            "Iteration 394, loss = 0.30425586\n",
            "Iteration 395, loss = 0.30412874\n",
            "Iteration 396, loss = 0.30401247\n",
            "Iteration 397, loss = 0.30389545\n",
            "Iteration 398, loss = 0.30376629\n",
            "Iteration 399, loss = 0.30365390\n",
            "Iteration 400, loss = 0.30350980\n",
            "Iteration 401, loss = 0.30338956\n",
            "Iteration 402, loss = 0.30326296\n",
            "Iteration 403, loss = 0.30314604\n",
            "Iteration 404, loss = 0.30302948\n",
            "Iteration 405, loss = 0.30290469\n",
            "Iteration 406, loss = 0.30278097\n",
            "Iteration 407, loss = 0.30266104\n",
            "Iteration 408, loss = 0.30253758\n",
            "Iteration 409, loss = 0.30241040\n",
            "Iteration 410, loss = 0.30228213\n",
            "Iteration 411, loss = 0.30217043\n",
            "Iteration 412, loss = 0.30205436\n",
            "Iteration 413, loss = 0.30193538\n",
            "Iteration 414, loss = 0.30180700\n",
            "Iteration 415, loss = 0.30167617\n",
            "Iteration 416, loss = 0.30155831\n",
            "Iteration 417, loss = 0.30145380\n",
            "Iteration 418, loss = 0.30131970\n",
            "Iteration 419, loss = 0.30119618\n",
            "Iteration 420, loss = 0.30108164\n",
            "Iteration 421, loss = 0.30097078\n",
            "Iteration 422, loss = 0.30083728\n",
            "Iteration 423, loss = 0.30072363\n",
            "Iteration 424, loss = 0.30060107\n",
            "Iteration 425, loss = 0.30048819\n",
            "Iteration 426, loss = 0.30035661\n",
            "Iteration 427, loss = 0.30024085\n",
            "Iteration 428, loss = 0.30013463\n",
            "Iteration 429, loss = 0.30000075\n",
            "Iteration 430, loss = 0.29989798\n",
            "Iteration 431, loss = 0.29977750\n",
            "Iteration 432, loss = 0.29965180\n",
            "Iteration 433, loss = 0.29952266\n",
            "Iteration 434, loss = 0.29941771\n",
            "Iteration 435, loss = 0.29929562\n",
            "Iteration 436, loss = 0.29919176\n",
            "Iteration 437, loss = 0.29906309\n",
            "Iteration 438, loss = 0.29895933\n",
            "Iteration 439, loss = 0.29882493\n",
            "Iteration 440, loss = 0.29870262\n",
            "Iteration 441, loss = 0.29859625\n",
            "Iteration 442, loss = 0.29847301\n",
            "Iteration 443, loss = 0.29836125\n",
            "Iteration 444, loss = 0.29824081\n",
            "Iteration 445, loss = 0.29813562\n",
            "Iteration 446, loss = 0.29801693\n",
            "Iteration 447, loss = 0.29790000\n",
            "Iteration 448, loss = 0.29778764\n",
            "Iteration 449, loss = 0.29767381\n",
            "Iteration 450, loss = 0.29754435\n",
            "Iteration 451, loss = 0.29744284\n",
            "Iteration 452, loss = 0.29732938\n",
            "Iteration 453, loss = 0.29719937\n",
            "Iteration 454, loss = 0.29709407\n",
            "Iteration 455, loss = 0.29696615\n",
            "Iteration 456, loss = 0.29685190\n",
            "Iteration 457, loss = 0.29675989\n",
            "Iteration 458, loss = 0.29661564\n",
            "Iteration 459, loss = 0.29650900\n",
            "Iteration 460, loss = 0.29639882\n",
            "Iteration 461, loss = 0.29627706\n",
            "Iteration 462, loss = 0.29616528\n",
            "Iteration 463, loss = 0.29605511\n",
            "Iteration 464, loss = 0.29594666\n",
            "Iteration 465, loss = 0.29583645\n",
            "Iteration 466, loss = 0.29571789\n",
            "Iteration 467, loss = 0.29561879\n",
            "Iteration 468, loss = 0.29548986\n",
            "Iteration 469, loss = 0.29537272\n",
            "Iteration 470, loss = 0.29526154\n",
            "Iteration 471, loss = 0.29515098\n",
            "Iteration 472, loss = 0.29503316\n",
            "Iteration 473, loss = 0.29493699\n",
            "Iteration 474, loss = 0.29480128\n",
            "Iteration 475, loss = 0.29470546\n",
            "Iteration 476, loss = 0.29459409\n",
            "Iteration 477, loss = 0.29446942\n",
            "Iteration 478, loss = 0.29436380\n",
            "Iteration 479, loss = 0.29424852\n",
            "Iteration 480, loss = 0.29413487\n",
            "Iteration 481, loss = 0.29401686\n",
            "Iteration 482, loss = 0.29392026\n",
            "Iteration 483, loss = 0.29380784\n",
            "Iteration 484, loss = 0.29369462\n",
            "Iteration 485, loss = 0.29359161\n",
            "Iteration 486, loss = 0.29346807\n",
            "Iteration 487, loss = 0.29335991\n",
            "Iteration 488, loss = 0.29326155\n",
            "Iteration 489, loss = 0.29315077\n",
            "Iteration 490, loss = 0.29302939\n",
            "Iteration 491, loss = 0.29292702\n",
            "Iteration 492, loss = 0.29281237\n",
            "Iteration 493, loss = 0.29271074\n",
            "Iteration 494, loss = 0.29259669\n",
            "Iteration 495, loss = 0.29248729\n",
            "Iteration 496, loss = 0.29238152\n",
            "Iteration 497, loss = 0.29227511\n",
            "Iteration 498, loss = 0.29216346\n",
            "Iteration 499, loss = 0.29205764\n",
            "Iteration 500, loss = 0.29193538\n",
            "Iteration 501, loss = 0.29184129\n",
            "Iteration 502, loss = 0.29173657\n",
            "Iteration 503, loss = 0.29163057\n",
            "Iteration 504, loss = 0.29150328\n",
            "Iteration 505, loss = 0.29140107\n",
            "Iteration 506, loss = 0.29128441\n",
            "Iteration 507, loss = 0.29118547\n",
            "Iteration 508, loss = 0.29106630\n",
            "Iteration 509, loss = 0.29096269\n",
            "Iteration 510, loss = 0.29086424\n",
            "Iteration 511, loss = 0.29074976\n",
            "Iteration 512, loss = 0.29064384\n",
            "Iteration 513, loss = 0.29053355\n",
            "Iteration 514, loss = 0.29042974\n",
            "Iteration 515, loss = 0.29031524\n",
            "Iteration 516, loss = 0.29022522\n",
            "Iteration 517, loss = 0.29012140\n",
            "Iteration 518, loss = 0.28999582\n",
            "Iteration 519, loss = 0.28988796\n",
            "Iteration 520, loss = 0.28978534\n",
            "Iteration 521, loss = 0.28966480\n",
            "Iteration 522, loss = 0.28955900\n",
            "Iteration 523, loss = 0.28946512\n",
            "Iteration 524, loss = 0.28935920\n",
            "Iteration 525, loss = 0.28924153\n",
            "Iteration 526, loss = 0.28913710\n",
            "Iteration 527, loss = 0.28902274\n",
            "Iteration 528, loss = 0.28891511\n",
            "Iteration 529, loss = 0.28881801\n",
            "Iteration 530, loss = 0.28870197\n",
            "Iteration 531, loss = 0.28860362\n",
            "Iteration 532, loss = 0.28849160\n",
            "Iteration 533, loss = 0.28839057\n",
            "Iteration 534, loss = 0.28827988\n",
            "Iteration 535, loss = 0.28818346\n",
            "Iteration 536, loss = 0.28806711\n",
            "Iteration 537, loss = 0.28796815\n",
            "Iteration 538, loss = 0.28786198\n",
            "Iteration 539, loss = 0.28775181\n",
            "Iteration 540, loss = 0.28765419\n",
            "Iteration 541, loss = 0.28754529\n",
            "Iteration 542, loss = 0.28743379\n",
            "Iteration 543, loss = 0.28732604\n",
            "Iteration 544, loss = 0.28721667\n",
            "Iteration 545, loss = 0.28711851\n",
            "Iteration 546, loss = 0.28701705\n",
            "Iteration 547, loss = 0.28690046\n",
            "Iteration 548, loss = 0.28678891\n",
            "Iteration 549, loss = 0.28668625\n",
            "Iteration 550, loss = 0.28658512\n",
            "Iteration 551, loss = 0.28649449\n",
            "Iteration 552, loss = 0.28636768\n",
            "Iteration 553, loss = 0.28626114\n",
            "Iteration 554, loss = 0.28614975\n",
            "Iteration 555, loss = 0.28604707\n",
            "Iteration 556, loss = 0.28594843\n",
            "Iteration 557, loss = 0.28583411\n",
            "Iteration 558, loss = 0.28572702\n",
            "Iteration 559, loss = 0.28561429\n",
            "Iteration 560, loss = 0.28551407\n",
            "Iteration 561, loss = 0.28540309\n",
            "Iteration 562, loss = 0.28530194\n",
            "Iteration 563, loss = 0.28519062\n",
            "Iteration 564, loss = 0.28509513\n",
            "Iteration 565, loss = 0.28497307\n",
            "Iteration 566, loss = 0.28488127\n",
            "Iteration 567, loss = 0.28477654\n",
            "Iteration 568, loss = 0.28466166\n",
            "Iteration 569, loss = 0.28456067\n",
            "Iteration 570, loss = 0.28445043\n",
            "Iteration 571, loss = 0.28435252\n",
            "Iteration 572, loss = 0.28424592\n",
            "Iteration 573, loss = 0.28413532\n",
            "Iteration 574, loss = 0.28404374\n",
            "Iteration 575, loss = 0.28393104\n",
            "Iteration 576, loss = 0.28382724\n",
            "Iteration 577, loss = 0.28372324\n",
            "Iteration 578, loss = 0.28361465\n",
            "Iteration 579, loss = 0.28351121\n",
            "Iteration 580, loss = 0.28342834\n",
            "Iteration 581, loss = 0.28329982\n",
            "Iteration 582, loss = 0.28318983\n",
            "Iteration 583, loss = 0.28309300\n",
            "Iteration 584, loss = 0.28298497\n",
            "Iteration 585, loss = 0.28288869\n",
            "Iteration 586, loss = 0.28277281\n",
            "Iteration 587, loss = 0.28267088\n",
            "Iteration 588, loss = 0.28256119\n",
            "Iteration 589, loss = 0.28246808\n",
            "Iteration 590, loss = 0.28234088\n",
            "Iteration 591, loss = 0.28224115\n",
            "Iteration 592, loss = 0.28213973\n",
            "Iteration 593, loss = 0.28203355\n",
            "Iteration 594, loss = 0.28192687\n",
            "Iteration 595, loss = 0.28181684\n",
            "Iteration 596, loss = 0.28173667\n",
            "Iteration 597, loss = 0.28161745\n",
            "Iteration 598, loss = 0.28151890\n",
            "Iteration 599, loss = 0.28141620\n",
            "Iteration 600, loss = 0.28131368\n",
            "Iteration 601, loss = 0.28120534\n",
            "Iteration 602, loss = 0.28109196\n",
            "Iteration 603, loss = 0.28098307\n",
            "Iteration 604, loss = 0.28089864\n",
            "Iteration 605, loss = 0.28077052\n",
            "Iteration 606, loss = 0.28067912\n",
            "Iteration 607, loss = 0.28059625\n",
            "Iteration 608, loss = 0.28046391\n",
            "Iteration 609, loss = 0.28036113\n",
            "Iteration 610, loss = 0.28025255\n",
            "Iteration 611, loss = 0.28015684\n",
            "Iteration 612, loss = 0.28005628\n",
            "Iteration 613, loss = 0.27994685\n",
            "Iteration 614, loss = 0.27984447\n",
            "Iteration 615, loss = 0.27973940\n",
            "Iteration 616, loss = 0.27962542\n",
            "Iteration 617, loss = 0.27951694\n",
            "Iteration 618, loss = 0.27943299\n",
            "Iteration 619, loss = 0.27932958\n",
            "Iteration 620, loss = 0.27921404\n",
            "Iteration 621, loss = 0.27910747\n",
            "Iteration 622, loss = 0.27900950\n",
            "Iteration 623, loss = 0.27893047\n",
            "Iteration 624, loss = 0.27881959\n",
            "Iteration 625, loss = 0.27869479\n",
            "Iteration 626, loss = 0.27859614\n",
            "Iteration 627, loss = 0.27849271\n",
            "Iteration 628, loss = 0.27839018\n",
            "Iteration 629, loss = 0.27828054\n",
            "Iteration 630, loss = 0.27817136\n",
            "Iteration 631, loss = 0.27806925\n",
            "Iteration 632, loss = 0.27797017\n",
            "Iteration 633, loss = 0.27787797\n",
            "Iteration 634, loss = 0.27775910\n",
            "Iteration 635, loss = 0.27765093\n",
            "Iteration 636, loss = 0.27755363\n",
            "Iteration 637, loss = 0.27745021\n",
            "Iteration 638, loss = 0.27734905\n",
            "Iteration 639, loss = 0.27724213\n",
            "Iteration 640, loss = 0.27713661\n",
            "Iteration 641, loss = 0.27703386\n",
            "Iteration 642, loss = 0.27693519\n",
            "Iteration 643, loss = 0.27682761\n",
            "Iteration 644, loss = 0.27673245\n",
            "Iteration 645, loss = 0.27662512\n",
            "Iteration 646, loss = 0.27651796\n",
            "Iteration 647, loss = 0.27642864\n",
            "Iteration 648, loss = 0.27631186\n",
            "Iteration 649, loss = 0.27621606\n",
            "Iteration 650, loss = 0.27610419\n",
            "Iteration 651, loss = 0.27600935\n",
            "Iteration 652, loss = 0.27589730\n",
            "Iteration 653, loss = 0.27580159\n",
            "Iteration 654, loss = 0.27570300\n",
            "Iteration 655, loss = 0.27558854\n",
            "Iteration 656, loss = 0.27548868\n",
            "Iteration 657, loss = 0.27538209\n",
            "Iteration 658, loss = 0.27527590\n",
            "Iteration 659, loss = 0.27517407\n",
            "Iteration 660, loss = 0.27506948\n",
            "Iteration 661, loss = 0.27498484\n",
            "Iteration 662, loss = 0.27487490\n",
            "Iteration 663, loss = 0.27478213\n",
            "Iteration 664, loss = 0.27465590\n",
            "Iteration 665, loss = 0.27455877\n",
            "Iteration 666, loss = 0.27445236\n",
            "Iteration 667, loss = 0.27434833\n",
            "Iteration 668, loss = 0.27424705\n",
            "Iteration 669, loss = 0.27416096\n",
            "Iteration 670, loss = 0.27404202\n",
            "Iteration 671, loss = 0.27396084\n",
            "Iteration 672, loss = 0.27383407\n",
            "Iteration 673, loss = 0.27374182\n",
            "Iteration 674, loss = 0.27363318\n",
            "Iteration 675, loss = 0.27352412\n",
            "Iteration 676, loss = 0.27342043\n",
            "Iteration 677, loss = 0.27332985\n",
            "Iteration 678, loss = 0.27322152\n",
            "Iteration 679, loss = 0.27312875\n",
            "Iteration 680, loss = 0.27303473\n",
            "Iteration 681, loss = 0.27292752\n",
            "Iteration 682, loss = 0.27281953\n",
            "Iteration 683, loss = 0.27270854\n",
            "Iteration 684, loss = 0.27261872\n",
            "Iteration 685, loss = 0.27251428\n",
            "Iteration 686, loss = 0.27242215\n",
            "Iteration 687, loss = 0.27231282\n",
            "Iteration 688, loss = 0.27221865\n",
            "Iteration 689, loss = 0.27210638\n",
            "Iteration 690, loss = 0.27200800\n",
            "Iteration 691, loss = 0.27190581\n",
            "Iteration 692, loss = 0.27181448\n",
            "Iteration 693, loss = 0.27170060\n",
            "Iteration 694, loss = 0.27160275\n",
            "Iteration 695, loss = 0.27149771\n",
            "Iteration 696, loss = 0.27139153\n",
            "Iteration 697, loss = 0.27130335\n",
            "Iteration 698, loss = 0.27120675\n",
            "Iteration 699, loss = 0.27110126\n",
            "Iteration 700, loss = 0.27100249\n",
            "Iteration 701, loss = 0.27089883\n",
            "Iteration 702, loss = 0.27079895\n",
            "Iteration 703, loss = 0.27069378\n",
            "Iteration 704, loss = 0.27061601\n",
            "Iteration 705, loss = 0.27049807\n",
            "Iteration 706, loss = 0.27040028\n",
            "Iteration 707, loss = 0.27030579\n",
            "Iteration 708, loss = 0.27019605\n",
            "Iteration 709, loss = 0.27009166\n",
            "Iteration 710, loss = 0.27000164\n",
            "Iteration 711, loss = 0.26989596\n",
            "Iteration 712, loss = 0.26979503\n",
            "Iteration 713, loss = 0.26969981\n",
            "Iteration 714, loss = 0.26960722\n",
            "Iteration 715, loss = 0.26949434\n",
            "Iteration 716, loss = 0.26939597\n",
            "Iteration 717, loss = 0.26930741\n",
            "Iteration 718, loss = 0.26919848\n",
            "Iteration 719, loss = 0.26909935\n",
            "Iteration 720, loss = 0.26900487\n",
            "Iteration 721, loss = 0.26890934\n",
            "Iteration 722, loss = 0.26880544\n",
            "Iteration 723, loss = 0.26870640\n",
            "Iteration 724, loss = 0.26860662\n",
            "Iteration 725, loss = 0.26851388\n",
            "Iteration 726, loss = 0.26841029\n",
            "Iteration 727, loss = 0.26830320\n",
            "Iteration 728, loss = 0.26824374\n",
            "Iteration 729, loss = 0.26811775\n",
            "Iteration 730, loss = 0.26801866\n",
            "Iteration 731, loss = 0.26791752\n",
            "Iteration 732, loss = 0.26781189\n",
            "Iteration 733, loss = 0.26772011\n",
            "Iteration 734, loss = 0.26761702\n",
            "Iteration 735, loss = 0.26752997\n",
            "Iteration 736, loss = 0.26741381\n",
            "Iteration 737, loss = 0.26732351\n",
            "Iteration 738, loss = 0.26724198\n",
            "Iteration 739, loss = 0.26713024\n",
            "Iteration 740, loss = 0.26703960\n",
            "Iteration 741, loss = 0.26694186\n",
            "Iteration 742, loss = 0.26682800\n",
            "Iteration 743, loss = 0.26674445\n",
            "Iteration 744, loss = 0.26663917\n",
            "Iteration 745, loss = 0.26655017\n",
            "Iteration 746, loss = 0.26643686\n",
            "Iteration 747, loss = 0.26634445\n",
            "Iteration 748, loss = 0.26623693\n",
            "Iteration 749, loss = 0.26615936\n",
            "Iteration 750, loss = 0.26605073\n",
            "Iteration 751, loss = 0.26594860\n",
            "Iteration 752, loss = 0.26585472\n",
            "Iteration 753, loss = 0.26576150\n",
            "Iteration 754, loss = 0.26565918\n",
            "Iteration 755, loss = 0.26556679\n",
            "Iteration 756, loss = 0.26547362\n",
            "Iteration 757, loss = 0.26537945\n",
            "Iteration 758, loss = 0.26527256\n",
            "Iteration 759, loss = 0.26517750\n",
            "Iteration 760, loss = 0.26508153\n",
            "Iteration 761, loss = 0.26498008\n",
            "Iteration 762, loss = 0.26487309\n",
            "Iteration 763, loss = 0.26477775\n",
            "Iteration 764, loss = 0.26468321\n",
            "Iteration 765, loss = 0.26459786\n",
            "Iteration 766, loss = 0.26448174\n",
            "Iteration 767, loss = 0.26440373\n",
            "Iteration 768, loss = 0.26430085\n",
            "Iteration 769, loss = 0.26419613\n",
            "Iteration 770, loss = 0.26410361\n",
            "Iteration 771, loss = 0.26402187\n",
            "Iteration 772, loss = 0.26390998\n",
            "Iteration 773, loss = 0.26382390\n",
            "Iteration 774, loss = 0.26371639\n",
            "Iteration 775, loss = 0.26362338\n",
            "Iteration 776, loss = 0.26353475\n",
            "Iteration 777, loss = 0.26342189\n",
            "Iteration 778, loss = 0.26333318\n",
            "Iteration 779, loss = 0.26324286\n",
            "Iteration 780, loss = 0.26314324\n",
            "Iteration 781, loss = 0.26304822\n",
            "Iteration 782, loss = 0.26294394\n",
            "Iteration 783, loss = 0.26285298\n",
            "Iteration 784, loss = 0.26276562\n",
            "Iteration 785, loss = 0.26265485\n",
            "Iteration 786, loss = 0.26256159\n",
            "Iteration 787, loss = 0.26247474\n",
            "Iteration 788, loss = 0.26236361\n",
            "Iteration 789, loss = 0.26228260\n",
            "Iteration 790, loss = 0.26216835\n",
            "Iteration 791, loss = 0.26208163\n",
            "Iteration 792, loss = 0.26198383\n",
            "Iteration 793, loss = 0.26190564\n",
            "Iteration 794, loss = 0.26179035\n",
            "Iteration 795, loss = 0.26169212\n",
            "Iteration 796, loss = 0.26159682\n",
            "Iteration 797, loss = 0.26151810\n",
            "Iteration 798, loss = 0.26141890\n",
            "Iteration 799, loss = 0.26132352\n",
            "Iteration 800, loss = 0.26122787\n",
            "Iteration 801, loss = 0.26112426\n",
            "Iteration 802, loss = 0.26103568\n",
            "Iteration 803, loss = 0.26094447\n",
            "Iteration 804, loss = 0.26085127\n",
            "Iteration 805, loss = 0.26074138\n",
            "Iteration 806, loss = 0.26064926\n",
            "Iteration 807, loss = 0.26055324\n",
            "Iteration 808, loss = 0.26046057\n",
            "Iteration 809, loss = 0.26035923\n",
            "Iteration 810, loss = 0.26026082\n",
            "Iteration 811, loss = 0.26017407\n",
            "Iteration 812, loss = 0.26007787\n",
            "Iteration 813, loss = 0.25999184\n",
            "Iteration 814, loss = 0.25988838\n",
            "Iteration 815, loss = 0.25979087\n",
            "Iteration 816, loss = 0.25969226\n",
            "Iteration 817, loss = 0.25960268\n",
            "Iteration 818, loss = 0.25953449\n",
            "Iteration 819, loss = 0.25942087\n",
            "Iteration 820, loss = 0.25932425\n",
            "Iteration 821, loss = 0.25923287\n",
            "Iteration 822, loss = 0.25914127\n",
            "Iteration 823, loss = 0.25903526\n",
            "Iteration 824, loss = 0.25895034\n",
            "Iteration 825, loss = 0.25885641\n",
            "Iteration 826, loss = 0.25874310\n",
            "Iteration 827, loss = 0.25865234\n",
            "Iteration 828, loss = 0.25856683\n",
            "Iteration 829, loss = 0.25846450\n",
            "Iteration 830, loss = 0.25837720\n",
            "Iteration 831, loss = 0.25828198\n",
            "Iteration 832, loss = 0.25819039\n",
            "Iteration 833, loss = 0.25809359\n",
            "Iteration 834, loss = 0.25801139\n",
            "Iteration 835, loss = 0.25791072\n",
            "Iteration 836, loss = 0.25781678\n",
            "Iteration 837, loss = 0.25772084\n",
            "Iteration 838, loss = 0.25763492\n",
            "Iteration 839, loss = 0.25753222\n",
            "Iteration 840, loss = 0.25744809\n",
            "Iteration 841, loss = 0.25735377\n",
            "Iteration 842, loss = 0.25727863\n",
            "Iteration 843, loss = 0.25716723\n",
            "Iteration 844, loss = 0.25706741\n",
            "Iteration 845, loss = 0.25696885\n",
            "Iteration 846, loss = 0.25688693\n",
            "Iteration 847, loss = 0.25679841\n",
            "Iteration 848, loss = 0.25669957\n",
            "Iteration 849, loss = 0.25661059\n",
            "Iteration 850, loss = 0.25651218\n",
            "Iteration 851, loss = 0.25642386\n",
            "Iteration 852, loss = 0.25632519\n",
            "Iteration 853, loss = 0.25623063\n",
            "Iteration 854, loss = 0.25614956\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.62959754\n",
            "Iteration 2, loss = 0.53952625\n",
            "Iteration 3, loss = 0.47892758\n",
            "Iteration 4, loss = 0.44377076\n",
            "Iteration 5, loss = 0.41928145\n",
            "Iteration 6, loss = 0.40499944\n",
            "Iteration 7, loss = 0.39393944\n",
            "Iteration 8, loss = 0.38533045\n",
            "Iteration 9, loss = 0.37779687\n",
            "Iteration 10, loss = 0.37145986\n",
            "Iteration 11, loss = 0.36606655\n",
            "Iteration 12, loss = 0.36087217\n",
            "Iteration 13, loss = 0.35616361\n",
            "Iteration 14, loss = 0.35190400\n",
            "Iteration 15, loss = 0.34819699\n",
            "Iteration 16, loss = 0.34432787\n",
            "Iteration 17, loss = 0.34087824\n",
            "Iteration 18, loss = 0.33742631\n",
            "Iteration 19, loss = 0.33429276\n",
            "Iteration 20, loss = 0.33124730\n",
            "Iteration 21, loss = 0.32838130\n",
            "Iteration 22, loss = 0.32560537\n",
            "Iteration 23, loss = 0.32310180\n",
            "Iteration 24, loss = 0.32063580\n",
            "Iteration 25, loss = 0.31791660\n",
            "Iteration 26, loss = 0.31586949\n",
            "Iteration 27, loss = 0.31329018\n",
            "Iteration 28, loss = 0.31103861\n",
            "Iteration 29, loss = 0.30894613\n",
            "Iteration 30, loss = 0.30662097\n",
            "Iteration 31, loss = 0.30443971\n",
            "Iteration 32, loss = 0.30228424\n",
            "Iteration 33, loss = 0.30003455\n",
            "Iteration 34, loss = 0.29797650\n",
            "Iteration 35, loss = 0.29606116\n",
            "Iteration 36, loss = 0.29384542\n",
            "Iteration 37, loss = 0.29185048\n",
            "Iteration 38, loss = 0.28975996\n",
            "Iteration 39, loss = 0.28803510\n",
            "Iteration 40, loss = 0.28585209\n",
            "Iteration 41, loss = 0.28387481\n",
            "Iteration 42, loss = 0.28193455\n",
            "Iteration 43, loss = 0.28006195\n",
            "Iteration 44, loss = 0.27813089\n",
            "Iteration 45, loss = 0.27619143\n",
            "Iteration 46, loss = 0.27431318\n",
            "Iteration 47, loss = 0.27273890\n",
            "Iteration 48, loss = 0.27058529\n",
            "Iteration 49, loss = 0.26868219\n",
            "Iteration 50, loss = 0.26670594\n",
            "Iteration 51, loss = 0.26498527\n",
            "Iteration 52, loss = 0.26309699\n",
            "Iteration 53, loss = 0.26130969\n",
            "Iteration 54, loss = 0.25943894\n",
            "Iteration 55, loss = 0.25742558\n",
            "Iteration 56, loss = 0.25572786\n",
            "Iteration 57, loss = 0.25384791\n",
            "Iteration 58, loss = 0.25199777\n",
            "Iteration 59, loss = 0.25036765\n",
            "Iteration 60, loss = 0.24838419\n",
            "Iteration 61, loss = 0.24656498\n",
            "Iteration 62, loss = 0.24507624\n",
            "Iteration 63, loss = 0.24299872\n",
            "Iteration 64, loss = 0.24164761\n",
            "Iteration 65, loss = 0.23981565\n",
            "Iteration 66, loss = 0.23794360\n",
            "Iteration 67, loss = 0.23628795\n",
            "Iteration 68, loss = 0.23467184\n",
            "Iteration 69, loss = 0.23318903\n",
            "Iteration 70, loss = 0.23108341\n",
            "Iteration 71, loss = 0.22946826\n",
            "Iteration 72, loss = 0.22816095\n",
            "Iteration 73, loss = 0.22600579\n",
            "Iteration 74, loss = 0.22440233\n",
            "Iteration 75, loss = 0.22272730\n",
            "Iteration 76, loss = 0.22117603\n",
            "Iteration 77, loss = 0.21964373\n",
            "Iteration 78, loss = 0.21780397\n",
            "Iteration 79, loss = 0.21644689\n",
            "Iteration 80, loss = 0.21466657\n",
            "Iteration 81, loss = 0.21300877\n",
            "Iteration 82, loss = 0.21171950\n",
            "Iteration 83, loss = 0.21001794\n",
            "Iteration 84, loss = 0.20874980\n",
            "Iteration 85, loss = 0.20716319\n",
            "Iteration 86, loss = 0.20558424\n",
            "Iteration 87, loss = 0.20458670\n",
            "Iteration 88, loss = 0.20268742\n",
            "Iteration 89, loss = 0.20110676\n",
            "Iteration 90, loss = 0.19982452\n",
            "Iteration 91, loss = 0.19848887\n",
            "Iteration 92, loss = 0.19690162\n",
            "Iteration 93, loss = 0.19537308\n",
            "Iteration 94, loss = 0.19411287\n",
            "Iteration 95, loss = 0.19267442\n",
            "Iteration 96, loss = 0.19141882\n",
            "Iteration 97, loss = 0.18998012\n",
            "Iteration 98, loss = 0.18882948\n",
            "Iteration 99, loss = 0.18725691\n",
            "Iteration 100, loss = 0.18612877\n",
            "Iteration 101, loss = 0.18464774\n",
            "Iteration 102, loss = 0.18356836\n",
            "Iteration 103, loss = 0.18215020\n",
            "Iteration 104, loss = 0.18090994\n",
            "Iteration 105, loss = 0.17976006\n",
            "Iteration 106, loss = 0.17867433\n",
            "Iteration 107, loss = 0.17755169\n",
            "Iteration 108, loss = 0.17578867\n",
            "Iteration 109, loss = 0.17474539\n",
            "Iteration 110, loss = 0.17355683\n",
            "Iteration 111, loss = 0.17240857\n",
            "Iteration 112, loss = 0.17142543\n",
            "Iteration 113, loss = 0.17011660\n",
            "Iteration 114, loss = 0.16917154\n",
            "Iteration 115, loss = 0.16789857\n",
            "Iteration 116, loss = 0.16657801\n",
            "Iteration 117, loss = 0.16553609\n",
            "Iteration 118, loss = 0.16450032\n",
            "Iteration 119, loss = 0.16358809\n",
            "Iteration 120, loss = 0.16252555\n",
            "Iteration 121, loss = 0.16114256\n",
            "Iteration 122, loss = 0.15995732\n",
            "Iteration 123, loss = 0.15902073\n",
            "Iteration 124, loss = 0.15807699\n",
            "Iteration 125, loss = 0.15720318\n",
            "Iteration 126, loss = 0.15624832\n",
            "Iteration 127, loss = 0.15511234\n",
            "Iteration 128, loss = 0.15362206\n",
            "Iteration 129, loss = 0.15261980\n",
            "Iteration 130, loss = 0.15153528\n",
            "Iteration 131, loss = 0.15075220\n",
            "Iteration 132, loss = 0.14968527\n",
            "Iteration 133, loss = 0.14872446\n",
            "Iteration 134, loss = 0.14772272\n",
            "Iteration 135, loss = 0.14674887\n",
            "Iteration 136, loss = 0.14565531\n",
            "Iteration 137, loss = 0.14493673\n",
            "Iteration 138, loss = 0.14394716\n",
            "Iteration 139, loss = 0.14274588\n",
            "Iteration 140, loss = 0.14217888\n",
            "Iteration 141, loss = 0.14102256\n",
            "Iteration 142, loss = 0.14042456\n",
            "Iteration 143, loss = 0.13922399\n",
            "Iteration 144, loss = 0.13831754\n",
            "Iteration 145, loss = 0.13761723\n",
            "Iteration 146, loss = 0.13670835\n",
            "Iteration 147, loss = 0.13566722\n",
            "Iteration 148, loss = 0.13453929\n",
            "Iteration 149, loss = 0.13391314\n",
            "Iteration 150, loss = 0.13298282\n",
            "Iteration 151, loss = 0.13197307\n",
            "Iteration 152, loss = 0.13092403\n",
            "Iteration 153, loss = 0.13028302\n",
            "Iteration 154, loss = 0.12925474\n",
            "Iteration 155, loss = 0.12849729\n",
            "Iteration 156, loss = 0.12766066\n",
            "Iteration 157, loss = 0.12663437\n",
            "Iteration 158, loss = 0.12600295\n",
            "Iteration 159, loss = 0.12527381\n",
            "Iteration 160, loss = 0.12410585\n",
            "Iteration 161, loss = 0.12349999\n",
            "Iteration 162, loss = 0.12269817\n",
            "Iteration 163, loss = 0.12170559\n",
            "Iteration 164, loss = 0.12094293\n",
            "Iteration 165, loss = 0.12007701\n",
            "Iteration 166, loss = 0.11951661\n",
            "Iteration 167, loss = 0.11846014\n",
            "Iteration 168, loss = 0.11776491\n",
            "Iteration 169, loss = 0.11721278\n",
            "Iteration 170, loss = 0.11613667\n",
            "Iteration 171, loss = 0.11553618\n",
            "Iteration 172, loss = 0.11445369\n",
            "Iteration 173, loss = 0.11385215\n",
            "Iteration 174, loss = 0.11311607\n",
            "Iteration 175, loss = 0.11237408\n",
            "Iteration 176, loss = 0.11165195\n",
            "Iteration 177, loss = 0.11061550\n",
            "Iteration 178, loss = 0.10987666\n",
            "Iteration 179, loss = 0.10926122\n",
            "Iteration 180, loss = 0.10842129\n",
            "Iteration 181, loss = 0.10776236\n",
            "Iteration 182, loss = 0.10701224\n",
            "Iteration 183, loss = 0.10676741\n",
            "Iteration 184, loss = 0.10554818\n",
            "Iteration 185, loss = 0.10484195\n",
            "Iteration 186, loss = 0.10413717\n",
            "Iteration 187, loss = 0.10354705\n",
            "Iteration 188, loss = 0.10286868\n",
            "Iteration 189, loss = 0.10197811\n",
            "Iteration 190, loss = 0.10146593\n",
            "Iteration 191, loss = 0.10081346\n",
            "Iteration 192, loss = 0.10018470\n",
            "Iteration 193, loss = 0.09941555\n",
            "Iteration 194, loss = 0.09886431\n",
            "Iteration 195, loss = 0.09819978\n",
            "Iteration 196, loss = 0.09779112\n",
            "Iteration 197, loss = 0.09703197\n",
            "Iteration 198, loss = 0.09614490\n",
            "Iteration 199, loss = 0.09546820\n",
            "Iteration 200, loss = 0.09478813\n",
            "Iteration 201, loss = 0.09413466\n",
            "Iteration 202, loss = 0.09345496\n",
            "Iteration 203, loss = 0.09284240\n",
            "Iteration 204, loss = 0.09305546\n",
            "Iteration 205, loss = 0.09204853\n",
            "Iteration 206, loss = 0.09143185\n",
            "Iteration 207, loss = 0.09058541\n",
            "Iteration 208, loss = 0.08997407\n",
            "Iteration 209, loss = 0.08949258\n",
            "Iteration 210, loss = 0.08876304\n",
            "Iteration 211, loss = 0.08806308\n",
            "Iteration 212, loss = 0.08775861\n",
            "Iteration 213, loss = 0.08693472\n",
            "Iteration 214, loss = 0.08640287\n",
            "Iteration 215, loss = 0.08586395\n",
            "Iteration 216, loss = 0.08519291\n",
            "Iteration 217, loss = 0.08492530\n",
            "Iteration 218, loss = 0.08418425\n",
            "Iteration 219, loss = 0.08380810\n",
            "Iteration 220, loss = 0.08322364\n",
            "Iteration 221, loss = 0.08251694\n",
            "Iteration 222, loss = 0.08215096\n",
            "Iteration 223, loss = 0.08160954\n",
            "Iteration 224, loss = 0.08078548\n",
            "Iteration 225, loss = 0.08053788\n",
            "Iteration 226, loss = 0.07971263\n",
            "Iteration 227, loss = 0.07925438\n",
            "Iteration 228, loss = 0.07868887\n",
            "Iteration 229, loss = 0.07848570\n",
            "Iteration 230, loss = 0.07791924\n",
            "Iteration 231, loss = 0.07723841\n",
            "Iteration 232, loss = 0.07664552\n",
            "Iteration 233, loss = 0.07623323\n",
            "Iteration 234, loss = 0.07555409\n",
            "Iteration 235, loss = 0.07530891\n",
            "Iteration 236, loss = 0.07462686\n",
            "Iteration 237, loss = 0.07413093\n",
            "Iteration 238, loss = 0.07336611\n",
            "Iteration 239, loss = 0.07314117\n",
            "Iteration 240, loss = 0.07258909\n",
            "Iteration 241, loss = 0.07202677\n",
            "Iteration 242, loss = 0.07156297\n",
            "Iteration 243, loss = 0.07121161\n",
            "Iteration 244, loss = 0.07062436\n",
            "Iteration 245, loss = 0.06996281\n",
            "Iteration 246, loss = 0.06949106\n",
            "Iteration 247, loss = 0.06921251\n",
            "Iteration 248, loss = 0.06873192\n",
            "Iteration 249, loss = 0.06825248\n",
            "Iteration 250, loss = 0.06791103\n",
            "Iteration 251, loss = 0.06735629\n",
            "Iteration 252, loss = 0.06736164\n",
            "Iteration 253, loss = 0.06633991\n",
            "Iteration 254, loss = 0.06629054\n",
            "Iteration 255, loss = 0.06555760\n",
            "Iteration 256, loss = 0.06551729\n",
            "Iteration 257, loss = 0.06519383\n",
            "Iteration 258, loss = 0.06432327\n",
            "Iteration 259, loss = 0.06395596\n",
            "Iteration 260, loss = 0.06326296\n",
            "Iteration 261, loss = 0.06297959\n",
            "Iteration 262, loss = 0.06254655\n",
            "Iteration 263, loss = 0.06206514\n",
            "Iteration 264, loss = 0.06164545\n",
            "Iteration 265, loss = 0.06104827\n",
            "Iteration 266, loss = 0.06088795\n",
            "Iteration 267, loss = 0.06028118\n",
            "Iteration 268, loss = 0.05989775\n",
            "Iteration 269, loss = 0.05955850\n",
            "Iteration 270, loss = 0.05930380\n",
            "Iteration 271, loss = 0.05877683\n",
            "Iteration 272, loss = 0.05842533\n",
            "Iteration 273, loss = 0.05795961\n",
            "Iteration 274, loss = 0.05755975\n",
            "Iteration 275, loss = 0.05715609\n",
            "Iteration 276, loss = 0.05675089\n",
            "Iteration 277, loss = 0.05640908\n",
            "Iteration 278, loss = 0.05621314\n",
            "Iteration 279, loss = 0.05586888\n",
            "Iteration 280, loss = 0.05526990\n",
            "Iteration 281, loss = 0.05488395\n",
            "Iteration 282, loss = 0.05464482\n",
            "Iteration 283, loss = 0.05407991\n",
            "Iteration 284, loss = 0.05373356\n",
            "Iteration 285, loss = 0.05347667\n",
            "Iteration 286, loss = 0.05318893\n",
            "Iteration 287, loss = 0.05275311\n",
            "Iteration 288, loss = 0.05240669\n",
            "Iteration 289, loss = 0.05218023\n",
            "Iteration 290, loss = 0.05183527\n",
            "Iteration 291, loss = 0.05127712\n",
            "Iteration 292, loss = 0.05098162\n",
            "Iteration 293, loss = 0.05050912\n",
            "Iteration 294, loss = 0.05027148\n",
            "Iteration 295, loss = 0.04986592\n",
            "Iteration 296, loss = 0.04943241\n",
            "Iteration 297, loss = 0.04911445\n",
            "Iteration 298, loss = 0.04869257\n",
            "Iteration 299, loss = 0.04836085\n",
            "Iteration 300, loss = 0.04819826\n",
            "Iteration 301, loss = 0.04799769\n",
            "Iteration 302, loss = 0.04763148\n",
            "Iteration 303, loss = 0.04765532\n",
            "Iteration 304, loss = 0.04686400\n",
            "Iteration 305, loss = 0.04660546\n",
            "Iteration 306, loss = 0.04612156\n",
            "Iteration 307, loss = 0.04581539\n",
            "Iteration 308, loss = 0.04552582\n",
            "Iteration 309, loss = 0.04512975\n",
            "Iteration 310, loss = 0.04488724\n",
            "Iteration 311, loss = 0.04469563\n",
            "Iteration 312, loss = 0.04432591\n",
            "Iteration 313, loss = 0.04392306\n",
            "Iteration 314, loss = 0.04382931\n",
            "Iteration 315, loss = 0.04341576\n",
            "Iteration 316, loss = 0.04311690\n",
            "Iteration 317, loss = 0.04273682\n",
            "Iteration 318, loss = 0.04242516\n",
            "Iteration 319, loss = 0.04214176\n",
            "Iteration 320, loss = 0.04208753\n",
            "Iteration 321, loss = 0.04170541\n",
            "Iteration 322, loss = 0.04134451\n",
            "Iteration 323, loss = 0.04125069\n",
            "Iteration 324, loss = 0.04108718\n",
            "Iteration 325, loss = 0.04042404\n",
            "Iteration 326, loss = 0.04024970\n",
            "Iteration 327, loss = 0.03995899\n",
            "Iteration 328, loss = 0.03963358\n",
            "Iteration 329, loss = 0.03954912\n",
            "Iteration 330, loss = 0.03922389\n",
            "Iteration 331, loss = 0.03911195\n",
            "Iteration 332, loss = 0.03875734\n",
            "Iteration 333, loss = 0.03834752\n",
            "Iteration 334, loss = 0.03824257\n",
            "Iteration 335, loss = 0.03794129\n",
            "Iteration 336, loss = 0.03775683\n",
            "Iteration 337, loss = 0.03748770\n",
            "Iteration 338, loss = 0.03738556\n",
            "Iteration 339, loss = 0.03708060\n",
            "Iteration 340, loss = 0.03665678\n",
            "Iteration 341, loss = 0.03642008\n",
            "Iteration 342, loss = 0.03621473\n",
            "Iteration 343, loss = 0.03591978\n",
            "Iteration 344, loss = 0.03566630\n",
            "Iteration 345, loss = 0.03545188\n",
            "Iteration 346, loss = 0.03525828\n",
            "Iteration 347, loss = 0.03507708\n",
            "Iteration 348, loss = 0.03483803\n",
            "Iteration 349, loss = 0.03459900\n",
            "Iteration 350, loss = 0.03435726\n",
            "Iteration 351, loss = 0.03420863\n",
            "Iteration 352, loss = 0.03406819\n",
            "Iteration 353, loss = 0.03376001\n",
            "Iteration 354, loss = 0.03347042\n",
            "Iteration 355, loss = 0.03318921\n",
            "Iteration 356, loss = 0.03304285\n",
            "Iteration 357, loss = 0.03288940\n",
            "Iteration 358, loss = 0.03264453\n",
            "Iteration 359, loss = 0.03244179\n",
            "Iteration 360, loss = 0.03226394\n",
            "Iteration 361, loss = 0.03201480\n",
            "Iteration 362, loss = 0.03166730\n",
            "Iteration 363, loss = 0.03147660\n",
            "Iteration 364, loss = 0.03150246\n",
            "Iteration 365, loss = 0.03114202\n",
            "Iteration 366, loss = 0.03091301\n",
            "Iteration 367, loss = 0.03073446\n",
            "Iteration 368, loss = 0.03058937\n",
            "Iteration 369, loss = 0.03028508\n",
            "Iteration 370, loss = 0.03027258\n",
            "Iteration 371, loss = 0.03009388\n",
            "Iteration 372, loss = 0.02968590\n",
            "Iteration 373, loss = 0.02969910\n",
            "Iteration 374, loss = 0.02936475\n",
            "Iteration 375, loss = 0.02926951\n",
            "Iteration 376, loss = 0.02903145\n",
            "Iteration 377, loss = 0.02902756\n",
            "Iteration 378, loss = 0.02868272\n",
            "Iteration 379, loss = 0.02844016\n",
            "Iteration 380, loss = 0.02824799\n",
            "Iteration 381, loss = 0.02813810\n",
            "Iteration 382, loss = 0.02791730\n",
            "Iteration 383, loss = 0.02769367\n",
            "Iteration 384, loss = 0.02753713\n",
            "Iteration 385, loss = 0.02742909\n",
            "Iteration 386, loss = 0.02723676\n",
            "Iteration 387, loss = 0.02704490\n",
            "Iteration 388, loss = 0.02682704\n",
            "Iteration 389, loss = 0.02676478\n",
            "Iteration 390, loss = 0.02644325\n",
            "Iteration 391, loss = 0.02647402\n",
            "Iteration 392, loss = 0.02619949\n",
            "Iteration 393, loss = 0.02613660\n",
            "Iteration 394, loss = 0.02587784\n",
            "Iteration 395, loss = 0.02583045\n",
            "Iteration 396, loss = 0.02563330\n",
            "Iteration 397, loss = 0.02536523\n",
            "Iteration 398, loss = 0.02522508\n",
            "Iteration 399, loss = 0.02516536\n",
            "Iteration 400, loss = 0.02483174\n",
            "Iteration 401, loss = 0.02474102\n",
            "Iteration 402, loss = 0.02461722\n",
            "Iteration 403, loss = 0.02459560\n",
            "Iteration 404, loss = 0.02421566\n",
            "Iteration 405, loss = 0.02413264\n",
            "Iteration 406, loss = 0.02397730\n",
            "Iteration 407, loss = 0.02387900\n",
            "Iteration 408, loss = 0.02372950\n",
            "Iteration 409, loss = 0.02354775\n",
            "Iteration 410, loss = 0.02339973\n",
            "Iteration 411, loss = 0.02328002\n",
            "Iteration 412, loss = 0.02310063\n",
            "Iteration 413, loss = 0.02307174\n",
            "Iteration 414, loss = 0.02285407\n",
            "Iteration 415, loss = 0.02265876\n",
            "Iteration 416, loss = 0.02262198\n",
            "Iteration 417, loss = 0.02245776\n",
            "Iteration 418, loss = 0.02234791\n",
            "Iteration 419, loss = 0.02220263\n",
            "Iteration 420, loss = 0.02208222\n",
            "Iteration 421, loss = 0.02184515\n",
            "Iteration 422, loss = 0.02185540\n",
            "Iteration 423, loss = 0.02170856\n",
            "Iteration 424, loss = 0.02156117\n",
            "Iteration 425, loss = 0.02133778\n",
            "Iteration 426, loss = 0.02117531\n",
            "Iteration 427, loss = 0.02107386\n",
            "Iteration 428, loss = 0.02095589\n",
            "Iteration 429, loss = 0.02081541\n",
            "Iteration 430, loss = 0.02063938\n",
            "Iteration 431, loss = 0.02071732\n",
            "Iteration 432, loss = 0.02057974\n",
            "Iteration 433, loss = 0.02033303\n",
            "Iteration 434, loss = 0.02031589\n",
            "Iteration 435, loss = 0.02003704\n",
            "Iteration 436, loss = 0.02013988\n",
            "Iteration 437, loss = 0.01979789\n",
            "Iteration 438, loss = 0.01975754\n",
            "Iteration 439, loss = 0.01968535\n",
            "Iteration 440, loss = 0.01949019\n",
            "Iteration 441, loss = 0.01939135\n",
            "Iteration 442, loss = 0.01925601\n",
            "Iteration 443, loss = 0.01912239\n",
            "Iteration 444, loss = 0.01896868\n",
            "Iteration 445, loss = 0.01894847\n",
            "Iteration 446, loss = 0.01892168\n",
            "Iteration 447, loss = 0.01870823\n",
            "Iteration 448, loss = 0.01858065\n",
            "Iteration 449, loss = 0.01845954\n",
            "Iteration 450, loss = 0.01839537\n",
            "Iteration 451, loss = 0.01828979\n",
            "Iteration 452, loss = 0.01821305\n",
            "Iteration 453, loss = 0.01805637\n",
            "Iteration 454, loss = 0.01795619\n",
            "Iteration 455, loss = 0.01784564\n",
            "Iteration 456, loss = 0.01776697\n",
            "Iteration 457, loss = 0.01766877\n",
            "Iteration 458, loss = 0.01752247\n",
            "Iteration 459, loss = 0.01746312\n",
            "Iteration 460, loss = 0.01726383\n",
            "Iteration 461, loss = 0.01725026\n",
            "Iteration 462, loss = 0.01710189\n",
            "Iteration 463, loss = 0.01700947\n",
            "Iteration 464, loss = 0.01691261\n",
            "Iteration 465, loss = 0.01682330\n",
            "Iteration 466, loss = 0.01677673\n",
            "Iteration 467, loss = 0.01658589\n",
            "Iteration 468, loss = 0.01649918\n",
            "Iteration 469, loss = 0.01638417\n",
            "Iteration 470, loss = 0.01631536\n",
            "Iteration 471, loss = 0.01633442\n",
            "Iteration 472, loss = 0.01620348\n",
            "Iteration 473, loss = 0.01611753\n",
            "Iteration 474, loss = 0.01605319\n",
            "Iteration 475, loss = 0.01589529\n",
            "Iteration 476, loss = 0.01582754\n",
            "Iteration 477, loss = 0.01563329\n",
            "Iteration 478, loss = 0.01554498\n",
            "Iteration 479, loss = 0.01551882\n",
            "Iteration 480, loss = 0.01537343\n",
            "Iteration 481, loss = 0.01531899\n",
            "Iteration 482, loss = 0.01515503\n",
            "Iteration 483, loss = 0.01520478\n",
            "Iteration 484, loss = 0.01507318\n",
            "Iteration 485, loss = 0.01499004\n",
            "Iteration 486, loss = 0.01493974\n",
            "Iteration 487, loss = 0.01493361\n",
            "Iteration 488, loss = 0.01468912\n",
            "Iteration 489, loss = 0.01464942\n",
            "Iteration 490, loss = 0.01450964\n",
            "Iteration 491, loss = 0.01445055\n",
            "Iteration 492, loss = 0.01436405\n",
            "Iteration 493, loss = 0.01431823\n",
            "Iteration 494, loss = 0.01424293\n",
            "Iteration 495, loss = 0.01411352\n",
            "Iteration 496, loss = 0.01403716\n",
            "Iteration 497, loss = 0.01393298\n",
            "Iteration 498, loss = 0.01386699\n",
            "Iteration 499, loss = 0.01377728\n",
            "Iteration 500, loss = 0.01365580\n",
            "Iteration 501, loss = 0.01366309\n",
            "Iteration 502, loss = 0.01353909\n",
            "Iteration 503, loss = 0.01344087\n",
            "Iteration 504, loss = 0.01349425\n",
            "Iteration 505, loss = 0.01327984\n",
            "Iteration 506, loss = 0.01325393\n",
            "Iteration 507, loss = 0.01314243\n",
            "Iteration 508, loss = 0.01317534\n",
            "Iteration 509, loss = 0.01304273\n",
            "Iteration 510, loss = 0.01297052\n",
            "Iteration 511, loss = 0.01286910\n",
            "Iteration 512, loss = 0.01283950\n",
            "Iteration 513, loss = 0.01274327\n",
            "Iteration 514, loss = 0.01267651\n",
            "Iteration 515, loss = 0.01255615\n",
            "Iteration 516, loss = 0.01248808\n",
            "Iteration 517, loss = 0.01245516\n",
            "Iteration 518, loss = 0.01233743\n",
            "Iteration 519, loss = 0.01228684\n",
            "Iteration 520, loss = 0.01222402\n",
            "Iteration 521, loss = 0.01216115\n",
            "Iteration 522, loss = 0.01212145\n",
            "Iteration 523, loss = 0.01201469\n",
            "Iteration 524, loss = 0.01193770\n",
            "Iteration 525, loss = 0.01189022\n",
            "Iteration 526, loss = 0.01188249\n",
            "Iteration 527, loss = 0.01185703\n",
            "Iteration 528, loss = 0.01168802\n",
            "Iteration 529, loss = 0.01163831\n",
            "Iteration 530, loss = 0.01157011\n",
            "Iteration 531, loss = 0.01148058\n",
            "Iteration 532, loss = 0.01142797\n",
            "Iteration 533, loss = 0.01135865\n",
            "Iteration 534, loss = 0.01131757\n",
            "Iteration 535, loss = 0.01122930\n",
            "Iteration 536, loss = 0.01119900\n",
            "Iteration 537, loss = 0.01113468\n",
            "Iteration 538, loss = 0.01108363\n",
            "Iteration 539, loss = 0.01107871\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.71475192\n",
            "Iteration 2, loss = 0.60002046\n",
            "Iteration 3, loss = 0.52221466\n",
            "Iteration 4, loss = 0.47270868\n",
            "Iteration 5, loss = 0.43925411\n",
            "Iteration 6, loss = 0.41762035\n",
            "Iteration 7, loss = 0.40378186\n",
            "Iteration 8, loss = 0.39259902\n",
            "Iteration 9, loss = 0.38350451\n",
            "Iteration 10, loss = 0.37589379\n",
            "Iteration 11, loss = 0.36960539\n",
            "Iteration 12, loss = 0.36404830\n",
            "Iteration 13, loss = 0.35871039\n",
            "Iteration 14, loss = 0.35415398\n",
            "Iteration 15, loss = 0.35026156\n",
            "Iteration 16, loss = 0.34622695\n",
            "Iteration 17, loss = 0.34267421\n",
            "Iteration 18, loss = 0.33944997\n",
            "Iteration 19, loss = 0.33617160\n",
            "Iteration 20, loss = 0.33337600\n",
            "Iteration 21, loss = 0.33050339\n",
            "Iteration 22, loss = 0.32778280\n",
            "Iteration 23, loss = 0.32492711\n",
            "Iteration 24, loss = 0.32250117\n",
            "Iteration 25, loss = 0.31997743\n",
            "Iteration 26, loss = 0.31758797\n",
            "Iteration 27, loss = 0.31567827\n",
            "Iteration 28, loss = 0.31322435\n",
            "Iteration 29, loss = 0.31078117\n",
            "Iteration 30, loss = 0.30849334\n",
            "Iteration 31, loss = 0.30642993\n",
            "Iteration 32, loss = 0.30430342\n",
            "Iteration 33, loss = 0.30231634\n",
            "Iteration 34, loss = 0.30021037\n",
            "Iteration 35, loss = 0.29824505\n",
            "Iteration 36, loss = 0.29636297\n",
            "Iteration 37, loss = 0.29452798\n",
            "Iteration 38, loss = 0.29267757\n",
            "Iteration 39, loss = 0.29084946\n",
            "Iteration 40, loss = 0.28928052\n",
            "Iteration 41, loss = 0.28740323\n",
            "Iteration 42, loss = 0.28549830\n",
            "Iteration 43, loss = 0.28403626\n",
            "Iteration 44, loss = 0.28219440\n",
            "Iteration 45, loss = 0.28082377\n",
            "Iteration 46, loss = 0.27923778\n",
            "Iteration 47, loss = 0.27733533\n",
            "Iteration 48, loss = 0.27563695\n",
            "Iteration 49, loss = 0.27408283\n",
            "Iteration 50, loss = 0.27266562\n",
            "Iteration 51, loss = 0.27104734\n",
            "Iteration 52, loss = 0.26967592\n",
            "Iteration 53, loss = 0.26783380\n",
            "Iteration 54, loss = 0.26641521\n",
            "Iteration 55, loss = 0.26495127\n",
            "Iteration 56, loss = 0.26351920\n",
            "Iteration 57, loss = 0.26195368\n",
            "Iteration 58, loss = 0.26042290\n",
            "Iteration 59, loss = 0.25918812\n",
            "Iteration 60, loss = 0.25841412\n",
            "Iteration 61, loss = 0.25604749\n",
            "Iteration 62, loss = 0.25472405\n",
            "Iteration 63, loss = 0.25321243\n",
            "Iteration 64, loss = 0.25179275\n",
            "Iteration 65, loss = 0.25033339\n",
            "Iteration 66, loss = 0.24896414\n",
            "Iteration 67, loss = 0.24759343\n",
            "Iteration 68, loss = 0.24606874\n",
            "Iteration 69, loss = 0.24487349\n",
            "Iteration 70, loss = 0.24350552\n",
            "Iteration 71, loss = 0.24243235\n",
            "Iteration 72, loss = 0.24061167\n",
            "Iteration 73, loss = 0.23922988\n",
            "Iteration 74, loss = 0.23797131\n",
            "Iteration 75, loss = 0.23627392\n",
            "Iteration 76, loss = 0.23522705\n",
            "Iteration 77, loss = 0.23416541\n",
            "Iteration 78, loss = 0.23222510\n",
            "Iteration 79, loss = 0.23105066\n",
            "Iteration 80, loss = 0.22976867\n",
            "Iteration 81, loss = 0.22835784\n",
            "Iteration 82, loss = 0.22686492\n",
            "Iteration 83, loss = 0.22586055\n",
            "Iteration 84, loss = 0.22438987\n",
            "Iteration 85, loss = 0.22306833\n",
            "Iteration 86, loss = 0.22204490\n",
            "Iteration 87, loss = 0.22076736\n",
            "Iteration 88, loss = 0.21941110\n",
            "Iteration 89, loss = 0.21827025\n",
            "Iteration 90, loss = 0.21701322\n",
            "Iteration 91, loss = 0.21568276\n",
            "Iteration 92, loss = 0.21444697\n",
            "Iteration 93, loss = 0.21307600\n",
            "Iteration 94, loss = 0.21196203\n",
            "Iteration 95, loss = 0.21077298\n",
            "Iteration 96, loss = 0.20985110\n",
            "Iteration 97, loss = 0.20935465\n",
            "Iteration 98, loss = 0.20781913\n",
            "Iteration 99, loss = 0.20630718\n",
            "Iteration 100, loss = 0.20503241\n",
            "Iteration 101, loss = 0.20362574\n",
            "Iteration 102, loss = 0.20279077\n",
            "Iteration 103, loss = 0.20138579\n",
            "Iteration 104, loss = 0.20015020\n",
            "Iteration 105, loss = 0.19923505\n",
            "Iteration 106, loss = 0.19805969\n",
            "Iteration 107, loss = 0.19697701\n",
            "Iteration 108, loss = 0.19570638\n",
            "Iteration 109, loss = 0.19456095\n",
            "Iteration 110, loss = 0.19353305\n",
            "Iteration 111, loss = 0.19229123\n",
            "Iteration 112, loss = 0.19101077\n",
            "Iteration 113, loss = 0.19032149\n",
            "Iteration 114, loss = 0.18907435\n",
            "Iteration 115, loss = 0.18802582\n",
            "Iteration 116, loss = 0.18706921\n",
            "Iteration 117, loss = 0.18557408\n",
            "Iteration 118, loss = 0.18507299\n",
            "Iteration 119, loss = 0.18354719\n",
            "Iteration 120, loss = 0.18259079\n",
            "Iteration 121, loss = 0.18160621\n",
            "Iteration 122, loss = 0.18042218\n",
            "Iteration 123, loss = 0.17982973\n",
            "Iteration 124, loss = 0.17829980\n",
            "Iteration 125, loss = 0.17756606\n",
            "Iteration 126, loss = 0.17637186\n",
            "Iteration 127, loss = 0.17555333\n",
            "Iteration 128, loss = 0.17446733\n",
            "Iteration 129, loss = 0.17344199\n",
            "Iteration 130, loss = 0.17253747\n",
            "Iteration 131, loss = 0.17159552\n",
            "Iteration 132, loss = 0.17108499\n",
            "Iteration 133, loss = 0.16939643\n",
            "Iteration 134, loss = 0.16865379\n",
            "Iteration 135, loss = 0.16827322\n",
            "Iteration 136, loss = 0.16675992\n",
            "Iteration 137, loss = 0.16575952\n",
            "Iteration 138, loss = 0.16473200\n",
            "Iteration 139, loss = 0.16382186\n",
            "Iteration 140, loss = 0.16290747\n",
            "Iteration 141, loss = 0.16216928\n",
            "Iteration 142, loss = 0.16152611\n",
            "Iteration 143, loss = 0.16066836\n",
            "Iteration 144, loss = 0.15918002\n",
            "Iteration 145, loss = 0.15859078\n",
            "Iteration 146, loss = 0.15770361\n",
            "Iteration 147, loss = 0.15679798\n",
            "Iteration 148, loss = 0.15625966\n",
            "Iteration 149, loss = 0.15502439\n",
            "Iteration 150, loss = 0.15413708\n",
            "Iteration 151, loss = 0.15301388\n",
            "Iteration 152, loss = 0.15217897\n",
            "Iteration 153, loss = 0.15138164\n",
            "Iteration 154, loss = 0.15059760\n",
            "Iteration 155, loss = 0.14989034\n",
            "Iteration 156, loss = 0.14865980\n",
            "Iteration 157, loss = 0.14820097\n",
            "Iteration 158, loss = 0.14708358\n",
            "Iteration 159, loss = 0.14631561\n",
            "Iteration 160, loss = 0.14529686\n",
            "Iteration 161, loss = 0.14495866\n",
            "Iteration 162, loss = 0.14377127\n",
            "Iteration 163, loss = 0.14279748\n",
            "Iteration 164, loss = 0.14246510\n",
            "Iteration 165, loss = 0.14273838\n",
            "Iteration 166, loss = 0.14040467\n",
            "Iteration 167, loss = 0.14030422\n",
            "Iteration 168, loss = 0.13938125\n",
            "Iteration 169, loss = 0.13831722\n",
            "Iteration 170, loss = 0.13753138\n",
            "Iteration 171, loss = 0.13682282\n",
            "Iteration 172, loss = 0.13582539\n",
            "Iteration 173, loss = 0.13488099\n",
            "Iteration 174, loss = 0.13415007\n",
            "Iteration 175, loss = 0.13373157\n",
            "Iteration 176, loss = 0.13271637\n",
            "Iteration 177, loss = 0.13205555\n",
            "Iteration 178, loss = 0.13091905\n",
            "Iteration 179, loss = 0.13021841\n",
            "Iteration 180, loss = 0.12990099\n",
            "Iteration 181, loss = 0.12887462\n",
            "Iteration 182, loss = 0.12800312\n",
            "Iteration 183, loss = 0.12732018\n",
            "Iteration 184, loss = 0.12672320\n",
            "Iteration 185, loss = 0.12569382\n",
            "Iteration 186, loss = 0.12538001\n",
            "Iteration 187, loss = 0.12443535\n",
            "Iteration 188, loss = 0.12363987\n",
            "Iteration 189, loss = 0.12309008\n",
            "Iteration 190, loss = 0.12243400\n",
            "Iteration 191, loss = 0.12157764\n",
            "Iteration 192, loss = 0.12068631\n",
            "Iteration 193, loss = 0.11992112\n",
            "Iteration 194, loss = 0.11945613\n",
            "Iteration 195, loss = 0.11841228\n",
            "Iteration 196, loss = 0.11775647\n",
            "Iteration 197, loss = 0.11710908\n",
            "Iteration 198, loss = 0.11671655\n",
            "Iteration 199, loss = 0.11577809\n",
            "Iteration 200, loss = 0.11517331\n",
            "Iteration 201, loss = 0.11446340\n",
            "Iteration 202, loss = 0.11376768\n",
            "Iteration 203, loss = 0.11313568\n",
            "Iteration 204, loss = 0.11234478\n",
            "Iteration 205, loss = 0.11173469\n",
            "Iteration 206, loss = 0.11119045\n",
            "Iteration 207, loss = 0.11035631\n",
            "Iteration 208, loss = 0.10955553\n",
            "Iteration 209, loss = 0.10902754\n",
            "Iteration 210, loss = 0.10867305\n",
            "Iteration 211, loss = 0.10771108\n",
            "Iteration 212, loss = 0.10717234\n",
            "Iteration 213, loss = 0.10650581\n",
            "Iteration 214, loss = 0.10630495\n",
            "Iteration 215, loss = 0.10520625\n",
            "Iteration 216, loss = 0.10460102\n",
            "Iteration 217, loss = 0.10409062\n",
            "Iteration 218, loss = 0.10359575\n",
            "Iteration 219, loss = 0.10277180\n",
            "Iteration 220, loss = 0.10197000\n",
            "Iteration 221, loss = 0.10170857\n",
            "Iteration 222, loss = 0.10052406\n",
            "Iteration 223, loss = 0.10011872\n",
            "Iteration 224, loss = 0.09950221\n",
            "Iteration 225, loss = 0.09879678\n",
            "Iteration 226, loss = 0.09831840\n",
            "Iteration 227, loss = 0.09767223\n",
            "Iteration 228, loss = 0.09712478\n",
            "Iteration 229, loss = 0.09668934\n",
            "Iteration 230, loss = 0.09583878\n",
            "Iteration 231, loss = 0.09518246\n",
            "Iteration 232, loss = 0.09469223\n",
            "Iteration 233, loss = 0.09416392\n",
            "Iteration 234, loss = 0.09373612\n",
            "Iteration 235, loss = 0.09303732\n",
            "Iteration 236, loss = 0.09214975\n",
            "Iteration 237, loss = 0.09159884\n",
            "Iteration 238, loss = 0.09115511\n",
            "Iteration 239, loss = 0.09040313\n",
            "Iteration 240, loss = 0.08982670\n",
            "Iteration 241, loss = 0.08945279\n",
            "Iteration 242, loss = 0.08878773\n",
            "Iteration 243, loss = 0.08822001\n",
            "Iteration 244, loss = 0.08777148\n",
            "Iteration 245, loss = 0.08713662\n",
            "Iteration 246, loss = 0.08654634\n",
            "Iteration 247, loss = 0.08621345\n",
            "Iteration 248, loss = 0.08578088\n",
            "Iteration 249, loss = 0.08500415\n",
            "Iteration 250, loss = 0.08443058\n",
            "Iteration 251, loss = 0.08406180\n",
            "Iteration 252, loss = 0.08336188\n",
            "Iteration 253, loss = 0.08298746\n",
            "Iteration 254, loss = 0.08234345\n",
            "Iteration 255, loss = 0.08178825\n",
            "Iteration 256, loss = 0.08113648\n",
            "Iteration 257, loss = 0.08056390\n",
            "Iteration 258, loss = 0.08022109\n",
            "Iteration 259, loss = 0.07957056\n",
            "Iteration 260, loss = 0.07897622\n",
            "Iteration 261, loss = 0.07861001\n",
            "Iteration 262, loss = 0.07810533\n",
            "Iteration 263, loss = 0.07761360\n",
            "Iteration 264, loss = 0.07693736\n",
            "Iteration 265, loss = 0.07651653\n",
            "Iteration 266, loss = 0.07598309\n",
            "Iteration 267, loss = 0.07570875\n",
            "Iteration 268, loss = 0.07506999\n",
            "Iteration 269, loss = 0.07453384\n",
            "Iteration 270, loss = 0.07397648\n",
            "Iteration 271, loss = 0.07360609\n",
            "Iteration 272, loss = 0.07301832\n",
            "Iteration 273, loss = 0.07249907\n",
            "Iteration 274, loss = 0.07208217\n",
            "Iteration 275, loss = 0.07173157\n",
            "Iteration 276, loss = 0.07154082\n",
            "Iteration 277, loss = 0.07086497\n",
            "Iteration 278, loss = 0.07022269\n",
            "Iteration 279, loss = 0.07025977\n",
            "Iteration 280, loss = 0.06940208\n",
            "Iteration 281, loss = 0.06920288\n",
            "Iteration 282, loss = 0.06845708\n",
            "Iteration 283, loss = 0.06799162\n",
            "Iteration 284, loss = 0.06745876\n",
            "Iteration 285, loss = 0.06711097\n",
            "Iteration 286, loss = 0.06673232\n",
            "Iteration 287, loss = 0.06597865\n",
            "Iteration 288, loss = 0.06602349\n",
            "Iteration 289, loss = 0.06547778\n",
            "Iteration 290, loss = 0.06483760\n",
            "Iteration 291, loss = 0.06436921\n",
            "Iteration 292, loss = 0.06437949\n",
            "Iteration 293, loss = 0.06432382\n",
            "Iteration 294, loss = 0.06327489\n",
            "Iteration 295, loss = 0.06295602\n",
            "Iteration 296, loss = 0.06292431\n",
            "Iteration 297, loss = 0.06226542\n",
            "Iteration 298, loss = 0.06142626\n",
            "Iteration 299, loss = 0.06108859\n",
            "Iteration 300, loss = 0.06076679\n",
            "Iteration 301, loss = 0.06016230\n",
            "Iteration 302, loss = 0.05969151\n",
            "Iteration 303, loss = 0.05930858\n",
            "Iteration 304, loss = 0.05945855\n",
            "Iteration 305, loss = 0.05923823\n",
            "Iteration 306, loss = 0.05832603\n",
            "Iteration 307, loss = 0.05791673\n",
            "Iteration 308, loss = 0.05755566\n",
            "Iteration 309, loss = 0.05718862\n",
            "Iteration 310, loss = 0.05694860\n",
            "Iteration 311, loss = 0.05625111\n",
            "Iteration 312, loss = 0.05596229\n",
            "Iteration 313, loss = 0.05543141\n",
            "Iteration 314, loss = 0.05549598\n",
            "Iteration 315, loss = 0.05462511\n",
            "Iteration 316, loss = 0.05469042\n",
            "Iteration 317, loss = 0.05413454\n",
            "Iteration 318, loss = 0.05355366\n",
            "Iteration 319, loss = 0.05334946\n",
            "Iteration 320, loss = 0.05300322\n",
            "Iteration 321, loss = 0.05259162\n",
            "Iteration 322, loss = 0.05237466\n",
            "Iteration 323, loss = 0.05192648\n",
            "Iteration 324, loss = 0.05167518\n",
            "Iteration 325, loss = 0.05128426\n",
            "Iteration 326, loss = 0.05101217\n",
            "Iteration 327, loss = 0.05054448\n",
            "Iteration 328, loss = 0.05036016\n",
            "Iteration 329, loss = 0.04999907\n",
            "Iteration 330, loss = 0.04949197\n",
            "Iteration 331, loss = 0.04920453\n",
            "Iteration 332, loss = 0.04905057\n",
            "Iteration 333, loss = 0.04847449\n",
            "Iteration 334, loss = 0.04830718\n",
            "Iteration 335, loss = 0.04802604\n",
            "Iteration 336, loss = 0.04793871\n",
            "Iteration 337, loss = 0.04753164\n",
            "Iteration 338, loss = 0.04741145\n",
            "Iteration 339, loss = 0.04671907\n",
            "Iteration 340, loss = 0.04635186\n",
            "Iteration 341, loss = 0.04614411\n",
            "Iteration 342, loss = 0.04580107\n",
            "Iteration 343, loss = 0.04570162\n",
            "Iteration 344, loss = 0.04519589\n",
            "Iteration 345, loss = 0.04486149\n",
            "Iteration 346, loss = 0.04454510\n",
            "Iteration 347, loss = 0.04439894\n",
            "Iteration 348, loss = 0.04402479\n",
            "Iteration 349, loss = 0.04397952\n",
            "Iteration 350, loss = 0.04339129\n",
            "Iteration 351, loss = 0.04326564\n",
            "Iteration 352, loss = 0.04315331\n",
            "Iteration 353, loss = 0.04287977\n",
            "Iteration 354, loss = 0.04225682\n",
            "Iteration 355, loss = 0.04201577\n",
            "Iteration 356, loss = 0.04179980\n",
            "Iteration 357, loss = 0.04145701\n",
            "Iteration 358, loss = 0.04106652\n",
            "Iteration 359, loss = 0.04093195\n",
            "Iteration 360, loss = 0.04055479\n",
            "Iteration 361, loss = 0.04040774\n",
            "Iteration 362, loss = 0.04006683\n",
            "Iteration 363, loss = 0.03976956\n",
            "Iteration 364, loss = 0.03948484\n",
            "Iteration 365, loss = 0.03929452\n",
            "Iteration 366, loss = 0.03895226\n",
            "Iteration 367, loss = 0.03877345\n",
            "Iteration 368, loss = 0.03861119\n",
            "Iteration 369, loss = 0.03830991\n",
            "Iteration 370, loss = 0.03819192\n",
            "Iteration 371, loss = 0.03800790\n",
            "Iteration 372, loss = 0.03755282\n",
            "Iteration 373, loss = 0.03731096\n",
            "Iteration 374, loss = 0.03703378\n",
            "Iteration 375, loss = 0.03667704\n",
            "Iteration 376, loss = 0.03663661\n",
            "Iteration 377, loss = 0.03626822\n",
            "Iteration 378, loss = 0.03605286\n",
            "Iteration 379, loss = 0.03592988\n",
            "Iteration 380, loss = 0.03571922\n",
            "Iteration 381, loss = 0.03542356\n",
            "Iteration 382, loss = 0.03507566\n",
            "Iteration 383, loss = 0.03488065\n",
            "Iteration 384, loss = 0.03465362\n",
            "Iteration 385, loss = 0.03446657\n",
            "Iteration 386, loss = 0.03438083\n",
            "Iteration 387, loss = 0.03403038\n",
            "Iteration 388, loss = 0.03379002\n",
            "Iteration 389, loss = 0.03357916\n",
            "Iteration 390, loss = 0.03341070\n",
            "Iteration 391, loss = 0.03323970\n",
            "Iteration 392, loss = 0.03309155\n",
            "Iteration 393, loss = 0.03287993\n",
            "Iteration 394, loss = 0.03260638\n",
            "Iteration 395, loss = 0.03222713\n",
            "Iteration 396, loss = 0.03223228\n",
            "Iteration 397, loss = 0.03184361\n",
            "Iteration 398, loss = 0.03176672\n",
            "Iteration 399, loss = 0.03148261\n",
            "Iteration 400, loss = 0.03121529\n",
            "Iteration 401, loss = 0.03108584\n",
            "Iteration 402, loss = 0.03094826\n",
            "Iteration 403, loss = 0.03077916\n",
            "Iteration 404, loss = 0.03045128\n",
            "Iteration 405, loss = 0.03026729\n",
            "Iteration 406, loss = 0.03009092\n",
            "Iteration 407, loss = 0.02991212\n",
            "Iteration 408, loss = 0.02974346\n",
            "Iteration 409, loss = 0.02957968\n",
            "Iteration 410, loss = 0.02931971\n",
            "Iteration 411, loss = 0.02911897\n",
            "Iteration 412, loss = 0.02902152\n",
            "Iteration 413, loss = 0.02895279\n",
            "Iteration 414, loss = 0.02868334\n",
            "Iteration 415, loss = 0.02856717\n",
            "Iteration 416, loss = 0.02825989\n",
            "Iteration 417, loss = 0.02816905\n",
            "Iteration 418, loss = 0.02784113\n",
            "Iteration 419, loss = 0.02781423\n",
            "Iteration 420, loss = 0.02749530\n",
            "Iteration 421, loss = 0.02731131\n",
            "Iteration 422, loss = 0.02712025\n",
            "Iteration 423, loss = 0.02709418\n",
            "Iteration 424, loss = 0.02683765\n",
            "Iteration 425, loss = 0.02668065\n",
            "Iteration 426, loss = 0.02645928\n",
            "Iteration 427, loss = 0.02629639\n",
            "Iteration 428, loss = 0.02613401\n",
            "Iteration 429, loss = 0.02596015\n",
            "Iteration 430, loss = 0.02580789\n",
            "Iteration 431, loss = 0.02568761\n",
            "Iteration 432, loss = 0.02557071\n",
            "Iteration 433, loss = 0.02530108\n",
            "Iteration 434, loss = 0.02518698\n",
            "Iteration 435, loss = 0.02515637\n",
            "Iteration 436, loss = 0.02502781\n",
            "Iteration 437, loss = 0.02476256\n",
            "Iteration 438, loss = 0.02455176\n",
            "Iteration 439, loss = 0.02456765\n",
            "Iteration 440, loss = 0.02441005\n",
            "Iteration 441, loss = 0.02412556\n",
            "Iteration 442, loss = 0.02395679\n",
            "Iteration 443, loss = 0.02373518\n",
            "Iteration 444, loss = 0.02363720\n",
            "Iteration 445, loss = 0.02345828\n",
            "Iteration 446, loss = 0.02326791\n",
            "Iteration 447, loss = 0.02328876\n",
            "Iteration 448, loss = 0.02308458\n",
            "Iteration 449, loss = 0.02292227\n",
            "Iteration 450, loss = 0.02277822\n",
            "Iteration 451, loss = 0.02266304\n",
            "Iteration 452, loss = 0.02277809\n",
            "Iteration 453, loss = 0.02231568\n",
            "Iteration 454, loss = 0.02228491\n",
            "Iteration 455, loss = 0.02212667\n",
            "Iteration 456, loss = 0.02195284\n",
            "Iteration 457, loss = 0.02181358\n",
            "Iteration 458, loss = 0.02171356\n",
            "Iteration 459, loss = 0.02154115\n",
            "Iteration 460, loss = 0.02144482\n",
            "Iteration 461, loss = 0.02122590\n",
            "Iteration 462, loss = 0.02112102\n",
            "Iteration 463, loss = 0.02097841\n",
            "Iteration 464, loss = 0.02085400\n",
            "Iteration 465, loss = 0.02086201\n",
            "Iteration 466, loss = 0.02074326\n",
            "Iteration 467, loss = 0.02060339\n",
            "Iteration 468, loss = 0.02045395\n",
            "Iteration 469, loss = 0.02025332\n",
            "Iteration 470, loss = 0.02017237\n",
            "Iteration 471, loss = 0.01996518\n",
            "Iteration 472, loss = 0.01984014\n",
            "Iteration 473, loss = 0.01971061\n",
            "Iteration 474, loss = 0.01962006\n",
            "Iteration 475, loss = 0.01948609\n",
            "Iteration 476, loss = 0.01939570\n",
            "Iteration 477, loss = 0.01947501\n",
            "Iteration 478, loss = 0.01916148\n",
            "Iteration 479, loss = 0.01920901\n",
            "Iteration 480, loss = 0.01893094\n",
            "Iteration 481, loss = 0.01882653\n",
            "Iteration 482, loss = 0.01877933\n",
            "Iteration 483, loss = 0.01868110\n",
            "Iteration 484, loss = 0.01851495\n",
            "Iteration 485, loss = 0.01835399\n",
            "Iteration 486, loss = 0.01823895\n",
            "Iteration 487, loss = 0.01817351\n",
            "Iteration 488, loss = 0.01800398\n",
            "Iteration 489, loss = 0.01793834\n",
            "Iteration 490, loss = 0.01789303\n",
            "Iteration 491, loss = 0.01771053\n",
            "Iteration 492, loss = 0.01756804\n",
            "Iteration 493, loss = 0.01744804\n",
            "Iteration 494, loss = 0.01740135\n",
            "Iteration 495, loss = 0.01727588\n",
            "Iteration 496, loss = 0.01719688\n",
            "Iteration 497, loss = 0.01709060\n",
            "Iteration 498, loss = 0.01704079\n",
            "Iteration 499, loss = 0.01689670\n",
            "Iteration 500, loss = 0.01677567\n",
            "Iteration 501, loss = 0.01666176\n",
            "Iteration 502, loss = 0.01655302\n",
            "Iteration 503, loss = 0.01644161\n",
            "Iteration 504, loss = 0.01632635\n",
            "Iteration 505, loss = 0.01624756\n",
            "Iteration 506, loss = 0.01617023\n",
            "Iteration 507, loss = 0.01610524\n",
            "Iteration 508, loss = 0.01595490\n",
            "Iteration 509, loss = 0.01597773\n",
            "Iteration 510, loss = 0.01574391\n",
            "Iteration 511, loss = 0.01575279\n",
            "Iteration 512, loss = 0.01555023\n",
            "Iteration 513, loss = 0.01559122\n",
            "Iteration 514, loss = 0.01541691\n",
            "Iteration 515, loss = 0.01534645\n",
            "Iteration 516, loss = 0.01525623\n",
            "Iteration 517, loss = 0.01513519\n",
            "Iteration 518, loss = 0.01505989\n",
            "Iteration 519, loss = 0.01501078\n",
            "Iteration 520, loss = 0.01492544\n",
            "Iteration 521, loss = 0.01478672\n",
            "Iteration 522, loss = 0.01470450\n",
            "Iteration 523, loss = 0.01459666\n",
            "Iteration 524, loss = 0.01450911\n",
            "Iteration 525, loss = 0.01443508\n",
            "Iteration 526, loss = 0.01436983\n",
            "Iteration 527, loss = 0.01430843\n",
            "Iteration 528, loss = 0.01420868\n",
            "Iteration 529, loss = 0.01411441\n",
            "Iteration 530, loss = 0.01406146\n",
            "Iteration 531, loss = 0.01396559\n",
            "Iteration 532, loss = 0.01388830\n",
            "Iteration 533, loss = 0.01383066\n",
            "Iteration 534, loss = 0.01374845\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.75793111\n",
            "Iteration 2, loss = 0.63014826\n",
            "Iteration 3, loss = 0.53987582\n",
            "Iteration 4, loss = 0.47931842\n",
            "Iteration 5, loss = 0.44203605\n",
            "Iteration 6, loss = 0.41894416\n",
            "Iteration 7, loss = 0.40221645\n",
            "Iteration 8, loss = 0.39054313\n",
            "Iteration 9, loss = 0.38130069\n",
            "Iteration 10, loss = 0.37367941\n",
            "Iteration 11, loss = 0.36712339\n",
            "Iteration 12, loss = 0.36126660\n",
            "Iteration 13, loss = 0.35632218\n",
            "Iteration 14, loss = 0.35173710\n",
            "Iteration 15, loss = 0.34726169\n",
            "Iteration 16, loss = 0.34344745\n",
            "Iteration 17, loss = 0.33982345\n",
            "Iteration 18, loss = 0.33633314\n",
            "Iteration 19, loss = 0.33293174\n",
            "Iteration 20, loss = 0.32990779\n",
            "Iteration 21, loss = 0.32699408\n",
            "Iteration 22, loss = 0.32423403\n",
            "Iteration 23, loss = 0.32131506\n",
            "Iteration 24, loss = 0.31894139\n",
            "Iteration 25, loss = 0.31599573\n",
            "Iteration 26, loss = 0.31352210\n",
            "Iteration 27, loss = 0.31119569\n",
            "Iteration 28, loss = 0.30880711\n",
            "Iteration 29, loss = 0.30636699\n",
            "Iteration 30, loss = 0.30402054\n",
            "Iteration 31, loss = 0.30210474\n",
            "Iteration 32, loss = 0.29976221\n",
            "Iteration 33, loss = 0.29765975\n",
            "Iteration 34, loss = 0.29542730\n",
            "Iteration 35, loss = 0.29335054\n",
            "Iteration 36, loss = 0.29153526\n",
            "Iteration 37, loss = 0.28941956\n",
            "Iteration 38, loss = 0.28745915\n",
            "Iteration 39, loss = 0.28580431\n",
            "Iteration 40, loss = 0.28369618\n",
            "Iteration 41, loss = 0.28220807\n",
            "Iteration 42, loss = 0.28018120\n",
            "Iteration 43, loss = 0.27838620\n",
            "Iteration 44, loss = 0.27644742\n",
            "Iteration 45, loss = 0.27470888\n",
            "Iteration 46, loss = 0.27305835\n",
            "Iteration 47, loss = 0.27145272\n",
            "Iteration 48, loss = 0.26959734\n",
            "Iteration 49, loss = 0.26783804\n",
            "Iteration 50, loss = 0.26639356\n",
            "Iteration 51, loss = 0.26458696\n",
            "Iteration 52, loss = 0.26300628\n",
            "Iteration 53, loss = 0.26123333\n",
            "Iteration 54, loss = 0.25958316\n",
            "Iteration 55, loss = 0.25806822\n",
            "Iteration 56, loss = 0.25639156\n",
            "Iteration 57, loss = 0.25474938\n",
            "Iteration 58, loss = 0.25339512\n",
            "Iteration 59, loss = 0.25157814\n",
            "Iteration 60, loss = 0.25017713\n",
            "Iteration 61, loss = 0.24862062\n",
            "Iteration 62, loss = 0.24691777\n",
            "Iteration 63, loss = 0.24537522\n",
            "Iteration 64, loss = 0.24370981\n",
            "Iteration 65, loss = 0.24227503\n",
            "Iteration 66, loss = 0.24069724\n",
            "Iteration 67, loss = 0.23941893\n",
            "Iteration 68, loss = 0.23772341\n",
            "Iteration 69, loss = 0.23635358\n",
            "Iteration 70, loss = 0.23488671\n",
            "Iteration 71, loss = 0.23350996\n",
            "Iteration 72, loss = 0.23171664\n",
            "Iteration 73, loss = 0.23046446\n",
            "Iteration 74, loss = 0.22917671\n",
            "Iteration 75, loss = 0.22797562\n",
            "Iteration 76, loss = 0.22627465\n",
            "Iteration 77, loss = 0.22484132\n",
            "Iteration 78, loss = 0.22358966\n",
            "Iteration 79, loss = 0.22216015\n",
            "Iteration 80, loss = 0.22069353\n",
            "Iteration 81, loss = 0.21914575\n",
            "Iteration 82, loss = 0.21802255\n",
            "Iteration 83, loss = 0.21688113\n",
            "Iteration 84, loss = 0.21532641\n",
            "Iteration 85, loss = 0.21404954\n",
            "Iteration 86, loss = 0.21256024\n",
            "Iteration 87, loss = 0.21156616\n",
            "Iteration 88, loss = 0.20975664\n",
            "Iteration 89, loss = 0.20856421\n",
            "Iteration 90, loss = 0.20727729\n",
            "Iteration 91, loss = 0.20604585\n",
            "Iteration 92, loss = 0.20484980\n",
            "Iteration 93, loss = 0.20348215\n",
            "Iteration 94, loss = 0.20213225\n",
            "Iteration 95, loss = 0.20102837\n",
            "Iteration 96, loss = 0.19969246\n",
            "Iteration 97, loss = 0.19823249\n",
            "Iteration 98, loss = 0.19727419\n",
            "Iteration 99, loss = 0.19605891\n",
            "Iteration 100, loss = 0.19487190\n",
            "Iteration 101, loss = 0.19377353\n",
            "Iteration 102, loss = 0.19235317\n",
            "Iteration 103, loss = 0.19116397\n",
            "Iteration 104, loss = 0.19003467\n",
            "Iteration 105, loss = 0.18884959\n",
            "Iteration 106, loss = 0.18777830\n",
            "Iteration 107, loss = 0.18657602\n",
            "Iteration 108, loss = 0.18536016\n",
            "Iteration 109, loss = 0.18420744\n",
            "Iteration 110, loss = 0.18337153\n",
            "Iteration 111, loss = 0.18222361\n",
            "Iteration 112, loss = 0.18089062\n",
            "Iteration 113, loss = 0.17991331\n",
            "Iteration 114, loss = 0.17858372\n",
            "Iteration 115, loss = 0.17765715\n",
            "Iteration 116, loss = 0.17658332\n",
            "Iteration 117, loss = 0.17532507\n",
            "Iteration 118, loss = 0.17438849\n",
            "Iteration 119, loss = 0.17326767\n",
            "Iteration 120, loss = 0.17215747\n",
            "Iteration 121, loss = 0.17181687\n",
            "Iteration 122, loss = 0.16988961\n",
            "Iteration 123, loss = 0.16894169\n",
            "Iteration 124, loss = 0.16791041\n",
            "Iteration 125, loss = 0.16702358\n",
            "Iteration 126, loss = 0.16588897\n",
            "Iteration 127, loss = 0.16491197\n",
            "Iteration 128, loss = 0.16396269\n",
            "Iteration 129, loss = 0.16284337\n",
            "Iteration 130, loss = 0.16196845\n",
            "Iteration 131, loss = 0.16069184\n",
            "Iteration 132, loss = 0.15998277\n",
            "Iteration 133, loss = 0.15949444\n",
            "Iteration 134, loss = 0.15791029\n",
            "Iteration 135, loss = 0.15666623\n",
            "Iteration 136, loss = 0.15580500\n",
            "Iteration 137, loss = 0.15462541\n",
            "Iteration 138, loss = 0.15373827\n",
            "Iteration 139, loss = 0.15286175\n",
            "Iteration 140, loss = 0.15166796\n",
            "Iteration 141, loss = 0.15076388\n",
            "Iteration 142, loss = 0.14987676\n",
            "Iteration 143, loss = 0.14907897\n",
            "Iteration 144, loss = 0.14794432\n",
            "Iteration 145, loss = 0.14708339\n",
            "Iteration 146, loss = 0.14612720\n",
            "Iteration 147, loss = 0.14517030\n",
            "Iteration 148, loss = 0.14424881\n",
            "Iteration 149, loss = 0.14309727\n",
            "Iteration 150, loss = 0.14210119\n",
            "Iteration 151, loss = 0.14162710\n",
            "Iteration 152, loss = 0.14047278\n",
            "Iteration 153, loss = 0.13957385\n",
            "Iteration 154, loss = 0.13887350\n",
            "Iteration 155, loss = 0.13836868\n",
            "Iteration 156, loss = 0.13732788\n",
            "Iteration 157, loss = 0.13603095\n",
            "Iteration 158, loss = 0.13523545\n",
            "Iteration 159, loss = 0.13452372\n",
            "Iteration 160, loss = 0.13350213\n",
            "Iteration 161, loss = 0.13260976\n",
            "Iteration 162, loss = 0.13176600\n",
            "Iteration 163, loss = 0.13093364\n",
            "Iteration 164, loss = 0.13033996\n",
            "Iteration 165, loss = 0.12934880\n",
            "Iteration 166, loss = 0.12857827\n",
            "Iteration 167, loss = 0.12764569\n",
            "Iteration 168, loss = 0.12678686\n",
            "Iteration 169, loss = 0.12625272\n",
            "Iteration 170, loss = 0.12531328\n",
            "Iteration 171, loss = 0.12411023\n",
            "Iteration 172, loss = 0.12364349\n",
            "Iteration 173, loss = 0.12266706\n",
            "Iteration 174, loss = 0.12248471\n",
            "Iteration 175, loss = 0.12200353\n",
            "Iteration 176, loss = 0.12156645\n",
            "Iteration 177, loss = 0.11960865\n",
            "Iteration 178, loss = 0.11893451\n",
            "Iteration 179, loss = 0.11820705\n",
            "Iteration 180, loss = 0.11732412\n",
            "Iteration 181, loss = 0.11652024\n",
            "Iteration 182, loss = 0.11569254\n",
            "Iteration 183, loss = 0.11539065\n",
            "Iteration 184, loss = 0.11409596\n",
            "Iteration 185, loss = 0.11363672\n",
            "Iteration 186, loss = 0.11268300\n",
            "Iteration 187, loss = 0.11208887\n",
            "Iteration 188, loss = 0.11162225\n",
            "Iteration 189, loss = 0.11055511\n",
            "Iteration 190, loss = 0.11003241\n",
            "Iteration 191, loss = 0.10912700\n",
            "Iteration 192, loss = 0.10855024\n",
            "Iteration 193, loss = 0.10785666\n",
            "Iteration 194, loss = 0.10741511\n",
            "Iteration 195, loss = 0.10660438\n",
            "Iteration 196, loss = 0.10567566\n",
            "Iteration 197, loss = 0.10501102\n",
            "Iteration 198, loss = 0.10446783\n",
            "Iteration 199, loss = 0.10377629\n",
            "Iteration 200, loss = 0.10296615\n",
            "Iteration 201, loss = 0.10225805\n",
            "Iteration 202, loss = 0.10147036\n",
            "Iteration 203, loss = 0.10090291\n",
            "Iteration 204, loss = 0.10054129\n",
            "Iteration 205, loss = 0.09939980\n",
            "Iteration 206, loss = 0.09892849\n",
            "Iteration 207, loss = 0.09818515\n",
            "Iteration 208, loss = 0.09820106\n",
            "Iteration 209, loss = 0.09680787\n",
            "Iteration 210, loss = 0.09664594\n",
            "Iteration 211, loss = 0.09554628\n",
            "Iteration 212, loss = 0.09507156\n",
            "Iteration 213, loss = 0.09428824\n",
            "Iteration 214, loss = 0.09370615\n",
            "Iteration 215, loss = 0.09312126\n",
            "Iteration 216, loss = 0.09252291\n",
            "Iteration 217, loss = 0.09178497\n",
            "Iteration 218, loss = 0.09125540\n",
            "Iteration 219, loss = 0.09051059\n",
            "Iteration 220, loss = 0.09000035\n",
            "Iteration 221, loss = 0.08951742\n",
            "Iteration 222, loss = 0.08868020\n",
            "Iteration 223, loss = 0.08859333\n",
            "Iteration 224, loss = 0.08764990\n",
            "Iteration 225, loss = 0.08705581\n",
            "Iteration 226, loss = 0.08659450\n",
            "Iteration 227, loss = 0.08606386\n",
            "Iteration 228, loss = 0.08526911\n",
            "Iteration 229, loss = 0.08504154\n",
            "Iteration 230, loss = 0.08424311\n",
            "Iteration 231, loss = 0.08380795\n",
            "Iteration 232, loss = 0.08316656\n",
            "Iteration 233, loss = 0.08247422\n",
            "Iteration 234, loss = 0.08218487\n",
            "Iteration 235, loss = 0.08153477\n",
            "Iteration 236, loss = 0.08096837\n",
            "Iteration 237, loss = 0.08040313\n",
            "Iteration 238, loss = 0.07964477\n",
            "Iteration 239, loss = 0.07928823\n",
            "Iteration 240, loss = 0.07863857\n",
            "Iteration 241, loss = 0.07836808\n",
            "Iteration 242, loss = 0.07767992\n",
            "Iteration 243, loss = 0.07724725\n",
            "Iteration 244, loss = 0.07680926\n",
            "Iteration 245, loss = 0.07617147\n",
            "Iteration 246, loss = 0.07569594\n",
            "Iteration 247, loss = 0.07512665\n",
            "Iteration 248, loss = 0.07479475\n",
            "Iteration 249, loss = 0.07414876\n",
            "Iteration 250, loss = 0.07369158\n",
            "Iteration 251, loss = 0.07315200\n",
            "Iteration 252, loss = 0.07282691\n",
            "Iteration 253, loss = 0.07200127\n",
            "Iteration 254, loss = 0.07264132\n",
            "Iteration 255, loss = 0.07173951\n",
            "Iteration 256, loss = 0.07110833\n",
            "Iteration 257, loss = 0.07058424\n",
            "Iteration 258, loss = 0.06987942\n",
            "Iteration 259, loss = 0.06938458\n",
            "Iteration 260, loss = 0.06914299\n",
            "Iteration 261, loss = 0.06830575\n",
            "Iteration 262, loss = 0.06799480\n",
            "Iteration 263, loss = 0.06738325\n",
            "Iteration 264, loss = 0.06696356\n",
            "Iteration 265, loss = 0.06655177\n",
            "Iteration 266, loss = 0.06618085\n",
            "Iteration 267, loss = 0.06576641\n",
            "Iteration 268, loss = 0.06559155\n",
            "Iteration 269, loss = 0.06483583\n",
            "Iteration 270, loss = 0.06448014\n",
            "Iteration 271, loss = 0.06432433\n",
            "Iteration 272, loss = 0.06365613\n",
            "Iteration 273, loss = 0.06315910\n",
            "Iteration 274, loss = 0.06268733\n",
            "Iteration 275, loss = 0.06238026\n",
            "Iteration 276, loss = 0.06210328\n",
            "Iteration 277, loss = 0.06170034\n",
            "Iteration 278, loss = 0.06135857\n",
            "Iteration 279, loss = 0.06067140\n",
            "Iteration 280, loss = 0.06026534\n",
            "Iteration 281, loss = 0.05999682\n",
            "Iteration 282, loss = 0.05948144\n",
            "Iteration 283, loss = 0.05917244\n",
            "Iteration 284, loss = 0.05866107\n",
            "Iteration 285, loss = 0.05845159\n",
            "Iteration 286, loss = 0.05800296\n",
            "Iteration 287, loss = 0.05759168\n",
            "Iteration 288, loss = 0.05720713\n",
            "Iteration 289, loss = 0.05685820\n",
            "Iteration 290, loss = 0.05664041\n",
            "Iteration 291, loss = 0.05603343\n",
            "Iteration 292, loss = 0.05578261\n",
            "Iteration 293, loss = 0.05539015\n",
            "Iteration 294, loss = 0.05524882\n",
            "Iteration 295, loss = 0.05450492\n",
            "Iteration 296, loss = 0.05424255\n",
            "Iteration 297, loss = 0.05391519\n",
            "Iteration 298, loss = 0.05342456\n",
            "Iteration 299, loss = 0.05316834\n",
            "Iteration 300, loss = 0.05294897\n",
            "Iteration 301, loss = 0.05260448\n",
            "Iteration 302, loss = 0.05200068\n",
            "Iteration 303, loss = 0.05181499\n",
            "Iteration 304, loss = 0.05139480\n",
            "Iteration 305, loss = 0.05107624\n",
            "Iteration 306, loss = 0.05078606\n",
            "Iteration 307, loss = 0.05051091\n",
            "Iteration 308, loss = 0.05001407\n",
            "Iteration 309, loss = 0.04998569\n",
            "Iteration 310, loss = 0.04935279\n",
            "Iteration 311, loss = 0.04907003\n",
            "Iteration 312, loss = 0.04878419\n",
            "Iteration 313, loss = 0.04841137\n",
            "Iteration 314, loss = 0.04824317\n",
            "Iteration 315, loss = 0.04775303\n",
            "Iteration 316, loss = 0.04777383\n",
            "Iteration 317, loss = 0.04736817\n",
            "Iteration 318, loss = 0.04670475\n",
            "Iteration 319, loss = 0.04661506\n",
            "Iteration 320, loss = 0.04620310\n",
            "Iteration 321, loss = 0.04591386\n",
            "Iteration 322, loss = 0.04571141\n",
            "Iteration 323, loss = 0.04544376\n",
            "Iteration 324, loss = 0.04508574\n",
            "Iteration 325, loss = 0.04496701\n",
            "Iteration 326, loss = 0.04444383\n",
            "Iteration 327, loss = 0.04405821\n",
            "Iteration 328, loss = 0.04390048\n",
            "Iteration 329, loss = 0.04353151\n",
            "Iteration 330, loss = 0.04316318\n",
            "Iteration 331, loss = 0.04299004\n",
            "Iteration 332, loss = 0.04257648\n",
            "Iteration 333, loss = 0.04234214\n",
            "Iteration 334, loss = 0.04203020\n",
            "Iteration 335, loss = 0.04176584\n",
            "Iteration 336, loss = 0.04154524\n",
            "Iteration 337, loss = 0.04164723\n",
            "Iteration 338, loss = 0.04097411\n",
            "Iteration 339, loss = 0.04091548\n",
            "Iteration 340, loss = 0.04038781\n",
            "Iteration 341, loss = 0.04031473\n",
            "Iteration 342, loss = 0.03990388\n",
            "Iteration 343, loss = 0.03982534\n",
            "Iteration 344, loss = 0.03931456\n",
            "Iteration 345, loss = 0.03945874\n",
            "Iteration 346, loss = 0.03901361\n",
            "Iteration 347, loss = 0.03864183\n",
            "Iteration 348, loss = 0.03839812\n",
            "Iteration 349, loss = 0.03832403\n",
            "Iteration 350, loss = 0.03791741\n",
            "Iteration 351, loss = 0.03770692\n",
            "Iteration 352, loss = 0.03764391\n",
            "Iteration 353, loss = 0.03715018\n",
            "Iteration 354, loss = 0.03699993\n",
            "Iteration 355, loss = 0.03679308\n",
            "Iteration 356, loss = 0.03647466\n",
            "Iteration 357, loss = 0.03633000\n",
            "Iteration 358, loss = 0.03604971\n",
            "Iteration 359, loss = 0.03580665\n",
            "Iteration 360, loss = 0.03555024\n",
            "Iteration 361, loss = 0.03541855\n",
            "Iteration 362, loss = 0.03523352\n",
            "Iteration 363, loss = 0.03480692\n",
            "Iteration 364, loss = 0.03468614\n",
            "Iteration 365, loss = 0.03446478\n",
            "Iteration 366, loss = 0.03408008\n",
            "Iteration 367, loss = 0.03400020\n",
            "Iteration 368, loss = 0.03381525\n",
            "Iteration 369, loss = 0.03345838\n",
            "Iteration 370, loss = 0.03324984\n",
            "Iteration 371, loss = 0.03311107\n",
            "Iteration 372, loss = 0.03316102\n",
            "Iteration 373, loss = 0.03289303\n",
            "Iteration 374, loss = 0.03256170\n",
            "Iteration 375, loss = 0.03233646\n",
            "Iteration 376, loss = 0.03208625\n",
            "Iteration 377, loss = 0.03176439\n",
            "Iteration 378, loss = 0.03169665\n",
            "Iteration 379, loss = 0.03142541\n",
            "Iteration 380, loss = 0.03127367\n",
            "Iteration 381, loss = 0.03152128\n",
            "Iteration 382, loss = 0.03097272\n",
            "Iteration 383, loss = 0.03073485\n",
            "Iteration 384, loss = 0.03043285\n",
            "Iteration 385, loss = 0.03022622\n",
            "Iteration 386, loss = 0.03009831\n",
            "Iteration 387, loss = 0.02986439\n",
            "Iteration 388, loss = 0.02975671\n",
            "Iteration 389, loss = 0.02967289\n",
            "Iteration 390, loss = 0.02924639\n",
            "Iteration 391, loss = 0.02937734\n",
            "Iteration 392, loss = 0.02902278\n",
            "Iteration 393, loss = 0.02890164\n",
            "Iteration 394, loss = 0.02860242\n",
            "Iteration 395, loss = 0.02858805\n",
            "Iteration 396, loss = 0.02821530\n",
            "Iteration 397, loss = 0.02809942\n",
            "Iteration 398, loss = 0.02787885\n",
            "Iteration 399, loss = 0.02764387\n",
            "Iteration 400, loss = 0.02756877\n",
            "Iteration 401, loss = 0.02727901\n",
            "Iteration 402, loss = 0.02718365\n",
            "Iteration 403, loss = 0.02694735\n",
            "Iteration 404, loss = 0.02693784\n",
            "Iteration 405, loss = 0.02670505\n",
            "Iteration 406, loss = 0.02660017\n",
            "Iteration 407, loss = 0.02635723\n",
            "Iteration 408, loss = 0.02614824\n",
            "Iteration 409, loss = 0.02642354\n",
            "Iteration 410, loss = 0.02585854\n",
            "Iteration 411, loss = 0.02573944\n",
            "Iteration 412, loss = 0.02552487\n",
            "Iteration 413, loss = 0.02543309\n",
            "Iteration 414, loss = 0.02524654\n",
            "Iteration 415, loss = 0.02506184\n",
            "Iteration 416, loss = 0.02484603\n",
            "Iteration 417, loss = 0.02476077\n",
            "Iteration 418, loss = 0.02454877\n",
            "Iteration 419, loss = 0.02431363\n",
            "Iteration 420, loss = 0.02427136\n",
            "Iteration 421, loss = 0.02410900\n",
            "Iteration 422, loss = 0.02398932\n",
            "Iteration 423, loss = 0.02385226\n",
            "Iteration 424, loss = 0.02359843\n",
            "Iteration 425, loss = 0.02350651\n",
            "Iteration 426, loss = 0.02328138\n",
            "Iteration 427, loss = 0.02319499\n",
            "Iteration 428, loss = 0.02309524\n",
            "Iteration 429, loss = 0.02295172\n",
            "Iteration 430, loss = 0.02274160\n",
            "Iteration 431, loss = 0.02260986\n",
            "Iteration 432, loss = 0.02245200\n",
            "Iteration 433, loss = 0.02239701\n",
            "Iteration 434, loss = 0.02216238\n",
            "Iteration 435, loss = 0.02201488\n",
            "Iteration 436, loss = 0.02192151\n",
            "Iteration 437, loss = 0.02179679\n",
            "Iteration 438, loss = 0.02167658\n",
            "Iteration 439, loss = 0.02146344\n",
            "Iteration 440, loss = 0.02144974\n",
            "Iteration 441, loss = 0.02112799\n",
            "Iteration 442, loss = 0.02114190\n",
            "Iteration 443, loss = 0.02100986\n",
            "Iteration 444, loss = 0.02088924\n",
            "Iteration 445, loss = 0.02092530\n",
            "Iteration 446, loss = 0.02062532\n",
            "Iteration 447, loss = 0.02044819\n",
            "Iteration 448, loss = 0.02036413\n",
            "Iteration 449, loss = 0.02031179\n",
            "Iteration 450, loss = 0.02010153\n",
            "Iteration 451, loss = 0.02001399\n",
            "Iteration 452, loss = 0.01982467\n",
            "Iteration 453, loss = 0.01972020\n",
            "Iteration 454, loss = 0.01963363\n",
            "Iteration 455, loss = 0.01949602\n",
            "Iteration 456, loss = 0.01935548\n",
            "Iteration 457, loss = 0.01924388\n",
            "Iteration 458, loss = 0.01908650\n",
            "Iteration 459, loss = 0.01898073\n",
            "Iteration 460, loss = 0.01891683\n",
            "Iteration 461, loss = 0.01875269\n",
            "Iteration 462, loss = 0.01866616\n",
            "Iteration 463, loss = 0.01854405\n",
            "Iteration 464, loss = 0.01843672\n",
            "Iteration 465, loss = 0.01836374\n",
            "Iteration 466, loss = 0.01821963\n",
            "Iteration 467, loss = 0.01810338\n",
            "Iteration 468, loss = 0.01807638\n",
            "Iteration 469, loss = 0.01790753\n",
            "Iteration 470, loss = 0.01778273\n",
            "Iteration 471, loss = 0.01772787\n",
            "Iteration 472, loss = 0.01756333\n",
            "Iteration 473, loss = 0.01743011\n",
            "Iteration 474, loss = 0.01740776\n",
            "Iteration 475, loss = 0.01742042\n",
            "Iteration 476, loss = 0.01717605\n",
            "Iteration 477, loss = 0.01720545\n",
            "Iteration 478, loss = 0.01706037\n",
            "Iteration 479, loss = 0.01685878\n",
            "Iteration 480, loss = 0.01676208\n",
            "Iteration 481, loss = 0.01665700\n",
            "Iteration 482, loss = 0.01652023\n",
            "Iteration 483, loss = 0.01646285\n",
            "Iteration 484, loss = 0.01637637\n",
            "Iteration 485, loss = 0.01633740\n",
            "Iteration 486, loss = 0.01621450\n",
            "Iteration 487, loss = 0.01611637\n",
            "Iteration 488, loss = 0.01598846\n",
            "Iteration 489, loss = 0.01594756\n",
            "Iteration 490, loss = 0.01582557\n",
            "Iteration 491, loss = 0.01579593\n",
            "Iteration 492, loss = 0.01569761\n",
            "Iteration 493, loss = 0.01552806\n",
            "Iteration 494, loss = 0.01545606\n",
            "Iteration 495, loss = 0.01536801\n",
            "Iteration 496, loss = 0.01527929\n",
            "Iteration 497, loss = 0.01517806\n",
            "Iteration 498, loss = 0.01506132\n",
            "Iteration 499, loss = 0.01500095\n",
            "Iteration 500, loss = 0.01489709\n",
            "Iteration 501, loss = 0.01483111\n",
            "Iteration 502, loss = 0.01483476\n",
            "Iteration 503, loss = 0.01463617\n",
            "Iteration 504, loss = 0.01461228\n",
            "Iteration 505, loss = 0.01444678\n",
            "Iteration 506, loss = 0.01440113\n",
            "Iteration 507, loss = 0.01430077\n",
            "Iteration 508, loss = 0.01425023\n",
            "Iteration 509, loss = 0.01412805\n",
            "Iteration 510, loss = 0.01403696\n",
            "Iteration 511, loss = 0.01396119\n",
            "Iteration 512, loss = 0.01398401\n",
            "Iteration 513, loss = 0.01383467\n",
            "Iteration 514, loss = 0.01382361\n",
            "Iteration 515, loss = 0.01365945\n",
            "Iteration 516, loss = 0.01354691\n",
            "Iteration 517, loss = 0.01347906\n",
            "Iteration 518, loss = 0.01343898\n",
            "Iteration 519, loss = 0.01330413\n",
            "Iteration 520, loss = 0.01327444\n",
            "Iteration 521, loss = 0.01340672\n",
            "Iteration 522, loss = 0.01324145\n",
            "Iteration 523, loss = 0.01335438\n",
            "Iteration 524, loss = 0.01309719\n",
            "Iteration 525, loss = 0.01290022\n",
            "Iteration 526, loss = 0.01281883\n",
            "Iteration 527, loss = 0.01273177\n",
            "Iteration 528, loss = 0.01265595\n",
            "Iteration 529, loss = 0.01265681\n",
            "Iteration 530, loss = 0.01264577\n",
            "Iteration 531, loss = 0.01246544\n",
            "Iteration 532, loss = 0.01240531\n",
            "Iteration 533, loss = 0.01230528\n",
            "Iteration 534, loss = 0.01227052\n",
            "Iteration 535, loss = 0.01229123\n",
            "Iteration 536, loss = 0.01213301\n",
            "Iteration 537, loss = 0.01204844\n",
            "Iteration 538, loss = 0.01198064\n",
            "Iteration 539, loss = 0.01189904\n",
            "Iteration 540, loss = 0.01186308\n",
            "Iteration 541, loss = 0.01173675\n",
            "Iteration 542, loss = 0.01168061\n",
            "Iteration 543, loss = 0.01164011\n",
            "Iteration 544, loss = 0.01154732\n",
            "Iteration 545, loss = 0.01155659\n",
            "Iteration 546, loss = 0.01143013\n",
            "Iteration 547, loss = 0.01139256\n",
            "Iteration 548, loss = 0.01131719\n",
            "Iteration 549, loss = 0.01128170\n",
            "Iteration 550, loss = 0.01118815\n",
            "Iteration 551, loss = 0.01110171\n",
            "Iteration 552, loss = 0.01106974\n",
            "Iteration 553, loss = 0.01099281\n",
            "Iteration 554, loss = 0.01093771\n",
            "Iteration 555, loss = 0.01087006\n",
            "Iteration 556, loss = 0.01083748\n",
            "Iteration 557, loss = 0.01076139\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.63707860\n",
            "Iteration 2, loss = 0.50939081\n",
            "Iteration 3, loss = 0.44562443\n",
            "Iteration 4, loss = 0.41467475\n",
            "Iteration 5, loss = 0.39804933\n",
            "Iteration 6, loss = 0.38716815\n",
            "Iteration 7, loss = 0.37852148\n",
            "Iteration 8, loss = 0.37115658\n",
            "Iteration 9, loss = 0.36495096\n",
            "Iteration 10, loss = 0.35928731\n",
            "Iteration 11, loss = 0.35425606\n",
            "Iteration 12, loss = 0.34955817\n",
            "Iteration 13, loss = 0.34537992\n",
            "Iteration 14, loss = 0.34112786\n",
            "Iteration 15, loss = 0.33759700\n",
            "Iteration 16, loss = 0.33432529\n",
            "Iteration 17, loss = 0.33106854\n",
            "Iteration 18, loss = 0.32794546\n",
            "Iteration 19, loss = 0.32508876\n",
            "Iteration 20, loss = 0.32197080\n",
            "Iteration 21, loss = 0.31929409\n",
            "Iteration 22, loss = 0.31676530\n",
            "Iteration 23, loss = 0.31440388\n",
            "Iteration 24, loss = 0.31184086\n",
            "Iteration 25, loss = 0.30924871\n",
            "Iteration 26, loss = 0.30709773\n",
            "Iteration 27, loss = 0.30468073\n",
            "Iteration 28, loss = 0.30239929\n",
            "Iteration 29, loss = 0.29994419\n",
            "Iteration 30, loss = 0.29786973\n",
            "Iteration 31, loss = 0.29579071\n",
            "Iteration 32, loss = 0.29361967\n",
            "Iteration 33, loss = 0.29158631\n",
            "Iteration 34, loss = 0.28935415\n",
            "Iteration 35, loss = 0.28716654\n",
            "Iteration 36, loss = 0.28548120\n",
            "Iteration 37, loss = 0.28335964\n",
            "Iteration 38, loss = 0.28138291\n",
            "Iteration 39, loss = 0.27916206\n",
            "Iteration 40, loss = 0.27721798\n",
            "Iteration 41, loss = 0.27560389\n",
            "Iteration 42, loss = 0.27356270\n",
            "Iteration 43, loss = 0.27146509\n",
            "Iteration 44, loss = 0.26925585\n",
            "Iteration 45, loss = 0.26739109\n",
            "Iteration 46, loss = 0.26582903\n",
            "Iteration 47, loss = 0.26385210\n",
            "Iteration 48, loss = 0.26196005\n",
            "Iteration 49, loss = 0.26024143\n",
            "Iteration 50, loss = 0.25891679\n",
            "Iteration 51, loss = 0.25707507\n",
            "Iteration 52, loss = 0.25513672\n",
            "Iteration 53, loss = 0.25278809\n",
            "Iteration 54, loss = 0.25137061\n",
            "Iteration 55, loss = 0.24970564\n",
            "Iteration 56, loss = 0.24829448\n",
            "Iteration 57, loss = 0.24689775\n",
            "Iteration 58, loss = 0.24493711\n",
            "Iteration 59, loss = 0.24337006\n",
            "Iteration 60, loss = 0.24171343\n",
            "Iteration 61, loss = 0.23978733\n",
            "Iteration 62, loss = 0.23862663\n",
            "Iteration 63, loss = 0.23658792\n",
            "Iteration 64, loss = 0.23507897\n",
            "Iteration 65, loss = 0.23394200\n",
            "Iteration 66, loss = 0.23262056\n",
            "Iteration 67, loss = 0.23095292\n",
            "Iteration 68, loss = 0.22926654\n",
            "Iteration 69, loss = 0.22781433\n",
            "Iteration 70, loss = 0.22632922\n",
            "Iteration 71, loss = 0.22471288\n",
            "Iteration 72, loss = 0.22305544\n",
            "Iteration 73, loss = 0.22157259\n",
            "Iteration 74, loss = 0.22034049\n",
            "Iteration 75, loss = 0.21879070\n",
            "Iteration 76, loss = 0.21762111\n",
            "Iteration 77, loss = 0.21612988\n",
            "Iteration 78, loss = 0.21485087\n",
            "Iteration 79, loss = 0.21388153\n",
            "Iteration 80, loss = 0.21281055\n",
            "Iteration 81, loss = 0.21110279\n",
            "Iteration 82, loss = 0.20961457\n",
            "Iteration 83, loss = 0.20793903\n",
            "Iteration 84, loss = 0.20742399\n",
            "Iteration 85, loss = 0.20575136\n",
            "Iteration 86, loss = 0.20452249\n",
            "Iteration 87, loss = 0.20314296\n",
            "Iteration 88, loss = 0.20185478\n",
            "Iteration 89, loss = 0.20105038\n",
            "Iteration 90, loss = 0.19911288\n",
            "Iteration 91, loss = 0.19771467\n",
            "Iteration 92, loss = 0.19678118\n",
            "Iteration 93, loss = 0.19596612\n",
            "Iteration 94, loss = 0.19443996\n",
            "Iteration 95, loss = 0.19360920\n",
            "Iteration 96, loss = 0.19175399\n",
            "Iteration 97, loss = 0.19141127\n",
            "Iteration 98, loss = 0.18968199\n",
            "Iteration 99, loss = 0.18828152\n",
            "Iteration 100, loss = 0.18688858\n",
            "Iteration 101, loss = 0.18618246\n",
            "Iteration 102, loss = 0.18507624\n",
            "Iteration 103, loss = 0.18402844\n",
            "Iteration 104, loss = 0.18277875\n",
            "Iteration 105, loss = 0.18165297\n",
            "Iteration 106, loss = 0.18111627\n",
            "Iteration 107, loss = 0.17948919\n",
            "Iteration 108, loss = 0.17858627\n",
            "Iteration 109, loss = 0.17723595\n",
            "Iteration 110, loss = 0.17642337\n",
            "Iteration 111, loss = 0.17527532\n",
            "Iteration 112, loss = 0.17403370\n",
            "Iteration 113, loss = 0.17299248\n",
            "Iteration 114, loss = 0.17165184\n",
            "Iteration 115, loss = 0.17088859\n",
            "Iteration 116, loss = 0.16961489\n",
            "Iteration 117, loss = 0.16965907\n",
            "Iteration 118, loss = 0.16739936\n",
            "Iteration 119, loss = 0.16661911\n",
            "Iteration 120, loss = 0.16572497\n",
            "Iteration 121, loss = 0.16448875\n",
            "Iteration 122, loss = 0.16368829\n",
            "Iteration 123, loss = 0.16342292\n",
            "Iteration 124, loss = 0.16205530\n",
            "Iteration 125, loss = 0.16066651\n",
            "Iteration 126, loss = 0.15998385\n",
            "Iteration 127, loss = 0.15953964\n",
            "Iteration 128, loss = 0.15797938\n",
            "Iteration 129, loss = 0.15684762\n",
            "Iteration 130, loss = 0.15608225\n",
            "Iteration 131, loss = 0.15504695\n",
            "Iteration 132, loss = 0.15350601\n",
            "Iteration 133, loss = 0.15288684\n",
            "Iteration 134, loss = 0.15184571\n",
            "Iteration 135, loss = 0.15040124\n",
            "Iteration 136, loss = 0.14968016\n",
            "Iteration 137, loss = 0.14898355\n",
            "Iteration 138, loss = 0.14777173\n",
            "Iteration 139, loss = 0.14706807\n",
            "Iteration 140, loss = 0.14631929\n",
            "Iteration 141, loss = 0.14487181\n",
            "Iteration 142, loss = 0.14422156\n",
            "Iteration 143, loss = 0.14372198\n",
            "Iteration 144, loss = 0.14245441\n",
            "Iteration 145, loss = 0.14153182\n",
            "Iteration 146, loss = 0.14084285\n",
            "Iteration 147, loss = 0.13978320\n",
            "Iteration 148, loss = 0.13890996\n",
            "Iteration 149, loss = 0.13906996\n",
            "Iteration 150, loss = 0.13769701\n",
            "Iteration 151, loss = 0.13618014\n",
            "Iteration 152, loss = 0.13475562\n",
            "Iteration 153, loss = 0.13423195\n",
            "Iteration 154, loss = 0.13334224\n",
            "Iteration 155, loss = 0.13270445\n",
            "Iteration 156, loss = 0.13212179\n",
            "Iteration 157, loss = 0.13077935\n",
            "Iteration 158, loss = 0.12985201\n",
            "Iteration 159, loss = 0.12927073\n",
            "Iteration 160, loss = 0.12861480\n",
            "Iteration 161, loss = 0.12794367\n",
            "Iteration 162, loss = 0.12735840\n",
            "Iteration 163, loss = 0.12632454\n",
            "Iteration 164, loss = 0.12633166\n",
            "Iteration 165, loss = 0.12462491\n",
            "Iteration 166, loss = 0.12365781\n",
            "Iteration 167, loss = 0.12299164\n",
            "Iteration 168, loss = 0.12198838\n",
            "Iteration 169, loss = 0.12098792\n",
            "Iteration 170, loss = 0.12060448\n",
            "Iteration 171, loss = 0.11965068\n",
            "Iteration 172, loss = 0.11895937\n",
            "Iteration 173, loss = 0.11803000\n",
            "Iteration 174, loss = 0.11731720\n",
            "Iteration 175, loss = 0.11635228\n",
            "Iteration 176, loss = 0.11540198\n",
            "Iteration 177, loss = 0.11490455\n",
            "Iteration 178, loss = 0.11480290\n",
            "Iteration 179, loss = 0.11356816\n",
            "Iteration 180, loss = 0.11261920\n",
            "Iteration 181, loss = 0.11159767\n",
            "Iteration 182, loss = 0.11108757\n",
            "Iteration 183, loss = 0.11057488\n",
            "Iteration 184, loss = 0.10946527\n",
            "Iteration 185, loss = 0.10932050\n",
            "Iteration 186, loss = 0.10815370\n",
            "Iteration 187, loss = 0.10787844\n",
            "Iteration 188, loss = 0.10731312\n",
            "Iteration 189, loss = 0.10639715\n",
            "Iteration 190, loss = 0.10538245\n",
            "Iteration 191, loss = 0.10503199\n",
            "Iteration 192, loss = 0.10385195\n",
            "Iteration 193, loss = 0.10399480\n",
            "Iteration 194, loss = 0.10290919\n",
            "Iteration 195, loss = 0.10186080\n",
            "Iteration 196, loss = 0.10147209\n",
            "Iteration 197, loss = 0.10039872\n",
            "Iteration 198, loss = 0.09999404\n",
            "Iteration 199, loss = 0.09946340\n",
            "Iteration 200, loss = 0.09844797\n",
            "Iteration 201, loss = 0.09820003\n",
            "Iteration 202, loss = 0.09719536\n",
            "Iteration 203, loss = 0.09707956\n",
            "Iteration 204, loss = 0.09731283\n",
            "Iteration 205, loss = 0.09557085\n",
            "Iteration 206, loss = 0.09496385\n",
            "Iteration 207, loss = 0.09437424\n",
            "Iteration 208, loss = 0.09378164\n",
            "Iteration 209, loss = 0.09315501\n",
            "Iteration 210, loss = 0.09304903\n",
            "Iteration 211, loss = 0.09171766\n",
            "Iteration 212, loss = 0.09094756\n",
            "Iteration 213, loss = 0.09040797\n",
            "Iteration 214, loss = 0.09008339\n",
            "Iteration 215, loss = 0.09012245\n",
            "Iteration 216, loss = 0.08909699\n",
            "Iteration 217, loss = 0.08833982\n",
            "Iteration 218, loss = 0.08787296\n",
            "Iteration 219, loss = 0.08677335\n",
            "Iteration 220, loss = 0.08667155\n",
            "Iteration 221, loss = 0.08689886\n",
            "Iteration 222, loss = 0.08538618\n",
            "Iteration 223, loss = 0.08467151\n",
            "Iteration 224, loss = 0.08433474\n",
            "Iteration 225, loss = 0.08389600\n",
            "Iteration 226, loss = 0.08286629\n",
            "Iteration 227, loss = 0.08286715\n",
            "Iteration 228, loss = 0.08220526\n",
            "Iteration 229, loss = 0.08162784\n",
            "Iteration 230, loss = 0.08068113\n",
            "Iteration 231, loss = 0.08059391\n",
            "Iteration 232, loss = 0.07935729\n",
            "Iteration 233, loss = 0.07902859\n",
            "Iteration 234, loss = 0.07849246\n",
            "Iteration 235, loss = 0.07803432\n",
            "Iteration 236, loss = 0.07741682\n",
            "Iteration 237, loss = 0.07684288\n",
            "Iteration 238, loss = 0.07624596\n",
            "Iteration 239, loss = 0.07574233\n",
            "Iteration 240, loss = 0.07561786\n",
            "Iteration 241, loss = 0.07498802\n",
            "Iteration 242, loss = 0.07429137\n",
            "Iteration 243, loss = 0.07386822\n",
            "Iteration 244, loss = 0.07321926\n",
            "Iteration 245, loss = 0.07281172\n",
            "Iteration 246, loss = 0.07211930\n",
            "Iteration 247, loss = 0.07188478\n",
            "Iteration 248, loss = 0.07129717\n",
            "Iteration 249, loss = 0.07097894\n",
            "Iteration 250, loss = 0.07060669\n",
            "Iteration 251, loss = 0.07011070\n",
            "Iteration 252, loss = 0.06961860\n",
            "Iteration 253, loss = 0.06913616\n",
            "Iteration 254, loss = 0.06878890\n",
            "Iteration 255, loss = 0.06771840\n",
            "Iteration 256, loss = 0.06795427\n",
            "Iteration 257, loss = 0.06692700\n",
            "Iteration 258, loss = 0.06665806\n",
            "Iteration 259, loss = 0.06658142\n",
            "Iteration 260, loss = 0.06555363\n",
            "Iteration 261, loss = 0.06548510\n",
            "Iteration 262, loss = 0.06491240\n",
            "Iteration 263, loss = 0.06447996\n",
            "Iteration 264, loss = 0.06381616\n",
            "Iteration 265, loss = 0.06334313\n",
            "Iteration 266, loss = 0.06299370\n",
            "Iteration 267, loss = 0.06289956\n",
            "Iteration 268, loss = 0.06232439\n",
            "Iteration 269, loss = 0.06196870\n",
            "Iteration 270, loss = 0.06155448\n",
            "Iteration 271, loss = 0.06116775\n",
            "Iteration 272, loss = 0.06049403\n",
            "Iteration 273, loss = 0.05987208\n",
            "Iteration 274, loss = 0.05961964\n",
            "Iteration 275, loss = 0.05914561\n",
            "Iteration 276, loss = 0.05868025\n",
            "Iteration 277, loss = 0.05835858\n",
            "Iteration 278, loss = 0.05849299\n",
            "Iteration 279, loss = 0.05740398\n",
            "Iteration 280, loss = 0.05742516\n",
            "Iteration 281, loss = 0.05689740\n",
            "Iteration 282, loss = 0.05685564\n",
            "Iteration 283, loss = 0.05591544\n",
            "Iteration 284, loss = 0.05586757\n",
            "Iteration 285, loss = 0.05611245\n",
            "Iteration 286, loss = 0.05584227\n",
            "Iteration 287, loss = 0.05446844\n",
            "Iteration 288, loss = 0.05434634\n",
            "Iteration 289, loss = 0.05371371\n",
            "Iteration 290, loss = 0.05345901\n",
            "Iteration 291, loss = 0.05311386\n",
            "Iteration 292, loss = 0.05263255\n",
            "Iteration 293, loss = 0.05248574\n",
            "Iteration 294, loss = 0.05193911\n",
            "Iteration 295, loss = 0.05205854\n",
            "Iteration 296, loss = 0.05119142\n",
            "Iteration 297, loss = 0.05077712\n",
            "Iteration 298, loss = 0.05057179\n",
            "Iteration 299, loss = 0.05043825\n",
            "Iteration 300, loss = 0.04987328\n",
            "Iteration 301, loss = 0.04950943\n",
            "Iteration 302, loss = 0.04932185\n",
            "Iteration 303, loss = 0.04877585\n",
            "Iteration 304, loss = 0.04839942\n",
            "Iteration 305, loss = 0.04817414\n",
            "Iteration 306, loss = 0.04818805\n",
            "Iteration 307, loss = 0.04814173\n",
            "Iteration 308, loss = 0.04716000\n",
            "Iteration 309, loss = 0.04733898\n",
            "Iteration 310, loss = 0.04689274\n",
            "Iteration 311, loss = 0.04619312\n",
            "Iteration 312, loss = 0.04622210\n",
            "Iteration 313, loss = 0.04564225\n",
            "Iteration 314, loss = 0.04534429\n",
            "Iteration 315, loss = 0.04504463\n",
            "Iteration 316, loss = 0.04484383\n",
            "Iteration 317, loss = 0.04444397\n",
            "Iteration 318, loss = 0.04393040\n",
            "Iteration 319, loss = 0.04372358\n",
            "Iteration 320, loss = 0.04349743\n",
            "Iteration 321, loss = 0.04337608\n",
            "Iteration 322, loss = 0.04295354\n",
            "Iteration 323, loss = 0.04319086\n",
            "Iteration 324, loss = 0.04249017\n",
            "Iteration 325, loss = 0.04210366\n",
            "Iteration 326, loss = 0.04179460\n",
            "Iteration 327, loss = 0.04158024\n",
            "Iteration 328, loss = 0.04149931\n",
            "Iteration 329, loss = 0.04101088\n",
            "Iteration 330, loss = 0.04122869\n",
            "Iteration 331, loss = 0.04053557\n",
            "Iteration 332, loss = 0.03998916\n",
            "Iteration 333, loss = 0.03972324\n",
            "Iteration 334, loss = 0.03974014\n",
            "Iteration 335, loss = 0.03926150\n",
            "Iteration 336, loss = 0.03895261\n",
            "Iteration 337, loss = 0.03870991\n",
            "Iteration 338, loss = 0.03851501\n",
            "Iteration 339, loss = 0.03843422\n",
            "Iteration 340, loss = 0.03788333\n",
            "Iteration 341, loss = 0.03786262\n",
            "Iteration 342, loss = 0.03767665\n",
            "Iteration 343, loss = 0.03717842\n",
            "Iteration 344, loss = 0.03698905\n",
            "Iteration 345, loss = 0.03659922\n",
            "Iteration 346, loss = 0.03657456\n",
            "Iteration 347, loss = 0.03631726\n",
            "Iteration 348, loss = 0.03595635\n",
            "Iteration 349, loss = 0.03597787\n",
            "Iteration 350, loss = 0.03535157\n",
            "Iteration 351, loss = 0.03529478\n",
            "Iteration 352, loss = 0.03503874\n",
            "Iteration 353, loss = 0.03500987\n",
            "Iteration 354, loss = 0.03467691\n",
            "Iteration 355, loss = 0.03446365\n",
            "Iteration 356, loss = 0.03428448\n",
            "Iteration 357, loss = 0.03385447\n",
            "Iteration 358, loss = 0.03361047\n",
            "Iteration 359, loss = 0.03344057\n",
            "Iteration 360, loss = 0.03303403\n",
            "Iteration 361, loss = 0.03301765\n",
            "Iteration 362, loss = 0.03258793\n",
            "Iteration 363, loss = 0.03254182\n",
            "Iteration 364, loss = 0.03291444\n",
            "Iteration 365, loss = 0.03221712\n",
            "Iteration 366, loss = 0.03192815\n",
            "Iteration 367, loss = 0.03204987\n",
            "Iteration 368, loss = 0.03192432\n",
            "Iteration 369, loss = 0.03115409\n",
            "Iteration 370, loss = 0.03120162\n",
            "Iteration 371, loss = 0.03088548\n",
            "Iteration 372, loss = 0.03067371\n",
            "Iteration 373, loss = 0.03020842\n",
            "Iteration 374, loss = 0.03072086\n",
            "Iteration 375, loss = 0.03003344\n",
            "Iteration 376, loss = 0.02982477\n",
            "Iteration 377, loss = 0.02949388\n",
            "Iteration 378, loss = 0.02935835\n",
            "Iteration 379, loss = 0.02912501\n",
            "Iteration 380, loss = 0.02897694\n",
            "Iteration 381, loss = 0.02882393\n",
            "Iteration 382, loss = 0.02865387\n",
            "Iteration 383, loss = 0.02841198\n",
            "Iteration 384, loss = 0.02813041\n",
            "Iteration 385, loss = 0.02808272\n",
            "Iteration 386, loss = 0.02802717\n",
            "Iteration 387, loss = 0.02791383\n",
            "Iteration 388, loss = 0.02794887\n",
            "Iteration 389, loss = 0.02762923\n",
            "Iteration 390, loss = 0.02745190\n",
            "Iteration 391, loss = 0.02718188\n",
            "Iteration 392, loss = 0.02684429\n",
            "Iteration 393, loss = 0.02671696\n",
            "Iteration 394, loss = 0.02638662\n",
            "Iteration 395, loss = 0.02613418\n",
            "Iteration 396, loss = 0.02610920\n",
            "Iteration 397, loss = 0.02585268\n",
            "Iteration 398, loss = 0.02565122\n",
            "Iteration 399, loss = 0.02551122\n",
            "Iteration 400, loss = 0.02536881\n",
            "Iteration 401, loss = 0.02525210\n",
            "Iteration 402, loss = 0.02498551\n",
            "Iteration 403, loss = 0.02482203\n",
            "Iteration 404, loss = 0.02493375\n",
            "Iteration 405, loss = 0.02456875\n",
            "Iteration 406, loss = 0.02431129\n",
            "Iteration 407, loss = 0.02420539\n",
            "Iteration 408, loss = 0.02397882\n",
            "Iteration 409, loss = 0.02389382\n",
            "Iteration 410, loss = 0.02374541\n",
            "Iteration 411, loss = 0.02355157\n",
            "Iteration 412, loss = 0.02344461\n",
            "Iteration 413, loss = 0.02322870\n",
            "Iteration 414, loss = 0.02319285\n",
            "Iteration 415, loss = 0.02291269\n",
            "Iteration 416, loss = 0.02280973\n",
            "Iteration 417, loss = 0.02267955\n",
            "Iteration 418, loss = 0.02250919\n",
            "Iteration 419, loss = 0.02234557\n",
            "Iteration 420, loss = 0.02222936\n",
            "Iteration 421, loss = 0.02214264\n",
            "Iteration 422, loss = 0.02188046\n",
            "Iteration 423, loss = 0.02181550\n",
            "Iteration 424, loss = 0.02169224\n",
            "Iteration 425, loss = 0.02142953\n",
            "Iteration 426, loss = 0.02129628\n",
            "Iteration 427, loss = 0.02118017\n",
            "Iteration 428, loss = 0.02100257\n",
            "Iteration 429, loss = 0.02098969\n",
            "Iteration 430, loss = 0.02098583\n",
            "Iteration 431, loss = 0.02064319\n",
            "Iteration 432, loss = 0.02055560\n",
            "Iteration 433, loss = 0.02035337\n",
            "Iteration 434, loss = 0.02016586\n",
            "Iteration 435, loss = 0.02022504\n",
            "Iteration 436, loss = 0.02001296\n",
            "Iteration 437, loss = 0.01972282\n",
            "Iteration 438, loss = 0.01995183\n",
            "Iteration 439, loss = 0.02004690\n",
            "Iteration 440, loss = 0.01944615\n",
            "Iteration 441, loss = 0.01933168\n",
            "Iteration 442, loss = 0.01914921\n",
            "Iteration 443, loss = 0.01923002\n",
            "Iteration 444, loss = 0.01896167\n",
            "Iteration 445, loss = 0.01892211\n",
            "Iteration 446, loss = 0.01924088\n",
            "Iteration 447, loss = 0.01908984\n",
            "Iteration 448, loss = 0.01850476\n",
            "Iteration 449, loss = 0.01830550\n",
            "Iteration 450, loss = 0.01813756\n",
            "Iteration 451, loss = 0.01815092\n",
            "Iteration 452, loss = 0.01792386\n",
            "Iteration 453, loss = 0.01790503\n",
            "Iteration 454, loss = 0.01765654\n",
            "Iteration 455, loss = 0.01753747\n",
            "Iteration 456, loss = 0.01759066\n",
            "Iteration 457, loss = 0.01745440\n",
            "Iteration 458, loss = 0.01730037\n",
            "Iteration 459, loss = 0.01753620\n",
            "Iteration 460, loss = 0.01712191\n",
            "Iteration 461, loss = 0.01692855\n",
            "Iteration 462, loss = 0.01677152\n",
            "Iteration 463, loss = 0.01676818\n",
            "Iteration 464, loss = 0.01673276\n",
            "Iteration 465, loss = 0.01666905\n",
            "Iteration 466, loss = 0.01627905\n",
            "Iteration 467, loss = 0.01626856\n",
            "Iteration 468, loss = 0.01611168\n",
            "Iteration 469, loss = 0.01606766\n",
            "Iteration 470, loss = 0.01588434\n",
            "Iteration 471, loss = 0.01600542\n",
            "Iteration 472, loss = 0.01584561\n",
            "Iteration 473, loss = 0.01564673\n",
            "Iteration 474, loss = 0.01556544\n",
            "Iteration 475, loss = 0.01570090\n",
            "Iteration 476, loss = 0.01554390\n",
            "Iteration 477, loss = 0.01541345\n",
            "Iteration 478, loss = 0.01531427\n",
            "Iteration 479, loss = 0.01536940\n",
            "Iteration 480, loss = 0.01516412\n",
            "Iteration 481, loss = 0.01485461\n",
            "Iteration 482, loss = 0.01484412\n",
            "Iteration 483, loss = 0.01461120\n",
            "Iteration 484, loss = 0.01451897\n",
            "Iteration 485, loss = 0.01446799\n",
            "Iteration 486, loss = 0.01446825\n",
            "Iteration 487, loss = 0.01420207\n",
            "Iteration 488, loss = 0.01414906\n",
            "Iteration 489, loss = 0.01416605\n",
            "Iteration 490, loss = 0.01390710\n",
            "Iteration 491, loss = 0.01400648\n",
            "Iteration 492, loss = 0.01381732\n",
            "Iteration 493, loss = 0.01378328\n",
            "Iteration 494, loss = 0.01369837\n",
            "Iteration 495, loss = 0.01355649\n",
            "Iteration 496, loss = 0.01341056\n",
            "Iteration 497, loss = 0.01337117\n",
            "Iteration 498, loss = 0.01322015\n",
            "Iteration 499, loss = 0.01320803\n",
            "Iteration 500, loss = 0.01305584\n",
            "Iteration 501, loss = 0.01308841\n",
            "Iteration 502, loss = 0.01293134\n",
            "Iteration 503, loss = 0.01285972\n",
            "Iteration 504, loss = 0.01273628\n",
            "Iteration 505, loss = 0.01266333\n",
            "Iteration 506, loss = 0.01261061\n",
            "Iteration 507, loss = 0.01247001\n",
            "Iteration 508, loss = 0.01256255\n",
            "Iteration 509, loss = 0.01250814\n",
            "Iteration 510, loss = 0.01230909\n",
            "Iteration 511, loss = 0.01229191\n",
            "Iteration 512, loss = 0.01213683\n",
            "Iteration 513, loss = 0.01214313\n",
            "Iteration 514, loss = 0.01189801\n",
            "Iteration 515, loss = 0.01186511\n",
            "Iteration 516, loss = 0.01177114\n",
            "Iteration 517, loss = 0.01173345\n",
            "Iteration 518, loss = 0.01155846\n",
            "Iteration 519, loss = 0.01158745\n",
            "Iteration 520, loss = 0.01159469\n",
            "Iteration 521, loss = 0.01161146\n",
            "Iteration 522, loss = 0.01144967\n",
            "Iteration 523, loss = 0.01135594\n",
            "Iteration 524, loss = 0.01124249\n",
            "Iteration 525, loss = 0.01112823\n",
            "Iteration 526, loss = 0.01118493\n",
            "Iteration 527, loss = 0.01106138\n",
            "Iteration 528, loss = 0.01103201\n",
            "Iteration 529, loss = 0.01090740\n",
            "Iteration 530, loss = 0.01097058\n",
            "Iteration 531, loss = 0.01077258\n",
            "Iteration 532, loss = 0.01068062\n",
            "Iteration 533, loss = 0.01056770\n",
            "Iteration 534, loss = 0.01048548\n",
            "Iteration 535, loss = 0.01042600\n",
            "Iteration 536, loss = 0.01060494\n",
            "Iteration 537, loss = 0.01083635\n",
            "Iteration 538, loss = 0.01037197\n",
            "Iteration 539, loss = 0.01019597\n",
            "Iteration 540, loss = 0.01008449\n",
            "Iteration 541, loss = 0.01001939\n",
            "Iteration 542, loss = 0.01006051\n",
            "Iteration 543, loss = 0.01003367\n",
            "Iteration 544, loss = 0.00982807\n",
            "Iteration 545, loss = 0.00978178\n",
            "Iteration 546, loss = 0.00974786\n",
            "Iteration 547, loss = 0.00960506\n",
            "Iteration 548, loss = 0.00959665\n",
            "Iteration 549, loss = 0.00958820\n",
            "Iteration 550, loss = 0.00944865\n",
            "Iteration 551, loss = 0.00945665\n",
            "Iteration 552, loss = 0.00935001\n",
            "Iteration 553, loss = 0.00934108\n",
            "Iteration 554, loss = 0.00926394\n",
            "Iteration 555, loss = 0.00918988\n",
            "Iteration 556, loss = 0.00909798\n",
            "Iteration 557, loss = 0.00907337\n",
            "Iteration 558, loss = 0.00916611\n",
            "Iteration 559, loss = 0.00901680\n",
            "Iteration 560, loss = 0.00895914\n",
            "Iteration 561, loss = 0.00898690\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                     batch_size='auto', beta_1=0.9,\n",
              "                                     beta_2=0.999, early_stopping=False,\n",
              "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
              "                                     learning_rate='constant',\n",
              "                                     learning_rate_init=0.001, max_fun=15000,\n",
              "                                     max_iter=200, momentum=0.9,\n",
              "                                     n_iter_no_change=10,\n",
              "                                     nesterovs_momentum=True, power_t=0.5,\n",
              "                                     random_state=None, shuffle=True,\n",
              "                                     solver='adam', tol=0.0001,\n",
              "                                     validation_fraction=0.1, verbose=False,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'activation': ['relu'], 'hidden_layer_sizes': [100],\n",
              "                         'max_iter': [10000], 'solver': ['sgd', 'adam'],\n",
              "                         'tol': [0.0001], 'verbose': [True]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c21e80e7-de0c-4d4e-89a3-96ee88db5a59",
        "outputId": "3f4c585b-c9fd-4ceb-f68c-8b22b572ef9e"
      },
      "source": [
        "nn_gs.best_params_"
      ],
      "id": "c21e80e7-de0c-4d4e-89a3-96ee88db5a59",
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'hidden_layer_sizes': 100,\n",
              " 'max_iter': 10000,\n",
              " 'solver': 'adam',\n",
              " 'tol': 0.0001,\n",
              " 'verbose': True}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99e19d49-b55f-42d4-98e3-a923bd789dc0",
        "outputId": "ec279f17-b938-478e-e320-246766504b89"
      },
      "source": [
        "best_nn = nn_gs.best_estimator_\n",
        "best_nn"
      ],
      "id": "99e19d49-b55f-42d4-98e3-a923bd789dc0",
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=100, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=10000,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77b3aeef-6596-4a30-8d2a-981898b7e80a"
      },
      "source": [
        "ytrain_predict = best_nn.predict(X_train_s)\n",
        "ytest_predict = best_nn.predict(X_test_s)"
      ],
      "id": "77b3aeef-6596-4a30-8d2a-981898b7e80a",
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d01f35e-9ee5-41ca-ad11-d02135257d05",
        "outputId": "ab84bb11-c07e-4715-d7f2-1489a8acbe25"
      },
      "source": [
        "#Train data Confusion Matrix\n",
        "print(confusion_matrix(train_labels, ytrain_predict))\n",
        "#Train Data Accuracy\n",
        "print(best_rf.score(X_train,train_labels) )\n",
        "print(classification_report(train_labels, ytrain_predict))"
      ],
      "id": "1d01f35e-9ee5-41ca-ad11-d02135257d05",
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1737    0]\n",
            " [   0  321]]\n",
            "0.8620019436345967\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1737\n",
            "           1       1.00      1.00      1.00       321\n",
            "\n",
            "    accuracy                           1.00      2058\n",
            "   macro avg       1.00      1.00      1.00      2058\n",
            "weighted avg       1.00      1.00      1.00      2058\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b2e9642-d9c3-4b06-ae5e-d6c2f5ee44fd",
        "outputId": "3f56116c-18e6-4e29-847d-2c48952fda9f"
      },
      "source": [
        "#Test data Confusion Matrix\n",
        "print(confusion_matrix(test_labels, ytest_predict))\n",
        "#Test Data Accuracy\n",
        "print(best_rf.score(X_test,test_labels) )\n",
        "print(classification_report(test_labels, ytest_predict))"
      ],
      "id": "1b2e9642-d9c3-4b06-ae5e-d6c2f5ee44fd",
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[707  22]\n",
            " [ 38 115]]\n",
            "0.8412698412698413\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       729\n",
            "           1       0.84      0.75      0.79       153\n",
            "\n",
            "    accuracy                           0.93       882\n",
            "   macro avg       0.89      0.86      0.88       882\n",
            "weighted avg       0.93      0.93      0.93       882\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11480103-be84-40a4-b0b7-95a7362371c9",
        "outputId": "e98facf1-c341-4455-fc8b-b5420bb9bf57"
      },
      "source": [
        "probs = best_nn.predict_proba(X_train_s)[:,1]\n",
        "auc_train = roc_auc_score(train_labels, probs)\n",
        "print(auc_train)\n",
        "fpr, tpr, thresholds = roc_curve(train_labels, probs)"
      ],
      "id": "11480103-be84-40a4-b0b7-95a7362371c9",
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3476a36a-1f78-4393-970b-a596d3741311",
        "outputId": "49e60532-2d39-4dec-8420-2626fbfa1517"
      },
      "source": [
        "# calculate the g-mean for each threshold\n",
        "gmeans = np.sqrt(tpr * (1-fpr))\n",
        "# locate the index of the largest g-mean\n",
        "ix = np.argmax(gmeans)\n",
        "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))"
      ],
      "id": "3476a36a-1f78-4393-970b-a596d3741311",
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold=0.749029, G-Mean=1.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "sTV1MoVUj72x",
        "outputId": "ba4152ca-e1d4-4106-cc2a-68efc5a0da2f"
      },
      "source": [
        "# plot the roc curve for the model\n",
        "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
        "plt.plot(fpr, tpr, marker='.', label='Logistic')\n",
        "plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
        "# axis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "id": "sTV1MoVUj72x",
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNuTv_tWkTTU",
        "outputId": "b312b20e-4f8f-470b-cc12-7377722a77f3"
      },
      "source": [
        "probt = best_nn.predict_proba(X_test_s)[:,1]\n",
        "auc_test = roc_auc_score(test_labels, probt)\n",
        "print(auc_test)\n",
        "fpr, tpr, thresholds = roc_curve(test_labels, probt)"
      ],
      "id": "lNuTv_tWkTTU",
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8764356222598778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBN36gPLkdzY",
        "outputId": "6a6d8209-4fca-4720-f28c-798ffb458746"
      },
      "source": [
        "# calculate the g-mean for each threshold\n",
        "gmeans = np.sqrt(tpr * (1-fpr))\n",
        "# locate the index of the largest g-mean\n",
        "ix = np.argmax(gmeans)\n",
        "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))"
      ],
      "id": "hBN36gPLkdzY",
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold=0.749029, G-Mean=0.860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "b168f271-2f01-4846-b8a4-7ea498177bbb",
        "outputId": "efbcc72d-e1ee-4078-a1fe-8649341518de"
      },
      "source": [
        "# plot the roc curve for the model\n",
        "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
        "plt.plot(fpr, tpr, marker='.', label='Logistic')\n",
        "plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
        "# axis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "id": "b168f271-2f01-4846-b8a4-7ea498177bbb",
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL71iVXHfVDv"
      },
      "source": [
        ""
      ],
      "id": "OL71iVXHfVDv",
      "execution_count": null,
      "outputs": []
    }
  ]
}
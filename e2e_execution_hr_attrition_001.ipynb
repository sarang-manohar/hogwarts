{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "e2e_execution_hr_attrition_001.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "55a39db2-7389-444a-a894-be9ff9cc343e"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, classification_report, confusion_matrix\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "id": "55a39db2-7389-444a-a894-be9ff9cc343e",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8018fa01-7bef-454b-abf6-6be090bb3316",
        "outputId": "ae137e66-0c48-4587-fc19-c60ff2af4e97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "raw_data = pd.read_csv(r'HR_Employee_Attrition_Data.csv')\n",
        "raw_data.head()"
      ],
      "id": "8018fa01-7bef-454b-abf6-6be090bb3316",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Attrition</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EmployeeCount</th>\n",
              "      <th>EmployeeNumber</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>JobLevel</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>MonthlyRate</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>PercentSalaryHike</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StandardHours</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>1102</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>94</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5993</td>\n",
              "      <td>19479</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>279</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>61</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5130</td>\n",
              "      <td>24907</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>1373</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>92</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2090</td>\n",
              "      <td>2396</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>1392</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>56</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2909</td>\n",
              "      <td>23159</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>591</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3468</td>\n",
              "      <td>16632</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age  Attrition  ...  YearsSinceLastPromotion  YearsWithCurrManager\n",
              "0   41          1  ...                        0                     5\n",
              "1   49          0  ...                        1                     7\n",
              "2   37          1  ...                        0                     0\n",
              "3   33          0  ...                        3                     0\n",
              "4   27          0  ...                        2                     2\n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac5238e0-4e0a-4b6e-b90c-2cbf006e8ed1",
        "outputId": "12c7910b-ee4e-4d8f-c768-3e3d433be5ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "raw_data.info()"
      ],
      "id": "ac5238e0-4e0a-4b6e-b90c-2cbf006e8ed1",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2940 entries, 0 to 2939\n",
            "Data columns (total 27 columns):\n",
            " #   Column                    Non-Null Count  Dtype\n",
            "---  ------                    --------------  -----\n",
            " 0   Age                       2940 non-null   int64\n",
            " 1   Attrition                 2940 non-null   int64\n",
            " 2   DailyRate                 2940 non-null   int64\n",
            " 3   DistanceFromHome          2940 non-null   int64\n",
            " 4   Education                 2940 non-null   int64\n",
            " 5   EmployeeCount             2940 non-null   int64\n",
            " 6   EmployeeNumber            2940 non-null   int64\n",
            " 7   EnvironmentSatisfaction   2940 non-null   int64\n",
            " 8   HourlyRate                2940 non-null   int64\n",
            " 9   JobInvolvement            2940 non-null   int64\n",
            " 10  JobLevel                  2940 non-null   int64\n",
            " 11  JobSatisfaction           2940 non-null   int64\n",
            " 12  MonthlyIncome             2940 non-null   int64\n",
            " 13  MonthlyRate               2940 non-null   int64\n",
            " 14  NumCompaniesWorked        2940 non-null   int64\n",
            " 15  PercentSalaryHike         2940 non-null   int64\n",
            " 16  PerformanceRating         2940 non-null   int64\n",
            " 17  RelationshipSatisfaction  2940 non-null   int64\n",
            " 18  StandardHours             2940 non-null   int64\n",
            " 19  StockOptionLevel          2940 non-null   int64\n",
            " 20  TotalWorkingYears         2940 non-null   int64\n",
            " 21  TrainingTimesLastYear     2940 non-null   int64\n",
            " 22  WorkLifeBalance           2940 non-null   int64\n",
            " 23  YearsAtCompany            2940 non-null   int64\n",
            " 24  YearsInCurrentRole        2940 non-null   int64\n",
            " 25  YearsSinceLastPromotion   2940 non-null   int64\n",
            " 26  YearsWithCurrManager      2940 non-null   int64\n",
            "dtypes: int64(27)\n",
            "memory usage: 620.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d75fa6b-6631-4f7b-a8d9-0cd461adc829"
      },
      "source": [
        "raw_data = raw_data.drop(['EmployeeCount','EmployeeNumber'], axis=1)"
      ],
      "id": "6d75fa6b-6631-4f7b-a8d9-0cd461adc829",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26430b62-0e83-4eb2-8707-d4ce44e452fc",
        "outputId": "143c8c9a-e701-4151-eb8e-f778f4eb6436",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "raw_data.shape"
      ],
      "id": "26430b62-0e83-4eb2-8707-d4ce44e452fc",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2940, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c596eda-2164-4a25-83ff-fabe7aea668e"
      },
      "source": [
        "X = raw_data.drop(['Attrition'], axis=1)\n",
        "y = raw_data.pop('Attrition')"
      ],
      "id": "5c596eda-2164-4a25-83ff-fabe7aea668e",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29a31ffa-7d93-4fc0-9411-25b02b5300f1"
      },
      "source": [
        "X_train, X_test, train_labels, test_labels = train_test_split(X,y,test_size=0.3, random_state=1)"
      ],
      "id": "29a31ffa-7d93-4fc0-9411-25b02b5300f1",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7230a55-8b55-4b35-b5a5-f643e7bb641f"
      },
      "source": [
        "dt = DecisionTreeClassifier(criterion='gini')"
      ],
      "id": "d7230a55-8b55-4b35-b5a5-f643e7bb641f",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9cf9115-90b9-40d5-bb9f-c327c7527871",
        "outputId": "e5f12c6e-86e1-45bc-c996-5a03cb339828",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dt.fit(X_train, train_labels)"
      ],
      "id": "f9cf9115-90b9-40d5-bb9f-c327c7527871",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66454820-5f08-4c9f-9822-b51df824c42b"
      },
      "source": [
        "from sklearn import tree"
      ],
      "id": "66454820-5f08-4c9f-9822-b51df824c42b",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fe93856-26d7-45cd-8780-9e070ffe3eae"
      },
      "source": [
        "train_char_labels = ['No','Yes']\n",
        "\n",
        "tree_graph = open(r'./hr_attrition_dt.dot','w')\n",
        "\n",
        "dot_data = tree.export_graphviz(dt, out_file = tree_graph, feature_names = list(X_train), class_names = train_char_labels)\n",
        "\n",
        "tree_graph.close()"
      ],
      "id": "4fe93856-26d7-45cd-8780-9e070ffe3eae",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbc983d2-593f-4935-8509-337a7b85d127",
        "outputId": "f2dfe47b-7e90-47bb-8341-0d8745f80b75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        }
      },
      "source": [
        "importances = pd.DataFrame(dt.feature_importances_, columns = ['Imp'], index = X_train.columns)\n",
        "importances['features'] = pd.DataFrame(dt.feature_importances_, columns = ['Imp'], index = X_train.columns).index\n",
        "importances.reset_index\n",
        "\n",
        "importances = importances.sort_values(by='Imp', ascending=False)\n",
        "importances.set_index(np.arange(0,importances.shape[0]),inplace = True)\n",
        "\n",
        "importances['cumsum'] = np.cumsum(importances.Imp)\n",
        "x_vals = list(range(len(importances)))\n",
        "\n",
        "sns.barplot(data = importances, x='features', y='Imp')\n",
        "plt.xticks(x_vals, importances['features'], rotation='vertical')\n",
        "plt.ylabel('Importance'); plt.xlabel('Features'); plt.title('Feature Importance');\n",
        "plt.show()\n",
        "\n",
        "plt.plot(x_vals, importances['cumsum'], 'g-')\n",
        "plt.hlines(y = 0.95, xmin=0, xmax=len(importances), color = 'r', linestyles = 'dashed')\n",
        "plt.xticks(x_vals, importances['features'], rotation='vertical')\n",
        "plt.ylabel('Importance'); plt.xlabel('Features'); plt.title('Cumulative Importance');\n",
        "plt.show()"
      ],
      "id": "bbc983d2-593f-4935-8509-337a7b85d127",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65d26ccb-47c4-4bc5-8ce5-69408264b8f2"
      },
      "source": [
        "dt_param_grid = {\n",
        "    'max_depth' : [5,6,7,8,9,10,11,12],\n",
        "    'min_samples_leaf' : [15,20,25,30],\n",
        "    'min_samples_split' : [50,60,75,90,100]\n",
        "}"
      ],
      "id": "65d26ccb-47c4-4bc5-8ce5-69408264b8f2",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "037c2d2f-358f-4211-91fe-007a35cceb53"
      },
      "source": [
        "dt_ht = DecisionTreeClassifier()"
      ],
      "id": "037c2d2f-358f-4211-91fe-007a35cceb53",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f64ba3e1-a662-4770-bd52-330451e41120"
      },
      "source": [
        "dt_gs = GridSearchCV(estimator=dt_ht, param_grid=dt_param_grid, cv = 3)"
      ],
      "id": "f64ba3e1-a662-4770-bd52-330451e41120",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "368d56b0-126e-40d4-9def-e777a0e78390",
        "outputId": "309b9f38-6d91-4159-d691-3e6640a0a159",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dt_gs.fit(X_train, train_labels)"
      ],
      "id": "368d56b0-126e-40d4-9def-e777a0e78390",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features=None,\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              presort='deprecated',\n",
              "                                              random_state=None,\n",
              "                                              splitter='best'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'max_depth': [5, 6, 7, 8, 9, 10, 11, 12],\n",
              "                         'min_samples_leaf': [15, 20, 25, 30],\n",
              "                         'min_samples_split': [50, 60, 75, 90, 100]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdb93f86-b9ab-465c-8315-1a2c77e90705",
        "outputId": "2d28ca77-e8cc-4229-b623-73d63d516939",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dt_gs.best_params_"
      ],
      "id": "cdb93f86-b9ab-465c-8315-1a2c77e90705",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 6, 'min_samples_leaf': 20, 'min_samples_split': 50}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5650ffb-b04a-45d4-a13e-24144cb5b97c"
      },
      "source": [
        "best_dt = dt_gs.best_estimator_"
      ],
      "id": "d5650ffb-b04a-45d4-a13e-24144cb5b97c",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b145b80-7bdf-4104-86f0-71f65aa2ccbe"
      },
      "source": [
        "ytrain_predict = best_dt.predict(X_train)\n",
        "ytest_predict = best_dt.predict(X_test)"
      ],
      "id": "6b145b80-7bdf-4104-86f0-71f65aa2ccbe",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd8aedd7-3504-4166-b6f9-93cf1306576d",
        "outputId": "97d498a8-4204-4184-b7a9-73505b56eabf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Train data Confusion Matrix\n",
        "print(confusion_matrix(train_labels, ytrain_predict))\n",
        "#Train Data Accuracy\n",
        "print(best_dt.score(X_train,train_labels) )\n",
        "print(classification_report(train_labels, ytrain_predict))"
      ],
      "id": "bd8aedd7-3504-4166-b6f9-93cf1306576d",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1691   46]\n",
            " [ 226   95]]\n",
            "0.8678328474246841\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.93      1737\n",
            "           1       0.67      0.30      0.41       321\n",
            "\n",
            "    accuracy                           0.87      2058\n",
            "   macro avg       0.78      0.63      0.67      2058\n",
            "weighted avg       0.85      0.87      0.85      2058\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f14f508-c72a-454e-b969-3434abb83acb",
        "outputId": "cf34d582-7186-4bbf-d4a6-f9853c29c1fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Test data Confusion Matrix\n",
        "print(confusion_matrix(test_labels, ytest_predict))\n",
        "#Test Data Accuracy\n",
        "print(best_dt.score(X_test,test_labels) )\n",
        "print(classification_report(test_labels, ytest_predict))"
      ],
      "id": "7f14f508-c72a-454e-b969-3434abb83acb",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[701  28]\n",
            " [122  31]]\n",
            "0.8299319727891157\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.96      0.90       729\n",
            "           1       0.53      0.20      0.29       153\n",
            "\n",
            "    accuracy                           0.83       882\n",
            "   macro avg       0.69      0.58      0.60       882\n",
            "weighted avg       0.80      0.83      0.80       882\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "505a8928-422e-427e-bc6e-f6e1856cf132",
        "outputId": "5a5b5025-bb7a-4f6e-9812-be98c70ebad1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "probs = best_dt.predict_proba(X_train)[:,1]\n",
        "auc_dev = roc_auc_score(train_labels, probs)\n",
        "print(auc_dev)\n",
        "fpr, tpr, thresholds = roc_curve(train_labels, probs)"
      ],
      "id": "505a8928-422e-427e-bc6e-f6e1856cf132",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8705595819052794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7288a344-4bfc-481e-89e2-0447dd7204e9",
        "outputId": "871ab16b-7fb1-4137-8e62-2047984361db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# calculate the g-mean for each threshold\n",
        "gmeans = np.sqrt(tpr * (1-fpr))\n",
        "# locate the index of the largest g-mean\n",
        "ix = np.argmax(gmeans)\n",
        "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))"
      ],
      "id": "7288a344-4bfc-481e-89e2-0447dd7204e9",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold=0.208333, G-Mean=0.800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cee31cfa-6d19-481c-9d47-2ae7b5f3a5ed",
        "outputId": "adae22bc-ecd4-4af1-8d18-05d053cb6ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# plot the roc curve for the model\n",
        "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
        "plt.plot(fpr, tpr, marker='.', label='Logistic')\n",
        "plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
        "# axis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "id": "cee31cfa-6d19-481c-9d47-2ae7b5f3a5ed",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64e30271-30db-43a3-8dbe-a4df2b273633"
      },
      "source": [
        "rf_param_grid = {\n",
        "    'max_depth' : [5,6],\n",
        "    'min_samples_leaf' : [10,15,20,30],\n",
        "    'min_samples_split' : [40,50,60],\n",
        "    'max_features' : [5,6],\n",
        "    'n_estimators' : [100]\n",
        "}"
      ],
      "id": "64e30271-30db-43a3-8dbe-a4df2b273633",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a0e889a-a0a7-4e08-bb32-a1a8de6dfa83",
        "outputId": "ffcb4e8e-b534-4642-f493-c37166bc9c67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rf_ht = RandomForestClassifier()\n",
        "rf_gs = GridSearchCV(estimator=rf_ht, param_grid=rf_param_grid, cv = 3)\n",
        "rf_gs.fit(X_train, train_labels)"
      ],
      "id": "8a0e889a-a0a7-4e08-bb32-a1a8de6dfa83",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'max_depth': [5, 6], 'max_features': [5, 6],\n",
              "                         'min_samples_leaf': [10, 15, 20, 30],\n",
              "                         'min_samples_split': [40, 50, 60],\n",
              "                         'n_estimators': [100]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf9408af-927c-4062-be04-8db3553327cc",
        "outputId": "5e9f99ba-10d1-4dd9-b5c3-05d6c9a32877",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rf_gs.best_params_"
      ],
      "id": "bf9408af-927c-4062-be04-8db3553327cc",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 6,\n",
              " 'max_features': 6,\n",
              " 'min_samples_leaf': 10,\n",
              " 'min_samples_split': 40,\n",
              " 'n_estimators': 100}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "632d2ad6-0c51-46b8-923b-52c9f1a9617f"
      },
      "source": [
        "best_rf = rf_gs.best_estimator_"
      ],
      "id": "632d2ad6-0c51-46b8-923b-52c9f1a9617f",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdb431d5-bf4f-4376-886a-54b45a4e7027"
      },
      "source": [
        "ytrain_predict = best_rf.predict(X_train)\n",
        "ytest_predict = best_rf.predict(X_test)"
      ],
      "id": "bdb431d5-bf4f-4376-886a-54b45a4e7027",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a5c679a-476d-4c80-a37b-ec405315323b",
        "outputId": "b96b6ded-6eb7-450d-b2e3-b9053b2ba548",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Train data Confusion Matrix\n",
        "print(confusion_matrix(train_labels, ytrain_predict))\n",
        "#Train Data Accuracy\n",
        "print(best_rf.score(X_train,train_labels) )\n",
        "print(classification_report(train_labels, ytrain_predict))"
      ],
      "id": "8a5c679a-476d-4c80-a37b-ec405315323b",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1733    4]\n",
            " [ 280   41]]\n",
            "0.8620019436345967\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      1.00      0.92      1737\n",
            "           1       0.91      0.13      0.22       321\n",
            "\n",
            "    accuracy                           0.86      2058\n",
            "   macro avg       0.89      0.56      0.57      2058\n",
            "weighted avg       0.87      0.86      0.82      2058\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a0c4b5f-fdd7-42c6-92ad-052ec03f1b56",
        "outputId": "08bd3992-af89-4afb-a77d-080c238786d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Test data Confusion Matrix\n",
        "print(confusion_matrix(test_labels, ytest_predict))\n",
        "#Test Data Accuracy\n",
        "print(best_rf.score(X_test,test_labels) )\n",
        "print(classification_report(test_labels, ytest_predict))"
      ],
      "id": "4a0c4b5f-fdd7-42c6-92ad-052ec03f1b56",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[725   4]\n",
            " [136  17]]\n",
            "0.8412698412698413\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.99      0.91       729\n",
            "           1       0.81      0.11      0.20       153\n",
            "\n",
            "    accuracy                           0.84       882\n",
            "   macro avg       0.83      0.55      0.55       882\n",
            "weighted avg       0.84      0.84      0.79       882\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c792f04c-a1b9-4195-9e6b-ede5185419c4",
        "outputId": "1ff1fbb9-85b7-4204-def2-36c2ff8385c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "probs = best_rf.predict_proba(X_train)[:,1]\n",
        "auc_dev = roc_auc_score(train_labels, probs)\n",
        "print(auc_dev)\n",
        "fpr, tpr, thresholds = roc_curve(train_labels, probs)"
      ],
      "id": "c792f04c-a1b9-4195-9e6b-ede5185419c4",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9173262168274516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "656330b2-c261-4cc9-be41-ba9e32489823",
        "outputId": "974eed6c-8595-4d63-b9f9-cd1871b52147",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# calculate the g-mean for each threshold\n",
        "gmeans = np.sqrt(tpr * (1-fpr))\n",
        "# locate the index of the largest g-mean\n",
        "ix = np.argmax(gmeans)\n",
        "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))"
      ],
      "id": "656330b2-c261-4cc9-be41-ba9e32489823",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold=0.180213, G-Mean=0.846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a3725c9-cd0a-4536-9570-56420ab8c09d",
        "outputId": "2c082342-42ff-4bf0-cf5c-2085bfe5b190",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# plot the roc curve for the model\n",
        "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
        "plt.plot(fpr, tpr, marker='.', label='Logistic')\n",
        "plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
        "# axis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "id": "2a3725c9-cd0a-4536-9570-56420ab8c09d",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4212c0a4-4a90-49c7-8c47-00a7f9d421f4"
      },
      "source": [
        "ss = StandardScaler()"
      ],
      "id": "4212c0a4-4a90-49c7-8c47-00a7f9d421f4",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2744fae-49c1-4757-b908-5453e466d6c5"
      },
      "source": [
        "X_train_s = ss.fit_transform(X_train)"
      ],
      "id": "e2744fae-49c1-4757-b908-5453e466d6c5",
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0193b0d-3fd7-400d-ad3e-ec542b555a7b"
      },
      "source": [
        "X_test_s = ss.transform(X_test)"
      ],
      "id": "d0193b0d-3fd7-400d-ad3e-ec542b555a7b",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "b91f62b2-8879-4ba2-bf02-7edc51522c78",
        "outputId": "82206e28-5d6a-4978-a6d3-8f078eacbade",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train_s"
      ],
      "id": "b91f62b2-8879-4ba2-bf02-7edc51522c78",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.75904517,  1.04289644, -0.27238444, ...,  0.76397248,\n",
              "         0.56720724,  0.82525338],\n",
              "       [ 0.2198339 , -1.64621765, -0.76671175, ..., -0.33955822,\n",
              "         0.25683434,  0.54043509],\n",
              "       [-0.10999708, -0.5899575 ,  1.08701567, ..., -1.16720624,\n",
              "        -0.67428439, -1.16847464],\n",
              "       ...,\n",
              "       [ 0.32977756,  0.23516808, -0.39596627, ...,  0.76397248,\n",
              "         1.49832597,  0.82525338],\n",
              "       [ 0.65960855,  0.57317133,  0.83985201, ...,  2.41926852,\n",
              "        -0.36391148,  1.39488995],\n",
              "       [-1.42932103,  0.06616646,  0.46910653, ..., -1.16720624,\n",
              "        -0.67428439, -1.16847464]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3f29f02-3703-4337-9ad7-fc91b393db40"
      },
      "source": [
        "nn_param_grid = {\n",
        "    'hidden_layer_sizes' : [100,100,100],\n",
        "    'activation' : ['relu'],\n",
        "    'solver' : ['adam'],\n",
        "    'max_iter' : [10000],\n",
        "    'tol' : [0.00001],\n",
        "    'verbose' : [True]\n",
        "}"
      ],
      "id": "f3f29f02-3703-4337-9ad7-fc91b393db40",
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6439aafe-99bb-402c-9c9d-455eed4e76da",
        "outputId": "bbb930d1-c7c3-4d10-db62-649b622c3eb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nn_ht = MLPClassifier()\n",
        "nn_gs = GridSearchCV(estimator=nn_ht, param_grid=nn_param_grid, cv = 3)\n",
        "nn_gs.fit(X_train_s, train_labels)"
      ],
      "id": "6439aafe-99bb-402c-9c9d-455eed4e76da",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Iteration 825, loss = 0.00407316\n",
            "Iteration 826, loss = 0.00409246\n",
            "Iteration 827, loss = 0.00405167\n",
            "Iteration 828, loss = 0.00403554\n",
            "Iteration 829, loss = 0.00405583\n",
            "Iteration 830, loss = 0.00399728\n",
            "Iteration 831, loss = 0.00397591\n",
            "Iteration 832, loss = 0.00396267\n",
            "Iteration 833, loss = 0.00393476\n",
            "Iteration 834, loss = 0.00392904\n",
            "Iteration 835, loss = 0.00388489\n",
            "Iteration 836, loss = 0.00389420\n",
            "Iteration 837, loss = 0.00385947\n",
            "Iteration 838, loss = 0.00384363\n",
            "Iteration 839, loss = 0.00381418\n",
            "Iteration 840, loss = 0.00382407\n",
            "Iteration 841, loss = 0.00378319\n",
            "Iteration 842, loss = 0.00378118\n",
            "Iteration 843, loss = 0.00375384\n",
            "Iteration 844, loss = 0.00373855\n",
            "Iteration 845, loss = 0.00371837\n",
            "Iteration 846, loss = 0.00369690\n",
            "Iteration 847, loss = 0.00367986\n",
            "Iteration 848, loss = 0.00366584\n",
            "Iteration 849, loss = 0.00365782\n",
            "Iteration 850, loss = 0.00363785\n",
            "Iteration 851, loss = 0.00361731\n",
            "Iteration 852, loss = 0.00360985\n",
            "Iteration 853, loss = 0.00358683\n",
            "Iteration 854, loss = 0.00356849\n",
            "Iteration 855, loss = 0.00356152\n",
            "Iteration 856, loss = 0.00354757\n",
            "Iteration 857, loss = 0.00352549\n",
            "Iteration 858, loss = 0.00351970\n",
            "Iteration 859, loss = 0.00349496\n",
            "Iteration 860, loss = 0.00348642\n",
            "Iteration 861, loss = 0.00346788\n",
            "Iteration 862, loss = 0.00343783\n",
            "Iteration 863, loss = 0.00343109\n",
            "Iteration 864, loss = 0.00343056\n",
            "Iteration 865, loss = 0.00339782\n",
            "Iteration 866, loss = 0.00338642\n",
            "Iteration 867, loss = 0.00337429\n",
            "Iteration 868, loss = 0.00335257\n",
            "Iteration 869, loss = 0.00334495\n",
            "Iteration 870, loss = 0.00332411\n",
            "Iteration 871, loss = 0.00331452\n",
            "Iteration 872, loss = 0.00329655\n",
            "Iteration 873, loss = 0.00329249\n",
            "Iteration 874, loss = 0.00327091\n",
            "Iteration 875, loss = 0.00324060\n",
            "Iteration 876, loss = 0.00326002\n",
            "Iteration 877, loss = 0.00323145\n",
            "Iteration 878, loss = 0.00320526\n",
            "Iteration 879, loss = 0.00319474\n",
            "Iteration 880, loss = 0.00317453\n",
            "Iteration 881, loss = 0.00316673\n",
            "Iteration 882, loss = 0.00314764\n",
            "Iteration 883, loss = 0.00314001\n",
            "Iteration 884, loss = 0.00312015\n",
            "Iteration 885, loss = 0.00310719\n",
            "Iteration 886, loss = 0.00309878\n",
            "Iteration 887, loss = 0.00307260\n",
            "Iteration 888, loss = 0.00308507\n",
            "Iteration 889, loss = 0.00306356\n",
            "Iteration 890, loss = 0.00304326\n",
            "Iteration 891, loss = 0.00303649\n",
            "Iteration 892, loss = 0.00300773\n",
            "Iteration 893, loss = 0.00300147\n",
            "Iteration 894, loss = 0.00298562\n",
            "Iteration 895, loss = 0.00297722\n",
            "Iteration 896, loss = 0.00297960\n",
            "Iteration 897, loss = 0.00295086\n",
            "Iteration 898, loss = 0.00293962\n",
            "Iteration 899, loss = 0.00295970\n",
            "Iteration 900, loss = 0.00291000\n",
            "Iteration 901, loss = 0.00289599\n",
            "Iteration 902, loss = 0.00288313\n",
            "Iteration 903, loss = 0.00288006\n",
            "Iteration 904, loss = 0.00286097\n",
            "Iteration 905, loss = 0.00284527\n",
            "Iteration 906, loss = 0.00284460\n",
            "Iteration 907, loss = 0.00281380\n",
            "Iteration 908, loss = 0.00281339\n",
            "Iteration 909, loss = 0.00279421\n",
            "Iteration 910, loss = 0.00278134\n",
            "Iteration 911, loss = 0.00277927\n",
            "Iteration 912, loss = 0.00276596\n",
            "Iteration 913, loss = 0.00274638\n",
            "Iteration 914, loss = 0.00273110\n",
            "Iteration 915, loss = 0.00273109\n",
            "Iteration 916, loss = 0.00271633\n",
            "Iteration 917, loss = 0.00270305\n",
            "Iteration 918, loss = 0.00269914\n",
            "Iteration 919, loss = 0.00268459\n",
            "Iteration 920, loss = 0.00266670\n",
            "Iteration 921, loss = 0.00265695\n",
            "Iteration 922, loss = 0.00264457\n",
            "Iteration 923, loss = 0.00263350\n",
            "Iteration 924, loss = 0.00261647\n",
            "Iteration 925, loss = 0.00260817\n",
            "Iteration 926, loss = 0.00259910\n",
            "Iteration 927, loss = 0.00258624\n",
            "Iteration 928, loss = 0.00257663\n",
            "Iteration 929, loss = 0.00256738\n",
            "Iteration 930, loss = 0.00256640\n",
            "Iteration 931, loss = 0.00255115\n",
            "Iteration 932, loss = 0.00253265\n",
            "Iteration 933, loss = 0.00252286\n",
            "Iteration 934, loss = 0.00252312\n",
            "Iteration 935, loss = 0.00251394\n",
            "Iteration 936, loss = 0.00249857\n",
            "Iteration 937, loss = 0.00248283\n",
            "Iteration 938, loss = 0.00246550\n",
            "Iteration 939, loss = 0.00245454\n",
            "Iteration 940, loss = 0.00244928\n",
            "Iteration 941, loss = 0.00243634\n",
            "Iteration 942, loss = 0.00243425\n",
            "Iteration 943, loss = 0.00242295\n",
            "Iteration 944, loss = 0.00240915\n",
            "Iteration 945, loss = 0.00240228\n",
            "Iteration 946, loss = 0.00238096\n",
            "Iteration 947, loss = 0.00236906\n",
            "Iteration 948, loss = 0.00236674\n",
            "Iteration 949, loss = 0.00235660\n",
            "Iteration 950, loss = 0.00234460\n",
            "Iteration 951, loss = 0.00233463\n",
            "Iteration 952, loss = 0.00232906\n",
            "Iteration 953, loss = 0.00231474\n",
            "Iteration 954, loss = 0.00230612\n",
            "Iteration 955, loss = 0.00229740\n",
            "Iteration 956, loss = 0.00228199\n",
            "Iteration 957, loss = 0.00227476\n",
            "Iteration 958, loss = 0.00226746\n",
            "Iteration 959, loss = 0.00225768\n",
            "Iteration 960, loss = 0.00225244\n",
            "Iteration 961, loss = 0.00224042\n",
            "Iteration 962, loss = 0.00222785\n",
            "Iteration 963, loss = 0.00222658\n",
            "Iteration 964, loss = 0.00220629\n",
            "Iteration 965, loss = 0.00219916\n",
            "Iteration 966, loss = 0.00219664\n",
            "Iteration 967, loss = 0.00218475\n",
            "Iteration 968, loss = 0.00217729\n",
            "Iteration 969, loss = 0.00217201\n",
            "Iteration 970, loss = 0.00215512\n",
            "Iteration 971, loss = 0.00214809\n",
            "Iteration 972, loss = 0.00213862\n",
            "Iteration 973, loss = 0.00213878\n",
            "Iteration 974, loss = 0.00212168\n",
            "Iteration 975, loss = 0.00212982\n",
            "Iteration 976, loss = 0.00210312\n",
            "Iteration 977, loss = 0.00209946\n",
            "Iteration 978, loss = 0.00208974\n",
            "Iteration 979, loss = 0.00207895\n",
            "Iteration 980, loss = 0.00207003\n",
            "Iteration 981, loss = 0.00206063\n",
            "Iteration 982, loss = 0.00204963\n",
            "Iteration 983, loss = 0.00204460\n",
            "Iteration 984, loss = 0.00204074\n",
            "Iteration 985, loss = 0.00202464\n",
            "Iteration 986, loss = 0.00201950\n",
            "Iteration 987, loss = 0.00201369\n",
            "Iteration 988, loss = 0.00200529\n",
            "Iteration 989, loss = 0.00199101\n",
            "Iteration 990, loss = 0.00198665\n",
            "Iteration 991, loss = 0.00198387\n",
            "Iteration 992, loss = 0.00197056\n",
            "Iteration 993, loss = 0.00196518\n",
            "Iteration 994, loss = 0.00195548\n",
            "Iteration 995, loss = 0.00195069\n",
            "Iteration 996, loss = 0.00193831\n",
            "Iteration 997, loss = 0.00192484\n",
            "Iteration 998, loss = 0.00192138\n",
            "Iteration 999, loss = 0.00191622\n",
            "Iteration 1000, loss = 0.00190573\n",
            "Iteration 1001, loss = 0.00189797\n",
            "Iteration 1002, loss = 0.00189045\n",
            "Iteration 1003, loss = 0.00187861\n",
            "Iteration 1004, loss = 0.00188010\n",
            "Iteration 1005, loss = 0.00188112\n",
            "Iteration 1006, loss = 0.00186041\n",
            "Iteration 1007, loss = 0.00185378\n",
            "Iteration 1008, loss = 0.00184682\n",
            "Iteration 1009, loss = 0.00183927\n",
            "Iteration 1010, loss = 0.00183215\n",
            "Iteration 1011, loss = 0.00182058\n",
            "Iteration 1012, loss = 0.00181560\n",
            "Iteration 1013, loss = 0.00181130\n",
            "Iteration 1014, loss = 0.00180300\n",
            "Iteration 1015, loss = 0.00179173\n",
            "Iteration 1016, loss = 0.00178444\n",
            "Iteration 1017, loss = 0.00177860\n",
            "Iteration 1018, loss = 0.00177204\n",
            "Iteration 1019, loss = 0.00176907\n",
            "Iteration 1020, loss = 0.00176419\n",
            "Iteration 1021, loss = 0.00174939\n",
            "Iteration 1022, loss = 0.00175000\n",
            "Iteration 1023, loss = 0.00173991\n",
            "Iteration 1024, loss = 0.00173786\n",
            "Iteration 1025, loss = 0.00172339\n",
            "Iteration 1026, loss = 0.00173016\n",
            "Iteration 1027, loss = 0.00171374\n",
            "Iteration 1028, loss = 0.00170398\n",
            "Iteration 1029, loss = 0.00170430\n",
            "Iteration 1030, loss = 0.00168770\n",
            "Iteration 1031, loss = 0.00168465\n",
            "Iteration 1032, loss = 0.00167443\n",
            "Iteration 1033, loss = 0.00166877\n",
            "Iteration 1034, loss = 0.00166401\n",
            "Iteration 1035, loss = 0.00165332\n",
            "Iteration 1036, loss = 0.00164831\n",
            "Iteration 1037, loss = 0.00164030\n",
            "Iteration 1038, loss = 0.00163474\n",
            "Iteration 1039, loss = 0.00162851\n",
            "Iteration 1040, loss = 0.00162267\n",
            "Iteration 1041, loss = 0.00161507\n",
            "Iteration 1042, loss = 0.00160840\n",
            "Iteration 1043, loss = 0.00160427\n",
            "Iteration 1044, loss = 0.00159987\n",
            "Iteration 1045, loss = 0.00159477\n",
            "Iteration 1046, loss = 0.00158847\n",
            "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.63299570\n",
            "Iteration 2, loss = 0.53574042\n",
            "Iteration 3, loss = 0.47429662\n",
            "Iteration 4, loss = 0.43575902\n",
            "Iteration 5, loss = 0.41011602\n",
            "Iteration 6, loss = 0.39456221\n",
            "Iteration 7, loss = 0.38280892\n",
            "Iteration 8, loss = 0.37319516\n",
            "Iteration 9, loss = 0.36584715\n",
            "Iteration 10, loss = 0.35908590\n",
            "Iteration 11, loss = 0.35338777\n",
            "Iteration 12, loss = 0.34829147\n",
            "Iteration 13, loss = 0.34333605\n",
            "Iteration 14, loss = 0.33911926\n",
            "Iteration 15, loss = 0.33503389\n",
            "Iteration 16, loss = 0.33095484\n",
            "Iteration 17, loss = 0.32737671\n",
            "Iteration 18, loss = 0.32393971\n",
            "Iteration 19, loss = 0.32050932\n",
            "Iteration 20, loss = 0.31711811\n",
            "Iteration 21, loss = 0.31408436\n",
            "Iteration 22, loss = 0.31104719\n",
            "Iteration 23, loss = 0.30812164\n",
            "Iteration 24, loss = 0.30529557\n",
            "Iteration 25, loss = 0.30260178\n",
            "Iteration 26, loss = 0.29989487\n",
            "Iteration 27, loss = 0.29729278\n",
            "Iteration 28, loss = 0.29479528\n",
            "Iteration 29, loss = 0.29206293\n",
            "Iteration 30, loss = 0.28983099\n",
            "Iteration 31, loss = 0.28745846\n",
            "Iteration 32, loss = 0.28480611\n",
            "Iteration 33, loss = 0.28250641\n",
            "Iteration 34, loss = 0.28017081\n",
            "Iteration 35, loss = 0.27797486\n",
            "Iteration 36, loss = 0.27568240\n",
            "Iteration 37, loss = 0.27351154\n",
            "Iteration 38, loss = 0.27139885\n",
            "Iteration 39, loss = 0.26941669\n",
            "Iteration 40, loss = 0.26736466\n",
            "Iteration 41, loss = 0.26527778\n",
            "Iteration 42, loss = 0.26365859\n",
            "Iteration 43, loss = 0.26147891\n",
            "Iteration 44, loss = 0.25951992\n",
            "Iteration 45, loss = 0.25763822\n",
            "Iteration 46, loss = 0.25579960\n",
            "Iteration 47, loss = 0.25374629\n",
            "Iteration 48, loss = 0.25197588\n",
            "Iteration 49, loss = 0.25026521\n",
            "Iteration 50, loss = 0.24870084\n",
            "Iteration 51, loss = 0.24671983\n",
            "Iteration 52, loss = 0.24520863\n",
            "Iteration 53, loss = 0.24318631\n",
            "Iteration 54, loss = 0.24150770\n",
            "Iteration 55, loss = 0.23989069\n",
            "Iteration 56, loss = 0.23835620\n",
            "Iteration 57, loss = 0.23650628\n",
            "Iteration 58, loss = 0.23512373\n",
            "Iteration 59, loss = 0.23338890\n",
            "Iteration 60, loss = 0.23175823\n",
            "Iteration 61, loss = 0.23031377\n",
            "Iteration 62, loss = 0.22878605\n",
            "Iteration 63, loss = 0.22693436\n",
            "Iteration 64, loss = 0.22569419\n",
            "Iteration 65, loss = 0.22384740\n",
            "Iteration 66, loss = 0.22266458\n",
            "Iteration 67, loss = 0.22108707\n",
            "Iteration 68, loss = 0.21961060\n",
            "Iteration 69, loss = 0.21798718\n",
            "Iteration 70, loss = 0.21641204\n",
            "Iteration 71, loss = 0.21486528\n",
            "Iteration 72, loss = 0.21361230\n",
            "Iteration 73, loss = 0.21203931\n",
            "Iteration 74, loss = 0.21088347\n",
            "Iteration 75, loss = 0.20936443\n",
            "Iteration 76, loss = 0.20789082\n",
            "Iteration 77, loss = 0.20646666\n",
            "Iteration 78, loss = 0.20532397\n",
            "Iteration 79, loss = 0.20362983\n",
            "Iteration 80, loss = 0.20243313\n",
            "Iteration 81, loss = 0.20084963\n",
            "Iteration 82, loss = 0.19960484\n",
            "Iteration 83, loss = 0.19823974\n",
            "Iteration 84, loss = 0.19683264\n",
            "Iteration 85, loss = 0.19567636\n",
            "Iteration 86, loss = 0.19419559\n",
            "Iteration 87, loss = 0.19300542\n",
            "Iteration 88, loss = 0.19186952\n",
            "Iteration 89, loss = 0.19038739\n",
            "Iteration 90, loss = 0.18927042\n",
            "Iteration 91, loss = 0.18825635\n",
            "Iteration 92, loss = 0.18692536\n",
            "Iteration 93, loss = 0.18556992\n",
            "Iteration 94, loss = 0.18418717\n",
            "Iteration 95, loss = 0.18301546\n",
            "Iteration 96, loss = 0.18216905\n",
            "Iteration 97, loss = 0.18068192\n",
            "Iteration 98, loss = 0.17958979\n",
            "Iteration 99, loss = 0.17829990\n",
            "Iteration 100, loss = 0.17713648\n",
            "Iteration 101, loss = 0.17634965\n",
            "Iteration 102, loss = 0.17511573\n",
            "Iteration 103, loss = 0.17393874\n",
            "Iteration 104, loss = 0.17262394\n",
            "Iteration 105, loss = 0.17175635\n",
            "Iteration 106, loss = 0.17046840\n",
            "Iteration 107, loss = 0.16991724\n",
            "Iteration 108, loss = 0.16842781\n",
            "Iteration 109, loss = 0.16738687\n",
            "Iteration 110, loss = 0.16635366\n",
            "Iteration 111, loss = 0.16569476\n",
            "Iteration 112, loss = 0.16405000\n",
            "Iteration 113, loss = 0.16308524\n",
            "Iteration 114, loss = 0.16227882\n",
            "Iteration 115, loss = 0.16129093\n",
            "Iteration 116, loss = 0.15987314\n",
            "Iteration 117, loss = 0.15925641\n",
            "Iteration 118, loss = 0.15800237\n",
            "Iteration 119, loss = 0.15673684\n",
            "Iteration 120, loss = 0.15586531\n",
            "Iteration 121, loss = 0.15494238\n",
            "Iteration 122, loss = 0.15371792\n",
            "Iteration 123, loss = 0.15302731\n",
            "Iteration 124, loss = 0.15178794\n",
            "Iteration 125, loss = 0.15102777\n",
            "Iteration 126, loss = 0.14997158\n",
            "Iteration 127, loss = 0.14902083\n",
            "Iteration 128, loss = 0.14837261\n",
            "Iteration 129, loss = 0.14735096\n",
            "Iteration 130, loss = 0.14627434\n",
            "Iteration 131, loss = 0.14542926\n",
            "Iteration 132, loss = 0.14435836\n",
            "Iteration 133, loss = 0.14328868\n",
            "Iteration 134, loss = 0.14286325\n",
            "Iteration 135, loss = 0.14162146\n",
            "Iteration 136, loss = 0.14064854\n",
            "Iteration 137, loss = 0.13973692\n",
            "Iteration 138, loss = 0.13925692\n",
            "Iteration 139, loss = 0.13810663\n",
            "Iteration 140, loss = 0.13722924\n",
            "Iteration 141, loss = 0.13639914\n",
            "Iteration 142, loss = 0.13533998\n",
            "Iteration 143, loss = 0.13454283\n",
            "Iteration 144, loss = 0.13355757\n",
            "Iteration 145, loss = 0.13266932\n",
            "Iteration 146, loss = 0.13198382\n",
            "Iteration 147, loss = 0.13082270\n",
            "Iteration 148, loss = 0.13002700\n",
            "Iteration 149, loss = 0.12935198\n",
            "Iteration 150, loss = 0.12864797\n",
            "Iteration 151, loss = 0.12778336\n",
            "Iteration 152, loss = 0.12695601\n",
            "Iteration 153, loss = 0.12664403\n",
            "Iteration 154, loss = 0.12513295\n",
            "Iteration 155, loss = 0.12431285\n",
            "Iteration 156, loss = 0.12357956\n",
            "Iteration 157, loss = 0.12276184\n",
            "Iteration 158, loss = 0.12200481\n",
            "Iteration 159, loss = 0.12120248\n",
            "Iteration 160, loss = 0.12054457\n",
            "Iteration 161, loss = 0.11970925\n",
            "Iteration 162, loss = 0.11895369\n",
            "Iteration 163, loss = 0.11819728\n",
            "Iteration 164, loss = 0.11739314\n",
            "Iteration 165, loss = 0.11644204\n",
            "Iteration 166, loss = 0.11606383\n",
            "Iteration 167, loss = 0.11514789\n",
            "Iteration 168, loss = 0.11447720\n",
            "Iteration 169, loss = 0.11376530\n",
            "Iteration 170, loss = 0.11267101\n",
            "Iteration 171, loss = 0.11217878\n",
            "Iteration 172, loss = 0.11125147\n",
            "Iteration 173, loss = 0.11052246\n",
            "Iteration 174, loss = 0.10990193\n",
            "Iteration 175, loss = 0.10911788\n",
            "Iteration 176, loss = 0.10839282\n",
            "Iteration 177, loss = 0.10764756\n",
            "Iteration 178, loss = 0.10739919\n",
            "Iteration 179, loss = 0.10694164\n",
            "Iteration 180, loss = 0.10563146\n",
            "Iteration 181, loss = 0.10496947\n",
            "Iteration 182, loss = 0.10434333\n",
            "Iteration 183, loss = 0.10384435\n",
            "Iteration 184, loss = 0.10294411\n",
            "Iteration 185, loss = 0.10239683\n",
            "Iteration 186, loss = 0.10176542\n",
            "Iteration 187, loss = 0.10078217\n",
            "Iteration 188, loss = 0.10022966\n",
            "Iteration 189, loss = 0.09960447\n",
            "Iteration 190, loss = 0.09910237\n",
            "Iteration 191, loss = 0.09830167\n",
            "Iteration 192, loss = 0.09794399\n",
            "Iteration 193, loss = 0.09712797\n",
            "Iteration 194, loss = 0.09642945\n",
            "Iteration 195, loss = 0.09568817\n",
            "Iteration 196, loss = 0.09504316\n",
            "Iteration 197, loss = 0.09449928\n",
            "Iteration 198, loss = 0.09400994\n",
            "Iteration 199, loss = 0.09344509\n",
            "Iteration 200, loss = 0.09250973\n",
            "Iteration 201, loss = 0.09283736\n",
            "Iteration 202, loss = 0.09114047\n",
            "Iteration 203, loss = 0.09104448\n",
            "Iteration 204, loss = 0.09026678\n",
            "Iteration 205, loss = 0.08979258\n",
            "Iteration 206, loss = 0.08898570\n",
            "Iteration 207, loss = 0.08840579\n",
            "Iteration 208, loss = 0.08796417\n",
            "Iteration 209, loss = 0.08737481\n",
            "Iteration 210, loss = 0.08682765\n",
            "Iteration 211, loss = 0.08625672\n",
            "Iteration 212, loss = 0.08569907\n",
            "Iteration 213, loss = 0.08523571\n",
            "Iteration 214, loss = 0.08471363\n",
            "Iteration 215, loss = 0.08389764\n",
            "Iteration 216, loss = 0.08338644\n",
            "Iteration 217, loss = 0.08270709\n",
            "Iteration 218, loss = 0.08231661\n",
            "Iteration 219, loss = 0.08174559\n",
            "Iteration 220, loss = 0.08121455\n",
            "Iteration 221, loss = 0.08065897\n",
            "Iteration 222, loss = 0.08031545\n",
            "Iteration 223, loss = 0.07975719\n",
            "Iteration 224, loss = 0.07925963\n",
            "Iteration 225, loss = 0.07856509\n",
            "Iteration 226, loss = 0.07816876\n",
            "Iteration 227, loss = 0.07737180\n",
            "Iteration 228, loss = 0.07689562\n",
            "Iteration 229, loss = 0.07671834\n",
            "Iteration 230, loss = 0.07614558\n",
            "Iteration 231, loss = 0.07532545\n",
            "Iteration 232, loss = 0.07506786\n",
            "Iteration 233, loss = 0.07440604\n",
            "Iteration 234, loss = 0.07413481\n",
            "Iteration 235, loss = 0.07354261\n",
            "Iteration 236, loss = 0.07268163\n",
            "Iteration 237, loss = 0.07266583\n",
            "Iteration 238, loss = 0.07207294\n",
            "Iteration 239, loss = 0.07137477\n",
            "Iteration 240, loss = 0.07091569\n",
            "Iteration 241, loss = 0.07044547\n",
            "Iteration 242, loss = 0.06987547\n",
            "Iteration 243, loss = 0.06959904\n",
            "Iteration 244, loss = 0.06895707\n",
            "Iteration 245, loss = 0.06867711\n",
            "Iteration 246, loss = 0.06815054\n",
            "Iteration 247, loss = 0.06758227\n",
            "Iteration 248, loss = 0.06717587\n",
            "Iteration 249, loss = 0.06685125\n",
            "Iteration 250, loss = 0.06628606\n",
            "Iteration 251, loss = 0.06635216\n",
            "Iteration 252, loss = 0.06551122\n",
            "Iteration 253, loss = 0.06494593\n",
            "Iteration 254, loss = 0.06453397\n",
            "Iteration 255, loss = 0.06400645\n",
            "Iteration 256, loss = 0.06375087\n",
            "Iteration 257, loss = 0.06314151\n",
            "Iteration 258, loss = 0.06303025\n",
            "Iteration 259, loss = 0.06224038\n",
            "Iteration 260, loss = 0.06202086\n",
            "Iteration 261, loss = 0.06149122\n",
            "Iteration 262, loss = 0.06123077\n",
            "Iteration 263, loss = 0.06076246\n",
            "Iteration 264, loss = 0.06033543\n",
            "Iteration 265, loss = 0.06023922\n",
            "Iteration 266, loss = 0.05938349\n",
            "Iteration 267, loss = 0.05940242\n",
            "Iteration 268, loss = 0.05866623\n",
            "Iteration 269, loss = 0.05837444\n",
            "Iteration 270, loss = 0.05822317\n",
            "Iteration 271, loss = 0.05758678\n",
            "Iteration 272, loss = 0.05699337\n",
            "Iteration 273, loss = 0.05662091\n",
            "Iteration 274, loss = 0.05632764\n",
            "Iteration 275, loss = 0.05579039\n",
            "Iteration 276, loss = 0.05545278\n",
            "Iteration 277, loss = 0.05504105\n",
            "Iteration 278, loss = 0.05477074\n",
            "Iteration 279, loss = 0.05427874\n",
            "Iteration 280, loss = 0.05400892\n",
            "Iteration 281, loss = 0.05360829\n",
            "Iteration 282, loss = 0.05330889\n",
            "Iteration 283, loss = 0.05305416\n",
            "Iteration 284, loss = 0.05257460\n",
            "Iteration 285, loss = 0.05212104\n",
            "Iteration 286, loss = 0.05178847\n",
            "Iteration 287, loss = 0.05147079\n",
            "Iteration 288, loss = 0.05096506\n",
            "Iteration 289, loss = 0.05092524\n",
            "Iteration 290, loss = 0.05057453\n",
            "Iteration 291, loss = 0.05029505\n",
            "Iteration 292, loss = 0.04975868\n",
            "Iteration 293, loss = 0.04956326\n",
            "Iteration 294, loss = 0.04910918\n",
            "Iteration 295, loss = 0.04882483\n",
            "Iteration 296, loss = 0.04849221\n",
            "Iteration 297, loss = 0.04825144\n",
            "Iteration 298, loss = 0.04775607\n",
            "Iteration 299, loss = 0.04750036\n",
            "Iteration 300, loss = 0.04746656\n",
            "Iteration 301, loss = 0.04711157\n",
            "Iteration 302, loss = 0.04659505\n",
            "Iteration 303, loss = 0.04620082\n",
            "Iteration 304, loss = 0.04593292\n",
            "Iteration 305, loss = 0.04560738\n",
            "Iteration 306, loss = 0.04524870\n",
            "Iteration 307, loss = 0.04492846\n",
            "Iteration 308, loss = 0.04476696\n",
            "Iteration 309, loss = 0.04434065\n",
            "Iteration 310, loss = 0.04400410\n",
            "Iteration 311, loss = 0.04365204\n",
            "Iteration 312, loss = 0.04350653\n",
            "Iteration 313, loss = 0.04306943\n",
            "Iteration 314, loss = 0.04285765\n",
            "Iteration 315, loss = 0.04255735\n",
            "Iteration 316, loss = 0.04219738\n",
            "Iteration 317, loss = 0.04212882\n",
            "Iteration 318, loss = 0.04172040\n",
            "Iteration 319, loss = 0.04146284\n",
            "Iteration 320, loss = 0.04107823\n",
            "Iteration 321, loss = 0.04076230\n",
            "Iteration 322, loss = 0.04053994\n",
            "Iteration 323, loss = 0.04032820\n",
            "Iteration 324, loss = 0.03997697\n",
            "Iteration 325, loss = 0.03994692\n",
            "Iteration 326, loss = 0.03938552\n",
            "Iteration 327, loss = 0.03931126\n",
            "Iteration 328, loss = 0.03893616\n",
            "Iteration 329, loss = 0.03865723\n",
            "Iteration 330, loss = 0.03850222\n",
            "Iteration 331, loss = 0.03815198\n",
            "Iteration 332, loss = 0.03788656\n",
            "Iteration 333, loss = 0.03779720\n",
            "Iteration 334, loss = 0.03747493\n",
            "Iteration 335, loss = 0.03717174\n",
            "Iteration 336, loss = 0.03682828\n",
            "Iteration 337, loss = 0.03666496\n",
            "Iteration 338, loss = 0.03655247\n",
            "Iteration 339, loss = 0.03605355\n",
            "Iteration 340, loss = 0.03590837\n",
            "Iteration 341, loss = 0.03559771\n",
            "Iteration 342, loss = 0.03541846\n",
            "Iteration 343, loss = 0.03519056\n",
            "Iteration 344, loss = 0.03495399\n",
            "Iteration 345, loss = 0.03462321\n",
            "Iteration 346, loss = 0.03446092\n",
            "Iteration 347, loss = 0.03420472\n",
            "Iteration 348, loss = 0.03392878\n",
            "Iteration 349, loss = 0.03376393\n",
            "Iteration 350, loss = 0.03357818\n",
            "Iteration 351, loss = 0.03334783\n",
            "Iteration 352, loss = 0.03308997\n",
            "Iteration 353, loss = 0.03299137\n",
            "Iteration 354, loss = 0.03267764\n",
            "Iteration 355, loss = 0.03241472\n",
            "Iteration 356, loss = 0.03225749\n",
            "Iteration 357, loss = 0.03210741\n",
            "Iteration 358, loss = 0.03191646\n",
            "Iteration 359, loss = 0.03166362\n",
            "Iteration 360, loss = 0.03125930\n",
            "Iteration 361, loss = 0.03116771\n",
            "Iteration 362, loss = 0.03101652\n",
            "Iteration 363, loss = 0.03066947\n",
            "Iteration 364, loss = 0.03048308\n",
            "Iteration 365, loss = 0.03032632\n",
            "Iteration 366, loss = 0.03017040\n",
            "Iteration 367, loss = 0.02993566\n",
            "Iteration 368, loss = 0.02966831\n",
            "Iteration 369, loss = 0.02953629\n",
            "Iteration 370, loss = 0.02934961\n",
            "Iteration 371, loss = 0.02929805\n",
            "Iteration 372, loss = 0.02891140\n",
            "Iteration 373, loss = 0.02873069\n",
            "Iteration 374, loss = 0.02853510\n",
            "Iteration 375, loss = 0.02829388\n",
            "Iteration 376, loss = 0.02815344\n",
            "Iteration 377, loss = 0.02802996\n",
            "Iteration 378, loss = 0.02776436\n",
            "Iteration 379, loss = 0.02769751\n",
            "Iteration 380, loss = 0.02731480\n",
            "Iteration 381, loss = 0.02715796\n",
            "Iteration 382, loss = 0.02702387\n",
            "Iteration 383, loss = 0.02679458\n",
            "Iteration 384, loss = 0.02667056\n",
            "Iteration 385, loss = 0.02648252\n",
            "Iteration 386, loss = 0.02635433\n",
            "Iteration 387, loss = 0.02614428\n",
            "Iteration 388, loss = 0.02592071\n",
            "Iteration 389, loss = 0.02581649\n",
            "Iteration 390, loss = 0.02562221\n",
            "Iteration 391, loss = 0.02550226\n",
            "Iteration 392, loss = 0.02530044\n",
            "Iteration 393, loss = 0.02510056\n",
            "Iteration 394, loss = 0.02497919\n",
            "Iteration 395, loss = 0.02488884\n",
            "Iteration 396, loss = 0.02477053\n",
            "Iteration 397, loss = 0.02441680\n",
            "Iteration 398, loss = 0.02428097\n",
            "Iteration 399, loss = 0.02407684\n",
            "Iteration 400, loss = 0.02412573\n",
            "Iteration 401, loss = 0.02385573\n",
            "Iteration 402, loss = 0.02363539\n",
            "Iteration 403, loss = 0.02365933\n",
            "Iteration 404, loss = 0.02335948\n",
            "Iteration 405, loss = 0.02318992\n",
            "Iteration 406, loss = 0.02315849\n",
            "Iteration 407, loss = 0.02290880\n",
            "Iteration 408, loss = 0.02271158\n",
            "Iteration 409, loss = 0.02259157\n",
            "Iteration 410, loss = 0.02250113\n",
            "Iteration 411, loss = 0.02231579\n",
            "Iteration 412, loss = 0.02218541\n",
            "Iteration 413, loss = 0.02202552\n",
            "Iteration 414, loss = 0.02203271\n",
            "Iteration 415, loss = 0.02172159\n",
            "Iteration 416, loss = 0.02163726\n",
            "Iteration 417, loss = 0.02150813\n",
            "Iteration 418, loss = 0.02129564\n",
            "Iteration 419, loss = 0.02120007\n",
            "Iteration 420, loss = 0.02103567\n",
            "Iteration 421, loss = 0.02093503\n",
            "Iteration 422, loss = 0.02079506\n",
            "Iteration 423, loss = 0.02073268\n",
            "Iteration 424, loss = 0.02052675\n",
            "Iteration 425, loss = 0.02041845\n",
            "Iteration 426, loss = 0.02027110\n",
            "Iteration 427, loss = 0.02008440\n",
            "Iteration 428, loss = 0.01996393\n",
            "Iteration 429, loss = 0.01984118\n",
            "Iteration 430, loss = 0.01978730\n",
            "Iteration 431, loss = 0.01963103\n",
            "Iteration 432, loss = 0.01950305\n",
            "Iteration 433, loss = 0.01935181\n",
            "Iteration 434, loss = 0.01927889\n",
            "Iteration 435, loss = 0.01922661\n",
            "Iteration 436, loss = 0.01902933\n",
            "Iteration 437, loss = 0.01890520\n",
            "Iteration 438, loss = 0.01876635\n",
            "Iteration 439, loss = 0.01867881\n",
            "Iteration 440, loss = 0.01858718\n",
            "Iteration 441, loss = 0.01843085\n",
            "Iteration 442, loss = 0.01843814\n",
            "Iteration 443, loss = 0.01831532\n",
            "Iteration 444, loss = 0.01818401\n",
            "Iteration 445, loss = 0.01803034\n",
            "Iteration 446, loss = 0.01786977\n",
            "Iteration 447, loss = 0.01777048\n",
            "Iteration 448, loss = 0.01761424\n",
            "Iteration 449, loss = 0.01751190\n",
            "Iteration 450, loss = 0.01746548\n",
            "Iteration 451, loss = 0.01734991\n",
            "Iteration 452, loss = 0.01738991\n",
            "Iteration 453, loss = 0.01725483\n",
            "Iteration 454, loss = 0.01715415\n",
            "Iteration 455, loss = 0.01694129\n",
            "Iteration 456, loss = 0.01682785\n",
            "Iteration 457, loss = 0.01670395\n",
            "Iteration 458, loss = 0.01660476\n",
            "Iteration 459, loss = 0.01646479\n",
            "Iteration 460, loss = 0.01642338\n",
            "Iteration 461, loss = 0.01630588\n",
            "Iteration 462, loss = 0.01621701\n",
            "Iteration 463, loss = 0.01610056\n",
            "Iteration 464, loss = 0.01602152\n",
            "Iteration 465, loss = 0.01594417\n",
            "Iteration 466, loss = 0.01583025\n",
            "Iteration 467, loss = 0.01574536\n",
            "Iteration 468, loss = 0.01563024\n",
            "Iteration 469, loss = 0.01554309\n",
            "Iteration 470, loss = 0.01540961\n",
            "Iteration 471, loss = 0.01534329\n",
            "Iteration 472, loss = 0.01520595\n",
            "Iteration 473, loss = 0.01513944\n",
            "Iteration 474, loss = 0.01505776\n",
            "Iteration 475, loss = 0.01497177\n",
            "Iteration 476, loss = 0.01486154\n",
            "Iteration 477, loss = 0.01480388\n",
            "Iteration 478, loss = 0.01470851\n",
            "Iteration 479, loss = 0.01458265\n",
            "Iteration 480, loss = 0.01451251\n",
            "Iteration 481, loss = 0.01445262\n",
            "Iteration 482, loss = 0.01435492\n",
            "Iteration 483, loss = 0.01428178\n",
            "Iteration 484, loss = 0.01416551\n",
            "Iteration 485, loss = 0.01409923\n",
            "Iteration 486, loss = 0.01401117\n",
            "Iteration 487, loss = 0.01393623\n",
            "Iteration 488, loss = 0.01389772\n",
            "Iteration 489, loss = 0.01381934\n",
            "Iteration 490, loss = 0.01370801\n",
            "Iteration 491, loss = 0.01363045\n",
            "Iteration 492, loss = 0.01356994\n",
            "Iteration 493, loss = 0.01347026\n",
            "Iteration 494, loss = 0.01335999\n",
            "Iteration 495, loss = 0.01328991\n",
            "Iteration 496, loss = 0.01323677\n",
            "Iteration 497, loss = 0.01322495\n",
            "Iteration 498, loss = 0.01311956\n",
            "Iteration 499, loss = 0.01302378\n",
            "Iteration 500, loss = 0.01289928\n",
            "Iteration 501, loss = 0.01283487\n",
            "Iteration 502, loss = 0.01274364\n",
            "Iteration 503, loss = 0.01269885\n",
            "Iteration 504, loss = 0.01259506\n",
            "Iteration 505, loss = 0.01255002\n",
            "Iteration 506, loss = 0.01246920\n",
            "Iteration 507, loss = 0.01238925\n",
            "Iteration 508, loss = 0.01228258\n",
            "Iteration 509, loss = 0.01225197\n",
            "Iteration 510, loss = 0.01222276\n",
            "Iteration 511, loss = 0.01210324\n",
            "Iteration 512, loss = 0.01202410\n",
            "Iteration 513, loss = 0.01199230\n",
            "Iteration 514, loss = 0.01196713\n",
            "Iteration 515, loss = 0.01181625\n",
            "Iteration 516, loss = 0.01175148\n",
            "Iteration 517, loss = 0.01167787\n",
            "Iteration 518, loss = 0.01161594\n",
            "Iteration 519, loss = 0.01156688\n",
            "Iteration 520, loss = 0.01148803\n",
            "Iteration 521, loss = 0.01142338\n",
            "Iteration 522, loss = 0.01137129\n",
            "Iteration 523, loss = 0.01127028\n",
            "Iteration 524, loss = 0.01121868\n",
            "Iteration 525, loss = 0.01113288\n",
            "Iteration 526, loss = 0.01109234\n",
            "Iteration 527, loss = 0.01104462\n",
            "Iteration 528, loss = 0.01098961\n",
            "Iteration 529, loss = 0.01086692\n",
            "Iteration 530, loss = 0.01087360\n",
            "Iteration 531, loss = 0.01078416\n",
            "Iteration 532, loss = 0.01072136\n",
            "Iteration 533, loss = 0.01064215\n",
            "Iteration 534, loss = 0.01058504\n",
            "Iteration 535, loss = 0.01054325\n",
            "Iteration 536, loss = 0.01046943\n",
            "Iteration 537, loss = 0.01038109\n",
            "Iteration 538, loss = 0.01035258\n",
            "Iteration 539, loss = 0.01028066\n",
            "Iteration 540, loss = 0.01024991\n",
            "Iteration 541, loss = 0.01018745\n",
            "Iteration 542, loss = 0.01014036\n",
            "Iteration 543, loss = 0.01006568\n",
            "Iteration 544, loss = 0.01001718\n",
            "Iteration 545, loss = 0.00993424\n",
            "Iteration 546, loss = 0.00991241\n",
            "Iteration 547, loss = 0.00981752\n",
            "Iteration 548, loss = 0.00979902\n",
            "Iteration 549, loss = 0.00973289\n",
            "Iteration 550, loss = 0.00972178\n",
            "Iteration 551, loss = 0.00963014\n",
            "Iteration 552, loss = 0.00960311\n",
            "Iteration 553, loss = 0.00952470\n",
            "Iteration 554, loss = 0.00951972\n",
            "Iteration 555, loss = 0.00943424\n",
            "Iteration 556, loss = 0.00934619\n",
            "Iteration 557, loss = 0.00931043\n",
            "Iteration 558, loss = 0.00926803\n",
            "Iteration 559, loss = 0.00924388\n",
            "Iteration 560, loss = 0.00919142\n",
            "Iteration 561, loss = 0.00913785\n",
            "Iteration 562, loss = 0.00905344\n",
            "Iteration 563, loss = 0.00900181\n",
            "Iteration 564, loss = 0.00896085\n",
            "Iteration 565, loss = 0.00893013\n",
            "Iteration 566, loss = 0.00887332\n",
            "Iteration 567, loss = 0.00883133\n",
            "Iteration 568, loss = 0.00874462\n",
            "Iteration 569, loss = 0.00871236\n",
            "Iteration 570, loss = 0.00864860\n",
            "Iteration 571, loss = 0.00860482\n",
            "Iteration 572, loss = 0.00855333\n",
            "Iteration 573, loss = 0.00853361\n",
            "Iteration 574, loss = 0.00844512\n",
            "Iteration 575, loss = 0.00846391\n",
            "Iteration 576, loss = 0.00844388\n",
            "Iteration 577, loss = 0.00832808\n",
            "Iteration 578, loss = 0.00839652\n",
            "Iteration 579, loss = 0.00825898\n",
            "Iteration 580, loss = 0.00822446\n",
            "Iteration 581, loss = 0.00812800\n",
            "Iteration 582, loss = 0.00814294\n",
            "Iteration 583, loss = 0.00807188\n",
            "Iteration 584, loss = 0.00804115\n",
            "Iteration 585, loss = 0.00796278\n",
            "Iteration 586, loss = 0.00791628\n",
            "Iteration 587, loss = 0.00789379\n",
            "Iteration 588, loss = 0.00782425\n",
            "Iteration 589, loss = 0.00781163\n",
            "Iteration 590, loss = 0.00775181\n",
            "Iteration 591, loss = 0.00773177\n",
            "Iteration 592, loss = 0.00766375\n",
            "Iteration 593, loss = 0.00763797\n",
            "Iteration 594, loss = 0.00760495\n",
            "Iteration 595, loss = 0.00759019\n",
            "Iteration 596, loss = 0.00751657\n",
            "Iteration 597, loss = 0.00747803\n",
            "Iteration 598, loss = 0.00744338\n",
            "Iteration 599, loss = 0.00738570\n",
            "Iteration 600, loss = 0.00732882\n",
            "Iteration 601, loss = 0.00730571\n",
            "Iteration 602, loss = 0.00727222\n",
            "Iteration 603, loss = 0.00721533\n",
            "Iteration 604, loss = 0.00717926\n",
            "Iteration 605, loss = 0.00714034\n",
            "Iteration 606, loss = 0.00715162\n",
            "Iteration 607, loss = 0.00706069\n",
            "Iteration 608, loss = 0.00704092\n",
            "Iteration 609, loss = 0.00699379\n",
            "Iteration 610, loss = 0.00694987\n",
            "Iteration 611, loss = 0.00692585\n",
            "Iteration 612, loss = 0.00688842\n",
            "Iteration 613, loss = 0.00684913\n",
            "Iteration 614, loss = 0.00680729\n",
            "Iteration 615, loss = 0.00677729\n",
            "Iteration 616, loss = 0.00675519\n",
            "Iteration 617, loss = 0.00668633\n",
            "Iteration 618, loss = 0.00667989\n",
            "Iteration 619, loss = 0.00663336\n",
            "Iteration 620, loss = 0.00660501\n",
            "Iteration 621, loss = 0.00654376\n",
            "Iteration 622, loss = 0.00653261\n",
            "Iteration 623, loss = 0.00649110\n",
            "Iteration 624, loss = 0.00643958\n",
            "Iteration 625, loss = 0.00640334\n",
            "Iteration 626, loss = 0.00640067\n",
            "Iteration 627, loss = 0.00636899\n",
            "Iteration 628, loss = 0.00631473\n",
            "Iteration 629, loss = 0.00631023\n",
            "Iteration 630, loss = 0.00626920\n",
            "Iteration 631, loss = 0.00619959\n",
            "Iteration 632, loss = 0.00618471\n",
            "Iteration 633, loss = 0.00616153\n",
            "Iteration 634, loss = 0.00611726\n",
            "Iteration 635, loss = 0.00612062\n",
            "Iteration 636, loss = 0.00604669\n",
            "Iteration 637, loss = 0.00605972\n",
            "Iteration 638, loss = 0.00599998\n",
            "Iteration 639, loss = 0.00597314\n",
            "Iteration 640, loss = 0.00593422\n",
            "Iteration 641, loss = 0.00590512\n",
            "Iteration 642, loss = 0.00588069\n",
            "Iteration 643, loss = 0.00582221\n",
            "Iteration 644, loss = 0.00580044\n",
            "Iteration 645, loss = 0.00576925\n",
            "Iteration 646, loss = 0.00574864\n",
            "Iteration 647, loss = 0.00571213\n",
            "Iteration 648, loss = 0.00569044\n",
            "Iteration 649, loss = 0.00565034\n",
            "Iteration 650, loss = 0.00561594\n",
            "Iteration 651, loss = 0.00559441\n",
            "Iteration 652, loss = 0.00555732\n",
            "Iteration 653, loss = 0.00553074\n",
            "Iteration 654, loss = 0.00553736\n",
            "Iteration 655, loss = 0.00549024\n",
            "Iteration 656, loss = 0.00546832\n",
            "Iteration 657, loss = 0.00543364\n",
            "Iteration 658, loss = 0.00541230\n",
            "Iteration 659, loss = 0.00537406\n",
            "Iteration 660, loss = 0.00534475\n",
            "Iteration 661, loss = 0.00531213\n",
            "Iteration 662, loss = 0.00528313\n",
            "Iteration 663, loss = 0.00525731\n",
            "Iteration 664, loss = 0.00523087\n",
            "Iteration 665, loss = 0.00519617\n",
            "Iteration 666, loss = 0.00517074\n",
            "Iteration 667, loss = 0.00515837\n",
            "Iteration 668, loss = 0.00511275\n",
            "Iteration 669, loss = 0.00510452\n",
            "Iteration 670, loss = 0.00506497\n",
            "Iteration 671, loss = 0.00504299\n",
            "Iteration 672, loss = 0.00501569\n",
            "Iteration 673, loss = 0.00499112\n",
            "Iteration 674, loss = 0.00497636\n",
            "Iteration 675, loss = 0.00494248\n",
            "Iteration 676, loss = 0.00492058\n",
            "Iteration 677, loss = 0.00488482\n",
            "Iteration 678, loss = 0.00486686\n",
            "Iteration 679, loss = 0.00484336\n",
            "Iteration 680, loss = 0.00482043\n",
            "Iteration 681, loss = 0.00479242\n",
            "Iteration 682, loss = 0.00476184\n",
            "Iteration 683, loss = 0.00473284\n",
            "Iteration 684, loss = 0.00473758\n",
            "Iteration 685, loss = 0.00469663\n",
            "Iteration 686, loss = 0.00466628\n",
            "Iteration 687, loss = 0.00464387\n",
            "Iteration 688, loss = 0.00463030\n",
            "Iteration 689, loss = 0.00460134\n",
            "Iteration 690, loss = 0.00459424\n",
            "Iteration 691, loss = 0.00456933\n",
            "Iteration 692, loss = 0.00455303\n",
            "Iteration 693, loss = 0.00452027\n",
            "Iteration 694, loss = 0.00448917\n",
            "Iteration 695, loss = 0.00445980\n",
            "Iteration 696, loss = 0.00444400\n",
            "Iteration 697, loss = 0.00442199\n",
            "Iteration 698, loss = 0.00439913\n",
            "Iteration 699, loss = 0.00438410\n",
            "Iteration 700, loss = 0.00435657\n",
            "Iteration 701, loss = 0.00434654\n",
            "Iteration 702, loss = 0.00430747\n",
            "Iteration 703, loss = 0.00429710\n",
            "Iteration 704, loss = 0.00426002\n",
            "Iteration 705, loss = 0.00424581\n",
            "Iteration 706, loss = 0.00424089\n",
            "Iteration 707, loss = 0.00421686\n",
            "Iteration 708, loss = 0.00420366\n",
            "Iteration 709, loss = 0.00416971\n",
            "Iteration 710, loss = 0.00413846\n",
            "Iteration 711, loss = 0.00413584\n",
            "Iteration 712, loss = 0.00409865\n",
            "Iteration 713, loss = 0.00407669\n",
            "Iteration 714, loss = 0.00407923\n",
            "Iteration 715, loss = 0.00404117\n",
            "Iteration 716, loss = 0.00401962\n",
            "Iteration 717, loss = 0.00400115\n",
            "Iteration 718, loss = 0.00398012\n",
            "Iteration 719, loss = 0.00397283\n",
            "Iteration 720, loss = 0.00393929\n",
            "Iteration 721, loss = 0.00393418\n",
            "Iteration 722, loss = 0.00390239\n",
            "Iteration 723, loss = 0.00388433\n",
            "Iteration 724, loss = 0.00386552\n",
            "Iteration 725, loss = 0.00384094\n",
            "Iteration 726, loss = 0.00382776\n",
            "Iteration 727, loss = 0.00381580\n",
            "Iteration 728, loss = 0.00379969\n",
            "Iteration 729, loss = 0.00377445\n",
            "Iteration 730, loss = 0.00376463\n",
            "Iteration 731, loss = 0.00377018\n",
            "Iteration 732, loss = 0.00373654\n",
            "Iteration 733, loss = 0.00370586\n",
            "Iteration 734, loss = 0.00369458\n",
            "Iteration 735, loss = 0.00366776\n",
            "Iteration 736, loss = 0.00365601\n",
            "Iteration 737, loss = 0.00363378\n",
            "Iteration 738, loss = 0.00361421\n",
            "Iteration 739, loss = 0.00360475\n",
            "Iteration 740, loss = 0.00359110\n",
            "Iteration 741, loss = 0.00356917\n",
            "Iteration 742, loss = 0.00354429\n",
            "Iteration 743, loss = 0.00352648\n",
            "Iteration 744, loss = 0.00350980\n",
            "Iteration 745, loss = 0.00349708\n",
            "Iteration 746, loss = 0.00346979\n",
            "Iteration 747, loss = 0.00346297\n",
            "Iteration 748, loss = 0.00343650\n",
            "Iteration 749, loss = 0.00342613\n",
            "Iteration 750, loss = 0.00340749\n",
            "Iteration 751, loss = 0.00340239\n",
            "Iteration 752, loss = 0.00337066\n",
            "Iteration 753, loss = 0.00337677\n",
            "Iteration 754, loss = 0.00334868\n",
            "Iteration 755, loss = 0.00333411\n",
            "Iteration 756, loss = 0.00331405\n",
            "Iteration 757, loss = 0.00330088\n",
            "Iteration 758, loss = 0.00328298\n",
            "Iteration 759, loss = 0.00327462\n",
            "Iteration 760, loss = 0.00325126\n",
            "Iteration 761, loss = 0.00324799\n",
            "Iteration 762, loss = 0.00323447\n",
            "Iteration 763, loss = 0.00321184\n",
            "Iteration 764, loss = 0.00319489\n",
            "Iteration 765, loss = 0.00317598\n",
            "Iteration 766, loss = 0.00316629\n",
            "Iteration 767, loss = 0.00314588\n",
            "Iteration 768, loss = 0.00312697\n",
            "Iteration 769, loss = 0.00311820\n",
            "Iteration 770, loss = 0.00310927\n",
            "Iteration 771, loss = 0.00309005\n",
            "Iteration 772, loss = 0.00307882\n",
            "Iteration 773, loss = 0.00306042\n",
            "Iteration 774, loss = 0.00304443\n",
            "Iteration 775, loss = 0.00304720\n",
            "Iteration 776, loss = 0.00302425\n",
            "Iteration 777, loss = 0.00300895\n",
            "Iteration 778, loss = 0.00299109\n",
            "Iteration 779, loss = 0.00297919\n",
            "Iteration 780, loss = 0.00297567\n",
            "Iteration 781, loss = 0.00295744\n",
            "Iteration 782, loss = 0.00294294\n",
            "Iteration 783, loss = 0.00292463\n",
            "Iteration 784, loss = 0.00291566\n",
            "Iteration 785, loss = 0.00290427\n",
            "Iteration 786, loss = 0.00288067\n",
            "Iteration 787, loss = 0.00286715\n",
            "Iteration 788, loss = 0.00285725\n",
            "Iteration 789, loss = 0.00284508\n",
            "Iteration 790, loss = 0.00283430\n",
            "Iteration 791, loss = 0.00281923\n",
            "Iteration 792, loss = 0.00282047\n",
            "Iteration 793, loss = 0.00281274\n",
            "Iteration 794, loss = 0.00278421\n",
            "Iteration 795, loss = 0.00276675\n",
            "Iteration 796, loss = 0.00276033\n",
            "Iteration 797, loss = 0.00274580\n",
            "Iteration 798, loss = 0.00273477\n",
            "Iteration 799, loss = 0.00271915\n",
            "Iteration 800, loss = 0.00270824\n",
            "Iteration 801, loss = 0.00269602\n",
            "Iteration 802, loss = 0.00268981\n",
            "Iteration 803, loss = 0.00268479\n",
            "Iteration 804, loss = 0.00265972\n",
            "Iteration 805, loss = 0.00265111\n",
            "Iteration 806, loss = 0.00264080\n",
            "Iteration 807, loss = 0.00261903\n",
            "Iteration 808, loss = 0.00260485\n",
            "Iteration 809, loss = 0.00260994\n",
            "Iteration 810, loss = 0.00258615\n",
            "Iteration 811, loss = 0.00257995\n",
            "Iteration 812, loss = 0.00258095\n",
            "Iteration 813, loss = 0.00255196\n",
            "Iteration 814, loss = 0.00253785\n",
            "Iteration 815, loss = 0.00252558\n",
            "Iteration 816, loss = 0.00252531\n",
            "Iteration 817, loss = 0.00251025\n",
            "Iteration 818, loss = 0.00249503\n",
            "Iteration 819, loss = 0.00247919\n",
            "Iteration 820, loss = 0.00247017\n",
            "Iteration 821, loss = 0.00246011\n",
            "Iteration 822, loss = 0.00245084\n",
            "Iteration 823, loss = 0.00244234\n",
            "Iteration 824, loss = 0.00242694\n",
            "Iteration 825, loss = 0.00241364\n",
            "Iteration 826, loss = 0.00240500\n",
            "Iteration 827, loss = 0.00239474\n",
            "Iteration 828, loss = 0.00239431\n",
            "Iteration 829, loss = 0.00237190\n",
            "Iteration 830, loss = 0.00237115\n",
            "Iteration 831, loss = 0.00235742\n",
            "Iteration 832, loss = 0.00234233\n",
            "Iteration 833, loss = 0.00233394\n",
            "Iteration 834, loss = 0.00233264\n",
            "Iteration 835, loss = 0.00231459\n",
            "Iteration 836, loss = 0.00230905\n",
            "Iteration 837, loss = 0.00230841\n",
            "Iteration 838, loss = 0.00228820\n",
            "Iteration 839, loss = 0.00227483\n",
            "Iteration 840, loss = 0.00226274\n",
            "Iteration 841, loss = 0.00225023\n",
            "Iteration 842, loss = 0.00224535\n",
            "Iteration 843, loss = 0.00224024\n",
            "Iteration 844, loss = 0.00222460\n",
            "Iteration 845, loss = 0.00222341\n",
            "Iteration 846, loss = 0.00220705\n",
            "Iteration 847, loss = 0.00219648\n",
            "Iteration 848, loss = 0.00218848\n",
            "Iteration 849, loss = 0.00217341\n",
            "Iteration 850, loss = 0.00216473\n",
            "Iteration 851, loss = 0.00216103\n",
            "Iteration 852, loss = 0.00215204\n",
            "Iteration 853, loss = 0.00214163\n",
            "Iteration 854, loss = 0.00212653\n",
            "Iteration 855, loss = 0.00212238\n",
            "Iteration 856, loss = 0.00211243\n",
            "Iteration 857, loss = 0.00210251\n",
            "Iteration 858, loss = 0.00208928\n",
            "Iteration 859, loss = 0.00208721\n",
            "Iteration 860, loss = 0.00208056\n",
            "Iteration 861, loss = 0.00206281\n",
            "Iteration 862, loss = 0.00205763\n",
            "Iteration 863, loss = 0.00205043\n",
            "Iteration 864, loss = 0.00203943\n",
            "Iteration 865, loss = 0.00203389\n",
            "Iteration 866, loss = 0.00202264\n",
            "Iteration 867, loss = 0.00201204\n",
            "Iteration 868, loss = 0.00200189\n",
            "Iteration 869, loss = 0.00199543\n",
            "Iteration 870, loss = 0.00198616\n",
            "Iteration 871, loss = 0.00198067\n",
            "Iteration 872, loss = 0.00196709\n",
            "Iteration 873, loss = 0.00196143\n",
            "Iteration 874, loss = 0.00195325\n",
            "Iteration 875, loss = 0.00194782\n",
            "Iteration 876, loss = 0.00193874\n",
            "Iteration 877, loss = 0.00193087\n",
            "Iteration 878, loss = 0.00192317\n",
            "Iteration 879, loss = 0.00191319\n",
            "Iteration 880, loss = 0.00190170\n",
            "Iteration 881, loss = 0.00189498\n",
            "Iteration 882, loss = 0.00188839\n",
            "Iteration 883, loss = 0.00188132\n",
            "Iteration 884, loss = 0.00187164\n",
            "Iteration 885, loss = 0.00186250\n",
            "Iteration 886, loss = 0.00185533\n",
            "Iteration 887, loss = 0.00184769\n",
            "Iteration 888, loss = 0.00184666\n",
            "Iteration 889, loss = 0.00183452\n",
            "Iteration 890, loss = 0.00182691\n",
            "Iteration 891, loss = 0.00181717\n",
            "Iteration 892, loss = 0.00181135\n",
            "Iteration 893, loss = 0.00179999\n",
            "Iteration 894, loss = 0.00179676\n",
            "Iteration 895, loss = 0.00178951\n",
            "Iteration 896, loss = 0.00178173\n",
            "Iteration 897, loss = 0.00177873\n",
            "Iteration 898, loss = 0.00177119\n",
            "Iteration 899, loss = 0.00175805\n",
            "Iteration 900, loss = 0.00175063\n",
            "Iteration 901, loss = 0.00174784\n",
            "Iteration 902, loss = 0.00173487\n",
            "Iteration 903, loss = 0.00173261\n",
            "Iteration 904, loss = 0.00172103\n",
            "Iteration 905, loss = 0.00172183\n",
            "Iteration 906, loss = 0.00170910\n",
            "Iteration 907, loss = 0.00169923\n",
            "Iteration 908, loss = 0.00169434\n",
            "Iteration 909, loss = 0.00168765\n",
            "Iteration 910, loss = 0.00168063\n",
            "Iteration 911, loss = 0.00167509\n",
            "Iteration 912, loss = 0.00166668\n",
            "Iteration 913, loss = 0.00166138\n",
            "Iteration 914, loss = 0.00165344\n",
            "Iteration 915, loss = 0.00164375\n",
            "Iteration 916, loss = 0.00163823\n",
            "Iteration 917, loss = 0.00163324\n",
            "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.48211484\n",
            "Iteration 2, loss = 0.44167697\n",
            "Iteration 3, loss = 0.41621607\n",
            "Iteration 4, loss = 0.40147601\n",
            "Iteration 5, loss = 0.39035457\n",
            "Iteration 6, loss = 0.38195856\n",
            "Iteration 7, loss = 0.37489326\n",
            "Iteration 8, loss = 0.36838970\n",
            "Iteration 9, loss = 0.36244010\n",
            "Iteration 10, loss = 0.35767232\n",
            "Iteration 11, loss = 0.35302875\n",
            "Iteration 12, loss = 0.34851804\n",
            "Iteration 13, loss = 0.34471288\n",
            "Iteration 14, loss = 0.34078667\n",
            "Iteration 15, loss = 0.33701915\n",
            "Iteration 16, loss = 0.33344832\n",
            "Iteration 17, loss = 0.33000222\n",
            "Iteration 18, loss = 0.32675387\n",
            "Iteration 19, loss = 0.32370500\n",
            "Iteration 20, loss = 0.32054807\n",
            "Iteration 21, loss = 0.31786661\n",
            "Iteration 22, loss = 0.31484520\n",
            "Iteration 23, loss = 0.31203695\n",
            "Iteration 24, loss = 0.30938642\n",
            "Iteration 25, loss = 0.30677701\n",
            "Iteration 26, loss = 0.30401292\n",
            "Iteration 27, loss = 0.30141463\n",
            "Iteration 28, loss = 0.29883646\n",
            "Iteration 29, loss = 0.29645577\n",
            "Iteration 30, loss = 0.29398219\n",
            "Iteration 31, loss = 0.29180498\n",
            "Iteration 32, loss = 0.28915069\n",
            "Iteration 33, loss = 0.28681685\n",
            "Iteration 34, loss = 0.28442906\n",
            "Iteration 35, loss = 0.28214158\n",
            "Iteration 36, loss = 0.27977198\n",
            "Iteration 37, loss = 0.27775316\n",
            "Iteration 38, loss = 0.27553528\n",
            "Iteration 39, loss = 0.27318812\n",
            "Iteration 40, loss = 0.27115296\n",
            "Iteration 41, loss = 0.26910868\n",
            "Iteration 42, loss = 0.26692311\n",
            "Iteration 43, loss = 0.26485543\n",
            "Iteration 44, loss = 0.26293252\n",
            "Iteration 45, loss = 0.26041127\n",
            "Iteration 46, loss = 0.25879325\n",
            "Iteration 47, loss = 0.25674595\n",
            "Iteration 48, loss = 0.25457355\n",
            "Iteration 49, loss = 0.25265278\n",
            "Iteration 50, loss = 0.25079687\n",
            "Iteration 51, loss = 0.24880605\n",
            "Iteration 52, loss = 0.24689919\n",
            "Iteration 53, loss = 0.24498420\n",
            "Iteration 54, loss = 0.24301543\n",
            "Iteration 55, loss = 0.24125145\n",
            "Iteration 56, loss = 0.23920834\n",
            "Iteration 57, loss = 0.23744569\n",
            "Iteration 58, loss = 0.23562499\n",
            "Iteration 59, loss = 0.23471675\n",
            "Iteration 60, loss = 0.23220001\n",
            "Iteration 61, loss = 0.23034625\n",
            "Iteration 62, loss = 0.22869564\n",
            "Iteration 63, loss = 0.22681769\n",
            "Iteration 64, loss = 0.22503477\n",
            "Iteration 65, loss = 0.22339094\n",
            "Iteration 66, loss = 0.22175425\n",
            "Iteration 67, loss = 0.22009180\n",
            "Iteration 68, loss = 0.21817435\n",
            "Iteration 69, loss = 0.21684189\n",
            "Iteration 70, loss = 0.21548521\n",
            "Iteration 71, loss = 0.21361849\n",
            "Iteration 72, loss = 0.21195277\n",
            "Iteration 73, loss = 0.21051487\n",
            "Iteration 74, loss = 0.20885880\n",
            "Iteration 75, loss = 0.20756890\n",
            "Iteration 76, loss = 0.20550496\n",
            "Iteration 77, loss = 0.20457710\n",
            "Iteration 78, loss = 0.20287104\n",
            "Iteration 79, loss = 0.20121353\n",
            "Iteration 80, loss = 0.20014567\n",
            "Iteration 81, loss = 0.19864217\n",
            "Iteration 82, loss = 0.19689992\n",
            "Iteration 83, loss = 0.19553638\n",
            "Iteration 84, loss = 0.19429041\n",
            "Iteration 85, loss = 0.19272592\n",
            "Iteration 86, loss = 0.19148947\n",
            "Iteration 87, loss = 0.19007052\n",
            "Iteration 88, loss = 0.18893916\n",
            "Iteration 89, loss = 0.18716008\n",
            "Iteration 90, loss = 0.18615248\n",
            "Iteration 91, loss = 0.18482524\n",
            "Iteration 92, loss = 0.18328381\n",
            "Iteration 93, loss = 0.18200663\n",
            "Iteration 94, loss = 0.18100081\n",
            "Iteration 95, loss = 0.17981798\n",
            "Iteration 96, loss = 0.17806115\n",
            "Iteration 97, loss = 0.17681866\n",
            "Iteration 98, loss = 0.17533151\n",
            "Iteration 99, loss = 0.17425657\n",
            "Iteration 100, loss = 0.17311836\n",
            "Iteration 101, loss = 0.17160097\n",
            "Iteration 102, loss = 0.17049746\n",
            "Iteration 103, loss = 0.16903363\n",
            "Iteration 104, loss = 0.16814686\n",
            "Iteration 105, loss = 0.16666767\n",
            "Iteration 106, loss = 0.16584242\n",
            "Iteration 107, loss = 0.16430512\n",
            "Iteration 108, loss = 0.16290915\n",
            "Iteration 109, loss = 0.16229569\n",
            "Iteration 110, loss = 0.16093314\n",
            "Iteration 111, loss = 0.15989874\n",
            "Iteration 112, loss = 0.15850526\n",
            "Iteration 113, loss = 0.15725115\n",
            "Iteration 114, loss = 0.15637237\n",
            "Iteration 115, loss = 0.15520987\n",
            "Iteration 116, loss = 0.15406364\n",
            "Iteration 117, loss = 0.15285157\n",
            "Iteration 118, loss = 0.15173948\n",
            "Iteration 119, loss = 0.15037306\n",
            "Iteration 120, loss = 0.14950924\n",
            "Iteration 121, loss = 0.14868272\n",
            "Iteration 122, loss = 0.14756576\n",
            "Iteration 123, loss = 0.14627878\n",
            "Iteration 124, loss = 0.14550619\n",
            "Iteration 125, loss = 0.14415624\n",
            "Iteration 126, loss = 0.14328978\n",
            "Iteration 127, loss = 0.14200368\n",
            "Iteration 128, loss = 0.14161714\n",
            "Iteration 129, loss = 0.14025640\n",
            "Iteration 130, loss = 0.13937306\n",
            "Iteration 131, loss = 0.13849151\n",
            "Iteration 132, loss = 0.13718338\n",
            "Iteration 133, loss = 0.13600302\n",
            "Iteration 134, loss = 0.13531869\n",
            "Iteration 135, loss = 0.13416126\n",
            "Iteration 136, loss = 0.13332912\n",
            "Iteration 137, loss = 0.13232461\n",
            "Iteration 138, loss = 0.13157543\n",
            "Iteration 139, loss = 0.13063560\n",
            "Iteration 140, loss = 0.12967278\n",
            "Iteration 141, loss = 0.12891725\n",
            "Iteration 142, loss = 0.12787846\n",
            "Iteration 143, loss = 0.12677266\n",
            "Iteration 144, loss = 0.12606425\n",
            "Iteration 145, loss = 0.12513355\n",
            "Iteration 146, loss = 0.12406846\n",
            "Iteration 147, loss = 0.12343283\n",
            "Iteration 148, loss = 0.12236820\n",
            "Iteration 149, loss = 0.12163502\n",
            "Iteration 150, loss = 0.12079193\n",
            "Iteration 151, loss = 0.11983605\n",
            "Iteration 152, loss = 0.11871028\n",
            "Iteration 153, loss = 0.11807283\n",
            "Iteration 154, loss = 0.11712231\n",
            "Iteration 155, loss = 0.11609441\n",
            "Iteration 156, loss = 0.11571897\n",
            "Iteration 157, loss = 0.11481206\n",
            "Iteration 158, loss = 0.11364903\n",
            "Iteration 159, loss = 0.11301880\n",
            "Iteration 160, loss = 0.11210604\n",
            "Iteration 161, loss = 0.11147249\n",
            "Iteration 162, loss = 0.11068977\n",
            "Iteration 163, loss = 0.10997821\n",
            "Iteration 164, loss = 0.10893828\n",
            "Iteration 165, loss = 0.10846105\n",
            "Iteration 166, loss = 0.10763971\n",
            "Iteration 167, loss = 0.10662608\n",
            "Iteration 168, loss = 0.10606706\n",
            "Iteration 169, loss = 0.10540817\n",
            "Iteration 170, loss = 0.10428660\n",
            "Iteration 171, loss = 0.10362106\n",
            "Iteration 172, loss = 0.10275677\n",
            "Iteration 173, loss = 0.10235345\n",
            "Iteration 174, loss = 0.10145306\n",
            "Iteration 175, loss = 0.10057754\n",
            "Iteration 176, loss = 0.10000415\n",
            "Iteration 177, loss = 0.09922222\n",
            "Iteration 178, loss = 0.09880220\n",
            "Iteration 179, loss = 0.09785268\n",
            "Iteration 180, loss = 0.09695453\n",
            "Iteration 181, loss = 0.09639224\n",
            "Iteration 182, loss = 0.09562705\n",
            "Iteration 183, loss = 0.09501776\n",
            "Iteration 184, loss = 0.09453916\n",
            "Iteration 185, loss = 0.09354563\n",
            "Iteration 186, loss = 0.09292388\n",
            "Iteration 187, loss = 0.09250538\n",
            "Iteration 188, loss = 0.09156673\n",
            "Iteration 189, loss = 0.09115821\n",
            "Iteration 190, loss = 0.09057829\n",
            "Iteration 191, loss = 0.08963606\n",
            "Iteration 192, loss = 0.08920039\n",
            "Iteration 193, loss = 0.08831313\n",
            "Iteration 194, loss = 0.08793686\n",
            "Iteration 195, loss = 0.08712640\n",
            "Iteration 196, loss = 0.08679747\n",
            "Iteration 197, loss = 0.08583509\n",
            "Iteration 198, loss = 0.08545029\n",
            "Iteration 199, loss = 0.08472535\n",
            "Iteration 200, loss = 0.08416655\n",
            "Iteration 201, loss = 0.08350781\n",
            "Iteration 202, loss = 0.08307295\n",
            "Iteration 203, loss = 0.08218407\n",
            "Iteration 204, loss = 0.08162626\n",
            "Iteration 205, loss = 0.08105019\n",
            "Iteration 206, loss = 0.08055996\n",
            "Iteration 207, loss = 0.08004826\n",
            "Iteration 208, loss = 0.07958501\n",
            "Iteration 209, loss = 0.07903440\n",
            "Iteration 210, loss = 0.07835483\n",
            "Iteration 211, loss = 0.07783591\n",
            "Iteration 212, loss = 0.07719051\n",
            "Iteration 213, loss = 0.07656644\n",
            "Iteration 214, loss = 0.07618624\n",
            "Iteration 215, loss = 0.07541503\n",
            "Iteration 216, loss = 0.07503998\n",
            "Iteration 217, loss = 0.07459436\n",
            "Iteration 218, loss = 0.07411956\n",
            "Iteration 219, loss = 0.07380194\n",
            "Iteration 220, loss = 0.07294358\n",
            "Iteration 221, loss = 0.07234992\n",
            "Iteration 222, loss = 0.07196778\n",
            "Iteration 223, loss = 0.07130560\n",
            "Iteration 224, loss = 0.07117633\n",
            "Iteration 225, loss = 0.07068686\n",
            "Iteration 226, loss = 0.06995409\n",
            "Iteration 227, loss = 0.06941245\n",
            "Iteration 228, loss = 0.06881499\n",
            "Iteration 229, loss = 0.06840721\n",
            "Iteration 230, loss = 0.06803063\n",
            "Iteration 231, loss = 0.06734769\n",
            "Iteration 232, loss = 0.06691911\n",
            "Iteration 233, loss = 0.06643396\n",
            "Iteration 234, loss = 0.06585238\n",
            "Iteration 235, loss = 0.06567089\n",
            "Iteration 236, loss = 0.06527066\n",
            "Iteration 237, loss = 0.06465374\n",
            "Iteration 238, loss = 0.06409146\n",
            "Iteration 239, loss = 0.06402567\n",
            "Iteration 240, loss = 0.06324713\n",
            "Iteration 241, loss = 0.06271299\n",
            "Iteration 242, loss = 0.06215829\n",
            "Iteration 243, loss = 0.06187480\n",
            "Iteration 244, loss = 0.06148777\n",
            "Iteration 245, loss = 0.06095394\n",
            "Iteration 246, loss = 0.06080045\n",
            "Iteration 247, loss = 0.06000851\n",
            "Iteration 248, loss = 0.06014586\n",
            "Iteration 249, loss = 0.05942142\n",
            "Iteration 250, loss = 0.05897979\n",
            "Iteration 251, loss = 0.05852300\n",
            "Iteration 252, loss = 0.05819948\n",
            "Iteration 253, loss = 0.05782755\n",
            "Iteration 254, loss = 0.05716040\n",
            "Iteration 255, loss = 0.05698664\n",
            "Iteration 256, loss = 0.05661394\n",
            "Iteration 257, loss = 0.05605307\n",
            "Iteration 258, loss = 0.05580080\n",
            "Iteration 259, loss = 0.05542491\n",
            "Iteration 260, loss = 0.05478484\n",
            "Iteration 261, loss = 0.05469115\n",
            "Iteration 262, loss = 0.05427950\n",
            "Iteration 263, loss = 0.05387677\n",
            "Iteration 264, loss = 0.05351139\n",
            "Iteration 265, loss = 0.05316045\n",
            "Iteration 266, loss = 0.05266427\n",
            "Iteration 267, loss = 0.05238416\n",
            "Iteration 268, loss = 0.05209748\n",
            "Iteration 269, loss = 0.05179184\n",
            "Iteration 270, loss = 0.05143051\n",
            "Iteration 271, loss = 0.05085811\n",
            "Iteration 272, loss = 0.05050786\n",
            "Iteration 273, loss = 0.05021654\n",
            "Iteration 274, loss = 0.04973826\n",
            "Iteration 275, loss = 0.04954751\n",
            "Iteration 276, loss = 0.04920371\n",
            "Iteration 277, loss = 0.04886082\n",
            "Iteration 278, loss = 0.04848397\n",
            "Iteration 279, loss = 0.04816449\n",
            "Iteration 280, loss = 0.04817591\n",
            "Iteration 281, loss = 0.04761954\n",
            "Iteration 282, loss = 0.04714236\n",
            "Iteration 283, loss = 0.04708067\n",
            "Iteration 284, loss = 0.04632880\n",
            "Iteration 285, loss = 0.04636581\n",
            "Iteration 286, loss = 0.04593449\n",
            "Iteration 287, loss = 0.04560719\n",
            "Iteration 288, loss = 0.04514423\n",
            "Iteration 289, loss = 0.04481192\n",
            "Iteration 290, loss = 0.04457801\n",
            "Iteration 291, loss = 0.04423945\n",
            "Iteration 292, loss = 0.04401403\n",
            "Iteration 293, loss = 0.04376150\n",
            "Iteration 294, loss = 0.04368193\n",
            "Iteration 295, loss = 0.04306893\n",
            "Iteration 296, loss = 0.04299953\n",
            "Iteration 297, loss = 0.04253417\n",
            "Iteration 298, loss = 0.04218995\n",
            "Iteration 299, loss = 0.04191619\n",
            "Iteration 300, loss = 0.04147570\n",
            "Iteration 301, loss = 0.04153494\n",
            "Iteration 302, loss = 0.04119741\n",
            "Iteration 303, loss = 0.04097140\n",
            "Iteration 304, loss = 0.04063861\n",
            "Iteration 305, loss = 0.04022548\n",
            "Iteration 306, loss = 0.04001936\n",
            "Iteration 307, loss = 0.03981369\n",
            "Iteration 308, loss = 0.03930438\n",
            "Iteration 309, loss = 0.03916956\n",
            "Iteration 310, loss = 0.03898017\n",
            "Iteration 311, loss = 0.03872370\n",
            "Iteration 312, loss = 0.03840531\n",
            "Iteration 313, loss = 0.03804684\n",
            "Iteration 314, loss = 0.03774947\n",
            "Iteration 315, loss = 0.03744034\n",
            "Iteration 316, loss = 0.03726342\n",
            "Iteration 317, loss = 0.03706501\n",
            "Iteration 318, loss = 0.03677215\n",
            "Iteration 319, loss = 0.03653221\n",
            "Iteration 320, loss = 0.03629201\n",
            "Iteration 321, loss = 0.03610770\n",
            "Iteration 322, loss = 0.03598169\n",
            "Iteration 323, loss = 0.03551541\n",
            "Iteration 324, loss = 0.03543724\n",
            "Iteration 325, loss = 0.03507249\n",
            "Iteration 326, loss = 0.03481508\n",
            "Iteration 327, loss = 0.03464030\n",
            "Iteration 328, loss = 0.03428367\n",
            "Iteration 329, loss = 0.03422279\n",
            "Iteration 330, loss = 0.03408174\n",
            "Iteration 331, loss = 0.03367353\n",
            "Iteration 332, loss = 0.03333315\n",
            "Iteration 333, loss = 0.03332231\n",
            "Iteration 334, loss = 0.03320021\n",
            "Iteration 335, loss = 0.03275151\n",
            "Iteration 336, loss = 0.03267926\n",
            "Iteration 337, loss = 0.03231979\n",
            "Iteration 338, loss = 0.03224169\n",
            "Iteration 339, loss = 0.03204459\n",
            "Iteration 340, loss = 0.03175327\n",
            "Iteration 341, loss = 0.03150868\n",
            "Iteration 342, loss = 0.03132339\n",
            "Iteration 343, loss = 0.03116785\n",
            "Iteration 344, loss = 0.03085143\n",
            "Iteration 345, loss = 0.03070270\n",
            "Iteration 346, loss = 0.03045875\n",
            "Iteration 347, loss = 0.03030523\n",
            "Iteration 348, loss = 0.03000919\n",
            "Iteration 349, loss = 0.02978498\n",
            "Iteration 350, loss = 0.02979818\n",
            "Iteration 351, loss = 0.02947278\n",
            "Iteration 352, loss = 0.02936002\n",
            "Iteration 353, loss = 0.02914811\n",
            "Iteration 354, loss = 0.02899760\n",
            "Iteration 355, loss = 0.02867094\n",
            "Iteration 356, loss = 0.02848392\n",
            "Iteration 357, loss = 0.02835308\n",
            "Iteration 358, loss = 0.02814018\n",
            "Iteration 359, loss = 0.02801716\n",
            "Iteration 360, loss = 0.02780859\n",
            "Iteration 361, loss = 0.02760242\n",
            "Iteration 362, loss = 0.02743845\n",
            "Iteration 363, loss = 0.02741019\n",
            "Iteration 364, loss = 0.02721343\n",
            "Iteration 365, loss = 0.02696028\n",
            "Iteration 366, loss = 0.02692448\n",
            "Iteration 367, loss = 0.02650919\n",
            "Iteration 368, loss = 0.02641244\n",
            "Iteration 369, loss = 0.02625003\n",
            "Iteration 370, loss = 0.02600065\n",
            "Iteration 371, loss = 0.02587315\n",
            "Iteration 372, loss = 0.02579857\n",
            "Iteration 373, loss = 0.02559952\n",
            "Iteration 374, loss = 0.02546075\n",
            "Iteration 375, loss = 0.02521692\n",
            "Iteration 376, loss = 0.02503040\n",
            "Iteration 377, loss = 0.02485925\n",
            "Iteration 378, loss = 0.02473224\n",
            "Iteration 379, loss = 0.02463302\n",
            "Iteration 380, loss = 0.02447002\n",
            "Iteration 381, loss = 0.02430835\n",
            "Iteration 382, loss = 0.02416933\n",
            "Iteration 383, loss = 0.02395911\n",
            "Iteration 384, loss = 0.02398427\n",
            "Iteration 385, loss = 0.02358777\n",
            "Iteration 386, loss = 0.02360757\n",
            "Iteration 387, loss = 0.02341563\n",
            "Iteration 388, loss = 0.02317826\n",
            "Iteration 389, loss = 0.02304297\n",
            "Iteration 390, loss = 0.02285792\n",
            "Iteration 391, loss = 0.02277572\n",
            "Iteration 392, loss = 0.02259576\n",
            "Iteration 393, loss = 0.02246693\n",
            "Iteration 394, loss = 0.02241451\n",
            "Iteration 395, loss = 0.02214994\n",
            "Iteration 396, loss = 0.02209501\n",
            "Iteration 397, loss = 0.02188788\n",
            "Iteration 398, loss = 0.02175360\n",
            "Iteration 399, loss = 0.02160779\n",
            "Iteration 400, loss = 0.02154693\n",
            "Iteration 401, loss = 0.02141728\n",
            "Iteration 402, loss = 0.02124548\n",
            "Iteration 403, loss = 0.02115537\n",
            "Iteration 404, loss = 0.02090281\n",
            "Iteration 405, loss = 0.02085816\n",
            "Iteration 406, loss = 0.02064204\n",
            "Iteration 407, loss = 0.02052261\n",
            "Iteration 408, loss = 0.02046740\n",
            "Iteration 409, loss = 0.02039126\n",
            "Iteration 410, loss = 0.02048209\n",
            "Iteration 411, loss = 0.01995123\n",
            "Iteration 412, loss = 0.02000192\n",
            "Iteration 413, loss = 0.02002437\n",
            "Iteration 414, loss = 0.01963531\n",
            "Iteration 415, loss = 0.01959138\n",
            "Iteration 416, loss = 0.01946490\n",
            "Iteration 417, loss = 0.01926072\n",
            "Iteration 418, loss = 0.01922636\n",
            "Iteration 419, loss = 0.01912579\n",
            "Iteration 420, loss = 0.01893877\n",
            "Iteration 421, loss = 0.01883219\n",
            "Iteration 422, loss = 0.01862673\n",
            "Iteration 423, loss = 0.01858503\n",
            "Iteration 424, loss = 0.01845694\n",
            "Iteration 425, loss = 0.01838555\n",
            "Iteration 426, loss = 0.01833088\n",
            "Iteration 427, loss = 0.01808287\n",
            "Iteration 428, loss = 0.01807086\n",
            "Iteration 429, loss = 0.01792008\n",
            "Iteration 430, loss = 0.01777827\n",
            "Iteration 431, loss = 0.01770415\n",
            "Iteration 432, loss = 0.01753682\n",
            "Iteration 433, loss = 0.01742819\n",
            "Iteration 434, loss = 0.01733738\n",
            "Iteration 435, loss = 0.01722859\n",
            "Iteration 436, loss = 0.01711217\n",
            "Iteration 437, loss = 0.01701090\n",
            "Iteration 438, loss = 0.01688841\n",
            "Iteration 439, loss = 0.01681744\n",
            "Iteration 440, loss = 0.01673923\n",
            "Iteration 441, loss = 0.01662966\n",
            "Iteration 442, loss = 0.01653337\n",
            "Iteration 443, loss = 0.01641024\n",
            "Iteration 444, loss = 0.01632093\n",
            "Iteration 445, loss = 0.01620620\n",
            "Iteration 446, loss = 0.01613977\n",
            "Iteration 447, loss = 0.01606287\n",
            "Iteration 448, loss = 0.01596999\n",
            "Iteration 449, loss = 0.01585112\n",
            "Iteration 450, loss = 0.01572560\n",
            "Iteration 451, loss = 0.01568026\n",
            "Iteration 452, loss = 0.01562154\n",
            "Iteration 453, loss = 0.01549177\n",
            "Iteration 454, loss = 0.01534724\n",
            "Iteration 455, loss = 0.01530952\n",
            "Iteration 456, loss = 0.01516807\n",
            "Iteration 457, loss = 0.01507380\n",
            "Iteration 458, loss = 0.01496341\n",
            "Iteration 459, loss = 0.01492603\n",
            "Iteration 460, loss = 0.01478739\n",
            "Iteration 461, loss = 0.01470124\n",
            "Iteration 462, loss = 0.01461602\n",
            "Iteration 463, loss = 0.01454408\n",
            "Iteration 464, loss = 0.01445636\n",
            "Iteration 465, loss = 0.01443358\n",
            "Iteration 466, loss = 0.01430230\n",
            "Iteration 467, loss = 0.01418713\n",
            "Iteration 468, loss = 0.01410270\n",
            "Iteration 469, loss = 0.01405329\n",
            "Iteration 470, loss = 0.01395699\n",
            "Iteration 471, loss = 0.01385369\n",
            "Iteration 472, loss = 0.01381348\n",
            "Iteration 473, loss = 0.01369164\n",
            "Iteration 474, loss = 0.01363116\n",
            "Iteration 475, loss = 0.01353389\n",
            "Iteration 476, loss = 0.01352639\n",
            "Iteration 477, loss = 0.01336778\n",
            "Iteration 478, loss = 0.01340464\n",
            "Iteration 479, loss = 0.01323575\n",
            "Iteration 480, loss = 0.01326690\n",
            "Iteration 481, loss = 0.01307325\n",
            "Iteration 482, loss = 0.01299307\n",
            "Iteration 483, loss = 0.01292455\n",
            "Iteration 484, loss = 0.01290394\n",
            "Iteration 485, loss = 0.01273923\n",
            "Iteration 486, loss = 0.01265658\n",
            "Iteration 487, loss = 0.01267303\n",
            "Iteration 488, loss = 0.01255107\n",
            "Iteration 489, loss = 0.01249534\n",
            "Iteration 490, loss = 0.01248480\n",
            "Iteration 491, loss = 0.01231892\n",
            "Iteration 492, loss = 0.01224224\n",
            "Iteration 493, loss = 0.01217262\n",
            "Iteration 494, loss = 0.01212390\n",
            "Iteration 495, loss = 0.01213749\n",
            "Iteration 496, loss = 0.01205893\n",
            "Iteration 497, loss = 0.01191037\n",
            "Iteration 498, loss = 0.01186193\n",
            "Iteration 499, loss = 0.01179021\n",
            "Iteration 500, loss = 0.01166796\n",
            "Iteration 501, loss = 0.01161257\n",
            "Iteration 502, loss = 0.01156271\n",
            "Iteration 503, loss = 0.01153421\n",
            "Iteration 504, loss = 0.01145187\n",
            "Iteration 505, loss = 0.01134082\n",
            "Iteration 506, loss = 0.01130632\n",
            "Iteration 507, loss = 0.01123757\n",
            "Iteration 508, loss = 0.01115505\n",
            "Iteration 509, loss = 0.01110492\n",
            "Iteration 510, loss = 0.01101694\n",
            "Iteration 511, loss = 0.01098411\n",
            "Iteration 512, loss = 0.01090064\n",
            "Iteration 513, loss = 0.01085612\n",
            "Iteration 514, loss = 0.01078029\n",
            "Iteration 515, loss = 0.01073979\n",
            "Iteration 516, loss = 0.01068581\n",
            "Iteration 517, loss = 0.01063631\n",
            "Iteration 518, loss = 0.01057935\n",
            "Iteration 519, loss = 0.01050276\n",
            "Iteration 520, loss = 0.01045020\n",
            "Iteration 521, loss = 0.01039415\n",
            "Iteration 522, loss = 0.01031025\n",
            "Iteration 523, loss = 0.01027794\n",
            "Iteration 524, loss = 0.01020631\n",
            "Iteration 525, loss = 0.01015344\n",
            "Iteration 526, loss = 0.01011406\n",
            "Iteration 527, loss = 0.01006790\n",
            "Iteration 528, loss = 0.00999261\n",
            "Iteration 529, loss = 0.00991462\n",
            "Iteration 530, loss = 0.00985501\n",
            "Iteration 531, loss = 0.00978931\n",
            "Iteration 532, loss = 0.00977119\n",
            "Iteration 533, loss = 0.00974023\n",
            "Iteration 534, loss = 0.00964929\n",
            "Iteration 535, loss = 0.00958595\n",
            "Iteration 536, loss = 0.00951613\n",
            "Iteration 537, loss = 0.00947423\n",
            "Iteration 538, loss = 0.00943504\n",
            "Iteration 539, loss = 0.00946548\n",
            "Iteration 540, loss = 0.00929263\n",
            "Iteration 541, loss = 0.00928494\n",
            "Iteration 542, loss = 0.00919297\n",
            "Iteration 543, loss = 0.00917992\n",
            "Iteration 544, loss = 0.00909699\n",
            "Iteration 545, loss = 0.00908185\n",
            "Iteration 546, loss = 0.00901395\n",
            "Iteration 547, loss = 0.00899386\n",
            "Iteration 548, loss = 0.00890480\n",
            "Iteration 549, loss = 0.00887208\n",
            "Iteration 550, loss = 0.00885837\n",
            "Iteration 551, loss = 0.00879550\n",
            "Iteration 552, loss = 0.00873661\n",
            "Iteration 553, loss = 0.00866037\n",
            "Iteration 554, loss = 0.00864348\n",
            "Iteration 555, loss = 0.00859515\n",
            "Iteration 556, loss = 0.00855972\n",
            "Iteration 557, loss = 0.00846174\n",
            "Iteration 558, loss = 0.00848075\n",
            "Iteration 559, loss = 0.00839665\n",
            "Iteration 560, loss = 0.00836677\n",
            "Iteration 561, loss = 0.00843094\n",
            "Iteration 562, loss = 0.00829633\n",
            "Iteration 563, loss = 0.00823957\n",
            "Iteration 564, loss = 0.00820032\n",
            "Iteration 565, loss = 0.00812867\n",
            "Iteration 566, loss = 0.00806029\n",
            "Iteration 567, loss = 0.00803195\n",
            "Iteration 568, loss = 0.00800290\n",
            "Iteration 569, loss = 0.00793720\n",
            "Iteration 570, loss = 0.00789900\n",
            "Iteration 571, loss = 0.00785693\n",
            "Iteration 572, loss = 0.00780940\n",
            "Iteration 573, loss = 0.00777423\n",
            "Iteration 574, loss = 0.00771672\n",
            "Iteration 575, loss = 0.00768959\n",
            "Iteration 576, loss = 0.00764170\n",
            "Iteration 577, loss = 0.00761457\n",
            "Iteration 578, loss = 0.00757643\n",
            "Iteration 579, loss = 0.00751859\n",
            "Iteration 580, loss = 0.00748415\n",
            "Iteration 581, loss = 0.00743135\n",
            "Iteration 582, loss = 0.00744491\n",
            "Iteration 583, loss = 0.00743642\n",
            "Iteration 584, loss = 0.00735293\n",
            "Iteration 585, loss = 0.00731271\n",
            "Iteration 586, loss = 0.00724671\n",
            "Iteration 587, loss = 0.00722214\n",
            "Iteration 588, loss = 0.00716521\n",
            "Iteration 589, loss = 0.00713220\n",
            "Iteration 590, loss = 0.00712111\n",
            "Iteration 591, loss = 0.00703786\n",
            "Iteration 592, loss = 0.00704531\n",
            "Iteration 593, loss = 0.00699198\n",
            "Iteration 594, loss = 0.00695910\n",
            "Iteration 595, loss = 0.00691624\n",
            "Iteration 596, loss = 0.00689439\n",
            "Iteration 597, loss = 0.00682710\n",
            "Iteration 598, loss = 0.00680721\n",
            "Iteration 599, loss = 0.00676432\n",
            "Iteration 600, loss = 0.00673419\n",
            "Iteration 601, loss = 0.00672319\n",
            "Iteration 602, loss = 0.00670361\n",
            "Iteration 603, loss = 0.00665941\n",
            "Iteration 604, loss = 0.00658943\n",
            "Iteration 605, loss = 0.00656896\n",
            "Iteration 606, loss = 0.00653546\n",
            "Iteration 607, loss = 0.00650126\n",
            "Iteration 608, loss = 0.00647339\n",
            "Iteration 609, loss = 0.00641820\n",
            "Iteration 610, loss = 0.00637774\n",
            "Iteration 611, loss = 0.00637566\n",
            "Iteration 612, loss = 0.00631280\n",
            "Iteration 613, loss = 0.00630293\n",
            "Iteration 614, loss = 0.00625680\n",
            "Iteration 615, loss = 0.00623339\n",
            "Iteration 616, loss = 0.00618198\n",
            "Iteration 617, loss = 0.00617263\n",
            "Iteration 618, loss = 0.00612919\n",
            "Iteration 619, loss = 0.00610916\n",
            "Iteration 620, loss = 0.00607689\n",
            "Iteration 621, loss = 0.00604446\n",
            "Iteration 622, loss = 0.00601231\n",
            "Iteration 623, loss = 0.00597680\n",
            "Iteration 624, loss = 0.00594180\n",
            "Iteration 625, loss = 0.00592016\n",
            "Iteration 626, loss = 0.00587649\n",
            "Iteration 627, loss = 0.00584979\n",
            "Iteration 628, loss = 0.00583138\n",
            "Iteration 629, loss = 0.00582183\n",
            "Iteration 630, loss = 0.00577489\n",
            "Iteration 631, loss = 0.00574338\n",
            "Iteration 632, loss = 0.00571927\n",
            "Iteration 633, loss = 0.00568182\n",
            "Iteration 634, loss = 0.00566007\n",
            "Iteration 635, loss = 0.00563024\n",
            "Iteration 636, loss = 0.00559704\n",
            "Iteration 637, loss = 0.00559496\n",
            "Iteration 638, loss = 0.00554470\n",
            "Iteration 639, loss = 0.00551100\n",
            "Iteration 640, loss = 0.00547710\n",
            "Iteration 641, loss = 0.00545051\n",
            "Iteration 642, loss = 0.00543236\n",
            "Iteration 643, loss = 0.00540582\n",
            "Iteration 644, loss = 0.00538778\n",
            "Iteration 645, loss = 0.00534821\n",
            "Iteration 646, loss = 0.00532206\n",
            "Iteration 647, loss = 0.00528519\n",
            "Iteration 648, loss = 0.00527690\n",
            "Iteration 649, loss = 0.00526543\n",
            "Iteration 650, loss = 0.00523317\n",
            "Iteration 651, loss = 0.00520510\n",
            "Iteration 652, loss = 0.00516873\n",
            "Iteration 653, loss = 0.00513214\n",
            "Iteration 654, loss = 0.00511360\n",
            "Iteration 655, loss = 0.00509187\n",
            "Iteration 656, loss = 0.00506613\n",
            "Iteration 657, loss = 0.00504042\n",
            "Iteration 658, loss = 0.00502154\n",
            "Iteration 659, loss = 0.00499459\n",
            "Iteration 660, loss = 0.00496090\n",
            "Iteration 661, loss = 0.00494198\n",
            "Iteration 662, loss = 0.00492111\n",
            "Iteration 663, loss = 0.00490056\n",
            "Iteration 664, loss = 0.00489545\n",
            "Iteration 665, loss = 0.00485717\n",
            "Iteration 666, loss = 0.00483453\n",
            "Iteration 667, loss = 0.00481116\n",
            "Iteration 668, loss = 0.00478549\n",
            "Iteration 669, loss = 0.00479568\n",
            "Iteration 670, loss = 0.00475598\n",
            "Iteration 671, loss = 0.00472020\n",
            "Iteration 672, loss = 0.00468621\n",
            "Iteration 673, loss = 0.00470794\n",
            "Iteration 674, loss = 0.00463336\n",
            "Iteration 675, loss = 0.00462543\n",
            "Iteration 676, loss = 0.00459267\n",
            "Iteration 677, loss = 0.00456887\n",
            "Iteration 678, loss = 0.00455709\n",
            "Iteration 679, loss = 0.00453071\n",
            "Iteration 680, loss = 0.00450737\n",
            "Iteration 681, loss = 0.00450997\n",
            "Iteration 682, loss = 0.00446759\n",
            "Iteration 683, loss = 0.00445258\n",
            "Iteration 684, loss = 0.00446473\n",
            "Iteration 685, loss = 0.00439015\n",
            "Iteration 686, loss = 0.00438732\n",
            "Iteration 687, loss = 0.00434808\n",
            "Iteration 688, loss = 0.00433520\n",
            "Iteration 689, loss = 0.00431498\n",
            "Iteration 690, loss = 0.00429417\n",
            "Iteration 691, loss = 0.00427697\n",
            "Iteration 692, loss = 0.00426271\n",
            "Iteration 693, loss = 0.00423288\n",
            "Iteration 694, loss = 0.00420244\n",
            "Iteration 695, loss = 0.00418983\n",
            "Iteration 696, loss = 0.00416113\n",
            "Iteration 697, loss = 0.00415567\n",
            "Iteration 698, loss = 0.00413368\n",
            "Iteration 699, loss = 0.00410417\n",
            "Iteration 700, loss = 0.00409833\n",
            "Iteration 701, loss = 0.00407667\n",
            "Iteration 702, loss = 0.00406110\n",
            "Iteration 703, loss = 0.00403002\n",
            "Iteration 704, loss = 0.00401230\n",
            "Iteration 705, loss = 0.00399717\n",
            "Iteration 706, loss = 0.00398295\n",
            "Iteration 707, loss = 0.00395745\n",
            "Iteration 708, loss = 0.00393329\n",
            "Iteration 709, loss = 0.00392131\n",
            "Iteration 710, loss = 0.00389650\n",
            "Iteration 711, loss = 0.00388388\n",
            "Iteration 712, loss = 0.00386518\n",
            "Iteration 713, loss = 0.00384594\n",
            "Iteration 714, loss = 0.00382994\n",
            "Iteration 715, loss = 0.00380127\n",
            "Iteration 716, loss = 0.00380413\n",
            "Iteration 717, loss = 0.00377403\n",
            "Iteration 718, loss = 0.00375908\n",
            "Iteration 719, loss = 0.00374019\n",
            "Iteration 720, loss = 0.00371750\n",
            "Iteration 721, loss = 0.00370359\n",
            "Iteration 722, loss = 0.00369163\n",
            "Iteration 723, loss = 0.00366874\n",
            "Iteration 724, loss = 0.00364907\n",
            "Iteration 725, loss = 0.00363777\n",
            "Iteration 726, loss = 0.00362177\n",
            "Iteration 727, loss = 0.00360389\n",
            "Iteration 728, loss = 0.00359272\n",
            "Iteration 729, loss = 0.00358290\n",
            "Iteration 730, loss = 0.00355621\n",
            "Iteration 731, loss = 0.00354397\n",
            "Iteration 732, loss = 0.00352544\n",
            "Iteration 733, loss = 0.00349603\n",
            "Iteration 734, loss = 0.00348146\n",
            "Iteration 735, loss = 0.00347860\n",
            "Iteration 736, loss = 0.00344984\n",
            "Iteration 737, loss = 0.00343725\n",
            "Iteration 738, loss = 0.00342274\n",
            "Iteration 739, loss = 0.00340238\n",
            "Iteration 740, loss = 0.00340344\n",
            "Iteration 741, loss = 0.00337942\n",
            "Iteration 742, loss = 0.00336486\n",
            "Iteration 743, loss = 0.00335201\n",
            "Iteration 744, loss = 0.00335176\n",
            "Iteration 745, loss = 0.00331612\n",
            "Iteration 746, loss = 0.00329691\n",
            "Iteration 747, loss = 0.00328430\n",
            "Iteration 748, loss = 0.00326804\n",
            "Iteration 749, loss = 0.00325741\n",
            "Iteration 750, loss = 0.00324752\n",
            "Iteration 751, loss = 0.00322048\n",
            "Iteration 752, loss = 0.00321834\n",
            "Iteration 753, loss = 0.00320341\n",
            "Iteration 754, loss = 0.00318043\n",
            "Iteration 755, loss = 0.00316550\n",
            "Iteration 756, loss = 0.00316136\n",
            "Iteration 757, loss = 0.00314223\n",
            "Iteration 758, loss = 0.00313267\n",
            "Iteration 759, loss = 0.00312151\n",
            "Iteration 760, loss = 0.00309804\n",
            "Iteration 761, loss = 0.00308780\n",
            "Iteration 762, loss = 0.00307438\n",
            "Iteration 763, loss = 0.00306169\n",
            "Iteration 764, loss = 0.00304080\n",
            "Iteration 765, loss = 0.00302676\n",
            "Iteration 766, loss = 0.00301930\n",
            "Iteration 767, loss = 0.00299912\n",
            "Iteration 768, loss = 0.00298977\n",
            "Iteration 769, loss = 0.00297805\n",
            "Iteration 770, loss = 0.00297904\n",
            "Iteration 771, loss = 0.00294727\n",
            "Iteration 772, loss = 0.00293442\n",
            "Iteration 773, loss = 0.00291907\n",
            "Iteration 774, loss = 0.00291010\n",
            "Iteration 775, loss = 0.00289638\n",
            "Iteration 776, loss = 0.00287905\n",
            "Iteration 777, loss = 0.00286450\n",
            "Iteration 778, loss = 0.00286306\n",
            "Iteration 779, loss = 0.00283924\n",
            "Iteration 780, loss = 0.00282955\n",
            "Iteration 781, loss = 0.00281972\n",
            "Iteration 782, loss = 0.00280141\n",
            "Iteration 783, loss = 0.00279847\n",
            "Iteration 784, loss = 0.00277990\n",
            "Iteration 785, loss = 0.00276817\n",
            "Iteration 786, loss = 0.00275532\n",
            "Iteration 787, loss = 0.00274218\n",
            "Iteration 788, loss = 0.00272711\n",
            "Iteration 789, loss = 0.00271621\n",
            "Iteration 790, loss = 0.00271210\n",
            "Iteration 791, loss = 0.00270448\n",
            "Iteration 792, loss = 0.00268588\n",
            "Iteration 793, loss = 0.00266803\n",
            "Iteration 794, loss = 0.00265505\n",
            "Iteration 795, loss = 0.00265508\n",
            "Iteration 796, loss = 0.00263923\n",
            "Iteration 797, loss = 0.00263010\n",
            "Iteration 798, loss = 0.00263705\n",
            "Iteration 799, loss = 0.00260695\n",
            "Iteration 800, loss = 0.00259106\n",
            "Iteration 801, loss = 0.00257493\n",
            "Iteration 802, loss = 0.00256609\n",
            "Iteration 803, loss = 0.00255563\n",
            "Iteration 804, loss = 0.00254569\n",
            "Iteration 805, loss = 0.00253247\n",
            "Iteration 806, loss = 0.00252742\n",
            "Iteration 807, loss = 0.00251757\n",
            "Iteration 808, loss = 0.00250960\n",
            "Iteration 809, loss = 0.00248499\n",
            "Iteration 810, loss = 0.00247907\n",
            "Iteration 811, loss = 0.00248532\n",
            "Iteration 812, loss = 0.00246270\n",
            "Iteration 813, loss = 0.00245708\n",
            "Iteration 814, loss = 0.00244146\n",
            "Iteration 815, loss = 0.00242244\n",
            "Iteration 816, loss = 0.00241861\n",
            "Iteration 817, loss = 0.00241231\n",
            "Iteration 818, loss = 0.00239498\n",
            "Iteration 819, loss = 0.00238677\n",
            "Iteration 820, loss = 0.00237519\n",
            "Iteration 821, loss = 0.00236158\n",
            "Iteration 822, loss = 0.00235208\n",
            "Iteration 823, loss = 0.00234750\n",
            "Iteration 824, loss = 0.00232998\n",
            "Iteration 825, loss = 0.00232746\n",
            "Iteration 826, loss = 0.00231133\n",
            "Iteration 827, loss = 0.00229622\n",
            "Iteration 828, loss = 0.00229679\n",
            "Iteration 829, loss = 0.00227853\n",
            "Iteration 830, loss = 0.00227020\n",
            "Iteration 831, loss = 0.00227451\n",
            "Iteration 832, loss = 0.00226201\n",
            "Iteration 833, loss = 0.00224849\n",
            "Iteration 834, loss = 0.00223568\n",
            "Iteration 835, loss = 0.00223339\n",
            "Iteration 836, loss = 0.00221674\n",
            "Iteration 837, loss = 0.00221253\n",
            "Iteration 838, loss = 0.00219608\n",
            "Iteration 839, loss = 0.00219018\n",
            "Iteration 840, loss = 0.00219921\n",
            "Iteration 841, loss = 0.00217415\n",
            "Iteration 842, loss = 0.00216216\n",
            "Iteration 843, loss = 0.00214765\n",
            "Iteration 844, loss = 0.00215271\n",
            "Iteration 845, loss = 0.00212843\n",
            "Iteration 846, loss = 0.00212640\n",
            "Iteration 847, loss = 0.00211233\n",
            "Iteration 848, loss = 0.00211305\n",
            "Iteration 849, loss = 0.00209363\n",
            "Iteration 850, loss = 0.00209175\n",
            "Iteration 851, loss = 0.00209165\n",
            "Iteration 852, loss = 0.00207171\n",
            "Iteration 853, loss = 0.00206597\n",
            "Iteration 854, loss = 0.00205176\n",
            "Iteration 855, loss = 0.00204207\n",
            "Iteration 856, loss = 0.00203939\n",
            "Iteration 857, loss = 0.00203212\n",
            "Iteration 858, loss = 0.00201959\n",
            "Iteration 859, loss = 0.00200901\n",
            "Iteration 860, loss = 0.00200088\n",
            "Iteration 861, loss = 0.00199715\n",
            "Iteration 862, loss = 0.00198109\n",
            "Iteration 863, loss = 0.00197715\n",
            "Iteration 864, loss = 0.00197389\n",
            "Iteration 865, loss = 0.00196649\n",
            "Iteration 866, loss = 0.00195000\n",
            "Iteration 867, loss = 0.00194640\n",
            "Iteration 868, loss = 0.00194049\n",
            "Iteration 869, loss = 0.00192213\n",
            "Iteration 870, loss = 0.00192138\n",
            "Iteration 871, loss = 0.00191693\n",
            "Iteration 872, loss = 0.00191048\n",
            "Iteration 873, loss = 0.00189659\n",
            "Iteration 874, loss = 0.00188328\n",
            "Iteration 875, loss = 0.00188377\n",
            "Iteration 876, loss = 0.00187488\n",
            "Iteration 877, loss = 0.00186608\n",
            "Iteration 878, loss = 0.00185628\n",
            "Iteration 879, loss = 0.00185154\n",
            "Iteration 880, loss = 0.00183929\n",
            "Iteration 881, loss = 0.00182906\n",
            "Iteration 882, loss = 0.00182565\n",
            "Iteration 883, loss = 0.00181859\n",
            "Iteration 884, loss = 0.00180700\n",
            "Iteration 885, loss = 0.00180134\n",
            "Iteration 886, loss = 0.00179449\n",
            "Iteration 887, loss = 0.00178398\n",
            "Iteration 888, loss = 0.00177753\n",
            "Iteration 889, loss = 0.00177225\n",
            "Iteration 890, loss = 0.00176764\n",
            "Iteration 891, loss = 0.00175865\n",
            "Iteration 892, loss = 0.00174785\n",
            "Iteration 893, loss = 0.00174410\n",
            "Iteration 894, loss = 0.00173726\n",
            "Iteration 895, loss = 0.00173036\n",
            "Iteration 896, loss = 0.00172163\n",
            "Iteration 897, loss = 0.00171165\n",
            "Iteration 898, loss = 0.00171220\n",
            "Iteration 899, loss = 0.00170146\n",
            "Iteration 900, loss = 0.00170141\n",
            "Iteration 901, loss = 0.00168489\n",
            "Iteration 902, loss = 0.00168335\n",
            "Iteration 903, loss = 0.00167135\n",
            "Iteration 904, loss = 0.00166854\n",
            "Iteration 905, loss = 0.00165849\n",
            "Iteration 906, loss = 0.00165138\n",
            "Iteration 907, loss = 0.00165198\n",
            "Iteration 908, loss = 0.00165036\n",
            "Iteration 909, loss = 0.00163704\n",
            "Iteration 910, loss = 0.00163618\n",
            "Iteration 911, loss = 0.00161982\n",
            "Iteration 912, loss = 0.00161454\n",
            "Iteration 913, loss = 0.00160678\n",
            "Iteration 914, loss = 0.00160382\n",
            "Iteration 915, loss = 0.00159687\n",
            "Iteration 916, loss = 0.00159107\n",
            "Iteration 917, loss = 0.00159058\n",
            "Iteration 918, loss = 0.00157502\n",
            "Iteration 919, loss = 0.00156843\n",
            "Iteration 920, loss = 0.00156945\n",
            "Iteration 921, loss = 0.00155837\n",
            "Iteration 922, loss = 0.00155452\n",
            "Iteration 923, loss = 0.00154335\n",
            "Iteration 924, loss = 0.00153776\n",
            "Iteration 925, loss = 0.00153014\n",
            "Iteration 926, loss = 0.00152548\n",
            "Iteration 927, loss = 0.00152203\n",
            "Iteration 928, loss = 0.00152220\n",
            "Iteration 929, loss = 0.00151004\n",
            "Iteration 930, loss = 0.00150115\n",
            "Iteration 931, loss = 0.00149900\n",
            "Iteration 932, loss = 0.00148739\n",
            "Iteration 933, loss = 0.00148429\n",
            "Iteration 934, loss = 0.00147473\n",
            "Iteration 935, loss = 0.00147150\n",
            "Iteration 936, loss = 0.00146587\n",
            "Iteration 937, loss = 0.00146470\n",
            "Iteration 938, loss = 0.00145401\n",
            "Iteration 939, loss = 0.00144729\n",
            "Iteration 940, loss = 0.00144072\n",
            "Iteration 941, loss = 0.00143683\n",
            "Iteration 942, loss = 0.00143323\n",
            "Iteration 943, loss = 0.00142800\n",
            "Iteration 944, loss = 0.00141910\n",
            "Iteration 945, loss = 0.00141519\n",
            "Iteration 946, loss = 0.00140923\n",
            "Iteration 947, loss = 0.00140415\n",
            "Iteration 948, loss = 0.00140034\n",
            "Iteration 949, loss = 0.00139174\n",
            "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.63519821\n",
            "Iteration 2, loss = 0.54360667\n",
            "Iteration 3, loss = 0.48143940\n",
            "Iteration 4, loss = 0.44283479\n",
            "Iteration 5, loss = 0.41872313\n",
            "Iteration 6, loss = 0.40332535\n",
            "Iteration 7, loss = 0.39253182\n",
            "Iteration 8, loss = 0.38386242\n",
            "Iteration 9, loss = 0.37693101\n",
            "Iteration 10, loss = 0.37103884\n",
            "Iteration 11, loss = 0.36582986\n",
            "Iteration 12, loss = 0.36097344\n",
            "Iteration 13, loss = 0.35667036\n",
            "Iteration 14, loss = 0.35295280\n",
            "Iteration 15, loss = 0.34919548\n",
            "Iteration 16, loss = 0.34560197\n",
            "Iteration 17, loss = 0.34238835\n",
            "Iteration 18, loss = 0.33908243\n",
            "Iteration 19, loss = 0.33643560\n",
            "Iteration 20, loss = 0.33339749\n",
            "Iteration 21, loss = 0.33081367\n",
            "Iteration 22, loss = 0.32822402\n",
            "Iteration 23, loss = 0.32557212\n",
            "Iteration 24, loss = 0.32316423\n",
            "Iteration 25, loss = 0.32078215\n",
            "Iteration 26, loss = 0.31849303\n",
            "Iteration 27, loss = 0.31621714\n",
            "Iteration 28, loss = 0.31400909\n",
            "Iteration 29, loss = 0.31177292\n",
            "Iteration 30, loss = 0.30954369\n",
            "Iteration 31, loss = 0.30778343\n",
            "Iteration 32, loss = 0.30548567\n",
            "Iteration 33, loss = 0.30341042\n",
            "Iteration 34, loss = 0.30148520\n",
            "Iteration 35, loss = 0.29939616\n",
            "Iteration 36, loss = 0.29759483\n",
            "Iteration 37, loss = 0.29571145\n",
            "Iteration 38, loss = 0.29387848\n",
            "Iteration 39, loss = 0.29244321\n",
            "Iteration 40, loss = 0.28993810\n",
            "Iteration 41, loss = 0.28822696\n",
            "Iteration 42, loss = 0.28659802\n",
            "Iteration 43, loss = 0.28461277\n",
            "Iteration 44, loss = 0.28256482\n",
            "Iteration 45, loss = 0.28127407\n",
            "Iteration 46, loss = 0.27920745\n",
            "Iteration 47, loss = 0.27744724\n",
            "Iteration 48, loss = 0.27553166\n",
            "Iteration 49, loss = 0.27382531\n",
            "Iteration 50, loss = 0.27203672\n",
            "Iteration 51, loss = 0.27034276\n",
            "Iteration 52, loss = 0.26847670\n",
            "Iteration 53, loss = 0.26694943\n",
            "Iteration 54, loss = 0.26523336\n",
            "Iteration 55, loss = 0.26361731\n",
            "Iteration 56, loss = 0.26202701\n",
            "Iteration 57, loss = 0.26035345\n",
            "Iteration 58, loss = 0.25880104\n",
            "Iteration 59, loss = 0.25707997\n",
            "Iteration 60, loss = 0.25531891\n",
            "Iteration 61, loss = 0.25385480\n",
            "Iteration 62, loss = 0.25241197\n",
            "Iteration 63, loss = 0.25111484\n",
            "Iteration 64, loss = 0.24924886\n",
            "Iteration 65, loss = 0.24772793\n",
            "Iteration 66, loss = 0.24659583\n",
            "Iteration 67, loss = 0.24490333\n",
            "Iteration 68, loss = 0.24349230\n",
            "Iteration 69, loss = 0.24188763\n",
            "Iteration 70, loss = 0.24033176\n",
            "Iteration 71, loss = 0.23861791\n",
            "Iteration 72, loss = 0.23707457\n",
            "Iteration 73, loss = 0.23572889\n",
            "Iteration 74, loss = 0.23428700\n",
            "Iteration 75, loss = 0.23281188\n",
            "Iteration 76, loss = 0.23125965\n",
            "Iteration 77, loss = 0.23001714\n",
            "Iteration 78, loss = 0.22840552\n",
            "Iteration 79, loss = 0.22725538\n",
            "Iteration 80, loss = 0.22562204\n",
            "Iteration 81, loss = 0.22420697\n",
            "Iteration 82, loss = 0.22315858\n",
            "Iteration 83, loss = 0.22152553\n",
            "Iteration 84, loss = 0.21982982\n",
            "Iteration 85, loss = 0.21868732\n",
            "Iteration 86, loss = 0.21734741\n",
            "Iteration 87, loss = 0.21596297\n",
            "Iteration 88, loss = 0.21476817\n",
            "Iteration 89, loss = 0.21339451\n",
            "Iteration 90, loss = 0.21194833\n",
            "Iteration 91, loss = 0.21069146\n",
            "Iteration 92, loss = 0.20967209\n",
            "Iteration 93, loss = 0.20872665\n",
            "Iteration 94, loss = 0.20712999\n",
            "Iteration 95, loss = 0.20601411\n",
            "Iteration 96, loss = 0.20476464\n",
            "Iteration 97, loss = 0.20354536\n",
            "Iteration 98, loss = 0.20246036\n",
            "Iteration 99, loss = 0.20079309\n",
            "Iteration 100, loss = 0.19973024\n",
            "Iteration 101, loss = 0.19869970\n",
            "Iteration 102, loss = 0.19751571\n",
            "Iteration 103, loss = 0.19655445\n",
            "Iteration 104, loss = 0.19500707\n",
            "Iteration 105, loss = 0.19399805\n",
            "Iteration 106, loss = 0.19265487\n",
            "Iteration 107, loss = 0.19199872\n",
            "Iteration 108, loss = 0.19031973\n",
            "Iteration 109, loss = 0.18926717\n",
            "Iteration 110, loss = 0.18828127\n",
            "Iteration 111, loss = 0.18709739\n",
            "Iteration 112, loss = 0.18586940\n",
            "Iteration 113, loss = 0.18492012\n",
            "Iteration 114, loss = 0.18413667\n",
            "Iteration 115, loss = 0.18297011\n",
            "Iteration 116, loss = 0.18206851\n",
            "Iteration 117, loss = 0.18088124\n",
            "Iteration 118, loss = 0.17949002\n",
            "Iteration 119, loss = 0.17855513\n",
            "Iteration 120, loss = 0.17754795\n",
            "Iteration 121, loss = 0.17639936\n",
            "Iteration 122, loss = 0.17546046\n",
            "Iteration 123, loss = 0.17454897\n",
            "Iteration 124, loss = 0.17369989\n",
            "Iteration 125, loss = 0.17227334\n",
            "Iteration 126, loss = 0.17115454\n",
            "Iteration 127, loss = 0.17088402\n",
            "Iteration 128, loss = 0.16914981\n",
            "Iteration 129, loss = 0.16821433\n",
            "Iteration 130, loss = 0.16746653\n",
            "Iteration 131, loss = 0.16640299\n",
            "Iteration 132, loss = 0.16545672\n",
            "Iteration 133, loss = 0.16455352\n",
            "Iteration 134, loss = 0.16379382\n",
            "Iteration 135, loss = 0.16327314\n",
            "Iteration 136, loss = 0.16150562\n",
            "Iteration 137, loss = 0.16120062\n",
            "Iteration 138, loss = 0.15978332\n",
            "Iteration 139, loss = 0.15921137\n",
            "Iteration 140, loss = 0.15782016\n",
            "Iteration 141, loss = 0.15696423\n",
            "Iteration 142, loss = 0.15589140\n",
            "Iteration 143, loss = 0.15517621\n",
            "Iteration 144, loss = 0.15408602\n",
            "Iteration 145, loss = 0.15356063\n",
            "Iteration 146, loss = 0.15235712\n",
            "Iteration 147, loss = 0.15171425\n",
            "Iteration 148, loss = 0.15075891\n",
            "Iteration 149, loss = 0.14993520\n",
            "Iteration 150, loss = 0.14869564\n",
            "Iteration 151, loss = 0.14810551\n",
            "Iteration 152, loss = 0.14721112\n",
            "Iteration 153, loss = 0.14637035\n",
            "Iteration 154, loss = 0.14553015\n",
            "Iteration 155, loss = 0.14450817\n",
            "Iteration 156, loss = 0.14389634\n",
            "Iteration 157, loss = 0.14283237\n",
            "Iteration 158, loss = 0.14200234\n",
            "Iteration 159, loss = 0.14139903\n",
            "Iteration 160, loss = 0.14027747\n",
            "Iteration 161, loss = 0.13966457\n",
            "Iteration 162, loss = 0.13862673\n",
            "Iteration 163, loss = 0.13795139\n",
            "Iteration 164, loss = 0.13707192\n",
            "Iteration 165, loss = 0.13656965\n",
            "Iteration 166, loss = 0.13554848\n",
            "Iteration 167, loss = 0.13474516\n",
            "Iteration 168, loss = 0.13396078\n",
            "Iteration 169, loss = 0.13309579\n",
            "Iteration 170, loss = 0.13243485\n",
            "Iteration 171, loss = 0.13174815\n",
            "Iteration 172, loss = 0.13104050\n",
            "Iteration 173, loss = 0.13036543\n",
            "Iteration 174, loss = 0.12915401\n",
            "Iteration 175, loss = 0.12924026\n",
            "Iteration 176, loss = 0.12776261\n",
            "Iteration 177, loss = 0.12709713\n",
            "Iteration 178, loss = 0.12646286\n",
            "Iteration 179, loss = 0.12546912\n",
            "Iteration 180, loss = 0.12556172\n",
            "Iteration 181, loss = 0.12388521\n",
            "Iteration 182, loss = 0.12379178\n",
            "Iteration 183, loss = 0.12251410\n",
            "Iteration 184, loss = 0.12214573\n",
            "Iteration 185, loss = 0.12117269\n",
            "Iteration 186, loss = 0.12034363\n",
            "Iteration 187, loss = 0.11989118\n",
            "Iteration 188, loss = 0.11904820\n",
            "Iteration 189, loss = 0.11861409\n",
            "Iteration 190, loss = 0.11762333\n",
            "Iteration 191, loss = 0.11705252\n",
            "Iteration 192, loss = 0.11642481\n",
            "Iteration 193, loss = 0.11559318\n",
            "Iteration 194, loss = 0.11488831\n",
            "Iteration 195, loss = 0.11422622\n",
            "Iteration 196, loss = 0.11359802\n",
            "Iteration 197, loss = 0.11308500\n",
            "Iteration 198, loss = 0.11200371\n",
            "Iteration 199, loss = 0.11180846\n",
            "Iteration 200, loss = 0.11069627\n",
            "Iteration 201, loss = 0.11032370\n",
            "Iteration 202, loss = 0.10961653\n",
            "Iteration 203, loss = 0.10889952\n",
            "Iteration 204, loss = 0.10865953\n",
            "Iteration 205, loss = 0.10755097\n",
            "Iteration 206, loss = 0.10684492\n",
            "Iteration 207, loss = 0.10638484\n",
            "Iteration 208, loss = 0.10582206\n",
            "Iteration 209, loss = 0.10498949\n",
            "Iteration 210, loss = 0.10415051\n",
            "Iteration 211, loss = 0.10365679\n",
            "Iteration 212, loss = 0.10271409\n",
            "Iteration 213, loss = 0.10241017\n",
            "Iteration 214, loss = 0.10165003\n",
            "Iteration 215, loss = 0.10091780\n",
            "Iteration 216, loss = 0.10043509\n",
            "Iteration 217, loss = 0.09977144\n",
            "Iteration 218, loss = 0.09911342\n",
            "Iteration 219, loss = 0.09870457\n",
            "Iteration 220, loss = 0.09793432\n",
            "Iteration 221, loss = 0.09784344\n",
            "Iteration 222, loss = 0.09699433\n",
            "Iteration 223, loss = 0.09639530\n",
            "Iteration 224, loss = 0.09576465\n",
            "Iteration 225, loss = 0.09518148\n",
            "Iteration 226, loss = 0.09471520\n",
            "Iteration 227, loss = 0.09402855\n",
            "Iteration 228, loss = 0.09348045\n",
            "Iteration 229, loss = 0.09270783\n",
            "Iteration 230, loss = 0.09235397\n",
            "Iteration 231, loss = 0.09271114\n",
            "Iteration 232, loss = 0.09127420\n",
            "Iteration 233, loss = 0.09070285\n",
            "Iteration 234, loss = 0.09004032\n",
            "Iteration 235, loss = 0.08940948\n",
            "Iteration 236, loss = 0.08901769\n",
            "Iteration 237, loss = 0.08826796\n",
            "Iteration 238, loss = 0.08794010\n",
            "Iteration 239, loss = 0.08726588\n",
            "Iteration 240, loss = 0.08666779\n",
            "Iteration 241, loss = 0.08615621\n",
            "Iteration 242, loss = 0.08559153\n",
            "Iteration 243, loss = 0.08508033\n",
            "Iteration 244, loss = 0.08475378\n",
            "Iteration 245, loss = 0.08424085\n",
            "Iteration 246, loss = 0.08349389\n",
            "Iteration 247, loss = 0.08311636\n",
            "Iteration 248, loss = 0.08271968\n",
            "Iteration 249, loss = 0.08209110\n",
            "Iteration 250, loss = 0.08143306\n",
            "Iteration 251, loss = 0.08130001\n",
            "Iteration 252, loss = 0.08055877\n",
            "Iteration 253, loss = 0.07989821\n",
            "Iteration 254, loss = 0.07948154\n",
            "Iteration 255, loss = 0.07906398\n",
            "Iteration 256, loss = 0.07909274\n",
            "Iteration 257, loss = 0.07850229\n",
            "Iteration 258, loss = 0.07775528\n",
            "Iteration 259, loss = 0.07714045\n",
            "Iteration 260, loss = 0.07725386\n",
            "Iteration 261, loss = 0.07620406\n",
            "Iteration 262, loss = 0.07582543\n",
            "Iteration 263, loss = 0.07513404\n",
            "Iteration 264, loss = 0.07467476\n",
            "Iteration 265, loss = 0.07449563\n",
            "Iteration 266, loss = 0.07400670\n",
            "Iteration 267, loss = 0.07344146\n",
            "Iteration 268, loss = 0.07304986\n",
            "Iteration 269, loss = 0.07255622\n",
            "Iteration 270, loss = 0.07203347\n",
            "Iteration 271, loss = 0.07145038\n",
            "Iteration 272, loss = 0.07124590\n",
            "Iteration 273, loss = 0.07066054\n",
            "Iteration 274, loss = 0.07033692\n",
            "Iteration 275, loss = 0.06976630\n",
            "Iteration 276, loss = 0.06999686\n",
            "Iteration 277, loss = 0.06856689\n",
            "Iteration 278, loss = 0.06860129\n",
            "Iteration 279, loss = 0.06805602\n",
            "Iteration 280, loss = 0.06775106\n",
            "Iteration 281, loss = 0.06707557\n",
            "Iteration 282, loss = 0.06687571\n",
            "Iteration 283, loss = 0.06617789\n",
            "Iteration 284, loss = 0.06600983\n",
            "Iteration 285, loss = 0.06541564\n",
            "Iteration 286, loss = 0.06540998\n",
            "Iteration 287, loss = 0.06474828\n",
            "Iteration 288, loss = 0.06421015\n",
            "Iteration 289, loss = 0.06384197\n",
            "Iteration 290, loss = 0.06337459\n",
            "Iteration 291, loss = 0.06304608\n",
            "Iteration 292, loss = 0.06270304\n",
            "Iteration 293, loss = 0.06227564\n",
            "Iteration 294, loss = 0.06202373\n",
            "Iteration 295, loss = 0.06156734\n",
            "Iteration 296, loss = 0.06108497\n",
            "Iteration 297, loss = 0.06058341\n",
            "Iteration 298, loss = 0.06041160\n",
            "Iteration 299, loss = 0.06021317\n",
            "Iteration 300, loss = 0.06047045\n",
            "Iteration 301, loss = 0.05905547\n",
            "Iteration 302, loss = 0.05909916\n",
            "Iteration 303, loss = 0.05828043\n",
            "Iteration 304, loss = 0.05817314\n",
            "Iteration 305, loss = 0.05762719\n",
            "Iteration 306, loss = 0.05715622\n",
            "Iteration 307, loss = 0.05705687\n",
            "Iteration 308, loss = 0.05661037\n",
            "Iteration 309, loss = 0.05637809\n",
            "Iteration 310, loss = 0.05589335\n",
            "Iteration 311, loss = 0.05554779\n",
            "Iteration 312, loss = 0.05510051\n",
            "Iteration 313, loss = 0.05559126\n",
            "Iteration 314, loss = 0.05480625\n",
            "Iteration 315, loss = 0.05426471\n",
            "Iteration 316, loss = 0.05382030\n",
            "Iteration 317, loss = 0.05351936\n",
            "Iteration 318, loss = 0.05301481\n",
            "Iteration 319, loss = 0.05272941\n",
            "Iteration 320, loss = 0.05270093\n",
            "Iteration 321, loss = 0.05228698\n",
            "Iteration 322, loss = 0.05163283\n",
            "Iteration 323, loss = 0.05148005\n",
            "Iteration 324, loss = 0.05107793\n",
            "Iteration 325, loss = 0.05085829\n",
            "Iteration 326, loss = 0.05082162\n",
            "Iteration 327, loss = 0.05010844\n",
            "Iteration 328, loss = 0.04966230\n",
            "Iteration 329, loss = 0.04945028\n",
            "Iteration 330, loss = 0.04922404\n",
            "Iteration 331, loss = 0.04907616\n",
            "Iteration 332, loss = 0.04885491\n",
            "Iteration 333, loss = 0.04817602\n",
            "Iteration 334, loss = 0.04778350\n",
            "Iteration 335, loss = 0.04765909\n",
            "Iteration 336, loss = 0.04750655\n",
            "Iteration 337, loss = 0.04701759\n",
            "Iteration 338, loss = 0.04662585\n",
            "Iteration 339, loss = 0.04639871\n",
            "Iteration 340, loss = 0.04616013\n",
            "Iteration 341, loss = 0.04581672\n",
            "Iteration 342, loss = 0.04552690\n",
            "Iteration 343, loss = 0.04520894\n",
            "Iteration 344, loss = 0.04502613\n",
            "Iteration 345, loss = 0.04469576\n",
            "Iteration 346, loss = 0.04451583\n",
            "Iteration 347, loss = 0.04414684\n",
            "Iteration 348, loss = 0.04383999\n",
            "Iteration 349, loss = 0.04361883\n",
            "Iteration 350, loss = 0.04330926\n",
            "Iteration 351, loss = 0.04325345\n",
            "Iteration 352, loss = 0.04291786\n",
            "Iteration 353, loss = 0.04246216\n",
            "Iteration 354, loss = 0.04226673\n",
            "Iteration 355, loss = 0.04193395\n",
            "Iteration 356, loss = 0.04180879\n",
            "Iteration 357, loss = 0.04174413\n",
            "Iteration 358, loss = 0.04139167\n",
            "Iteration 359, loss = 0.04090363\n",
            "Iteration 360, loss = 0.04067357\n",
            "Iteration 361, loss = 0.04038498\n",
            "Iteration 362, loss = 0.04024321\n",
            "Iteration 363, loss = 0.03981253\n",
            "Iteration 364, loss = 0.03972533\n",
            "Iteration 365, loss = 0.03939799\n",
            "Iteration 366, loss = 0.03927183\n",
            "Iteration 367, loss = 0.03883754\n",
            "Iteration 368, loss = 0.03884700\n",
            "Iteration 369, loss = 0.03843731\n",
            "Iteration 370, loss = 0.03818662\n",
            "Iteration 371, loss = 0.03790440\n",
            "Iteration 372, loss = 0.03779716\n",
            "Iteration 373, loss = 0.03739838\n",
            "Iteration 374, loss = 0.03716963\n",
            "Iteration 375, loss = 0.03701315\n",
            "Iteration 376, loss = 0.03680417\n",
            "Iteration 377, loss = 0.03654491\n",
            "Iteration 378, loss = 0.03637767\n",
            "Iteration 379, loss = 0.03603223\n",
            "Iteration 380, loss = 0.03584651\n",
            "Iteration 381, loss = 0.03575604\n",
            "Iteration 382, loss = 0.03538662\n",
            "Iteration 383, loss = 0.03518834\n",
            "Iteration 384, loss = 0.03498873\n",
            "Iteration 385, loss = 0.03482125\n",
            "Iteration 386, loss = 0.03464285\n",
            "Iteration 387, loss = 0.03426229\n",
            "Iteration 388, loss = 0.03409396\n",
            "Iteration 389, loss = 0.03399854\n",
            "Iteration 390, loss = 0.03366388\n",
            "Iteration 391, loss = 0.03348021\n",
            "Iteration 392, loss = 0.03322340\n",
            "Iteration 393, loss = 0.03301740\n",
            "Iteration 394, loss = 0.03293858\n",
            "Iteration 395, loss = 0.03257900\n",
            "Iteration 396, loss = 0.03244847\n",
            "Iteration 397, loss = 0.03231494\n",
            "Iteration 398, loss = 0.03208660\n",
            "Iteration 399, loss = 0.03201761\n",
            "Iteration 400, loss = 0.03179970\n",
            "Iteration 401, loss = 0.03154109\n",
            "Iteration 402, loss = 0.03141085\n",
            "Iteration 403, loss = 0.03116761\n",
            "Iteration 404, loss = 0.03095208\n",
            "Iteration 405, loss = 0.03099020\n",
            "Iteration 406, loss = 0.03092049\n",
            "Iteration 407, loss = 0.03059688\n",
            "Iteration 408, loss = 0.03018186\n",
            "Iteration 409, loss = 0.02995507\n",
            "Iteration 410, loss = 0.03001537\n",
            "Iteration 411, loss = 0.02958639\n",
            "Iteration 412, loss = 0.02945908\n",
            "Iteration 413, loss = 0.02917919\n",
            "Iteration 414, loss = 0.02907323\n",
            "Iteration 415, loss = 0.02885996\n",
            "Iteration 416, loss = 0.02864263\n",
            "Iteration 417, loss = 0.02852164\n",
            "Iteration 418, loss = 0.02829825\n",
            "Iteration 419, loss = 0.02818861\n",
            "Iteration 420, loss = 0.02797212\n",
            "Iteration 421, loss = 0.02783724\n",
            "Iteration 422, loss = 0.02766620\n",
            "Iteration 423, loss = 0.02782851\n",
            "Iteration 424, loss = 0.02751531\n",
            "Iteration 425, loss = 0.02706876\n",
            "Iteration 426, loss = 0.02701173\n",
            "Iteration 427, loss = 0.02681927\n",
            "Iteration 428, loss = 0.02674175\n",
            "Iteration 429, loss = 0.02646900\n",
            "Iteration 430, loss = 0.02626391\n",
            "Iteration 431, loss = 0.02614796\n",
            "Iteration 432, loss = 0.02600088\n",
            "Iteration 433, loss = 0.02585313\n",
            "Iteration 434, loss = 0.02567990\n",
            "Iteration 435, loss = 0.02554417\n",
            "Iteration 436, loss = 0.02542393\n",
            "Iteration 437, loss = 0.02527614\n",
            "Iteration 438, loss = 0.02506399\n",
            "Iteration 439, loss = 0.02494562\n",
            "Iteration 440, loss = 0.02470047\n",
            "Iteration 441, loss = 0.02462639\n",
            "Iteration 442, loss = 0.02453079\n",
            "Iteration 443, loss = 0.02442444\n",
            "Iteration 444, loss = 0.02406759\n",
            "Iteration 445, loss = 0.02406873\n",
            "Iteration 446, loss = 0.02397983\n",
            "Iteration 447, loss = 0.02390435\n",
            "Iteration 448, loss = 0.02362783\n",
            "Iteration 449, loss = 0.02344664\n",
            "Iteration 450, loss = 0.02333047\n",
            "Iteration 451, loss = 0.02314371\n",
            "Iteration 452, loss = 0.02305456\n",
            "Iteration 453, loss = 0.02283231\n",
            "Iteration 454, loss = 0.02274251\n",
            "Iteration 455, loss = 0.02255296\n",
            "Iteration 456, loss = 0.02248173\n",
            "Iteration 457, loss = 0.02236926\n",
            "Iteration 458, loss = 0.02214287\n",
            "Iteration 459, loss = 0.02203599\n",
            "Iteration 460, loss = 0.02188273\n",
            "Iteration 461, loss = 0.02177197\n",
            "Iteration 462, loss = 0.02168591\n",
            "Iteration 463, loss = 0.02146257\n",
            "Iteration 464, loss = 0.02144006\n",
            "Iteration 465, loss = 0.02123728\n",
            "Iteration 466, loss = 0.02115517\n",
            "Iteration 467, loss = 0.02106181\n",
            "Iteration 468, loss = 0.02084019\n",
            "Iteration 469, loss = 0.02073037\n",
            "Iteration 470, loss = 0.02067458\n",
            "Iteration 471, loss = 0.02049880\n",
            "Iteration 472, loss = 0.02060141\n",
            "Iteration 473, loss = 0.02044795\n",
            "Iteration 474, loss = 0.02028903\n",
            "Iteration 475, loss = 0.02015612\n",
            "Iteration 476, loss = 0.01999322\n",
            "Iteration 477, loss = 0.01978599\n",
            "Iteration 478, loss = 0.01965347\n",
            "Iteration 479, loss = 0.01959763\n",
            "Iteration 480, loss = 0.01940891\n",
            "Iteration 481, loss = 0.01933088\n",
            "Iteration 482, loss = 0.01918816\n",
            "Iteration 483, loss = 0.01910642\n",
            "Iteration 484, loss = 0.01900502\n",
            "Iteration 485, loss = 0.01890808\n",
            "Iteration 486, loss = 0.01880140\n",
            "Iteration 487, loss = 0.01867828\n",
            "Iteration 488, loss = 0.01848296\n",
            "Iteration 489, loss = 0.01840300\n",
            "Iteration 490, loss = 0.01829033\n",
            "Iteration 491, loss = 0.01813965\n",
            "Iteration 492, loss = 0.01813331\n",
            "Iteration 493, loss = 0.01794790\n",
            "Iteration 494, loss = 0.01794918\n",
            "Iteration 495, loss = 0.01782728\n",
            "Iteration 496, loss = 0.01780210\n",
            "Iteration 497, loss = 0.01753784\n",
            "Iteration 498, loss = 0.01749727\n",
            "Iteration 499, loss = 0.01741302\n",
            "Iteration 500, loss = 0.01726587\n",
            "Iteration 501, loss = 0.01717236\n",
            "Iteration 502, loss = 0.01705408\n",
            "Iteration 503, loss = 0.01695426\n",
            "Iteration 504, loss = 0.01680669\n",
            "Iteration 505, loss = 0.01680072\n",
            "Iteration 506, loss = 0.01669392\n",
            "Iteration 507, loss = 0.01656223\n",
            "Iteration 508, loss = 0.01644476\n",
            "Iteration 509, loss = 0.01633916\n",
            "Iteration 510, loss = 0.01624380\n",
            "Iteration 511, loss = 0.01615883\n",
            "Iteration 512, loss = 0.01606864\n",
            "Iteration 513, loss = 0.01598366\n",
            "Iteration 514, loss = 0.01593135\n",
            "Iteration 515, loss = 0.01584670\n",
            "Iteration 516, loss = 0.01565747\n",
            "Iteration 517, loss = 0.01561494\n",
            "Iteration 518, loss = 0.01553862\n",
            "Iteration 519, loss = 0.01560375\n",
            "Iteration 520, loss = 0.01540952\n",
            "Iteration 521, loss = 0.01536916\n",
            "Iteration 522, loss = 0.01516760\n",
            "Iteration 523, loss = 0.01509800\n",
            "Iteration 524, loss = 0.01505374\n",
            "Iteration 525, loss = 0.01508692\n",
            "Iteration 526, loss = 0.01484997\n",
            "Iteration 527, loss = 0.01477654\n",
            "Iteration 528, loss = 0.01462559\n",
            "Iteration 529, loss = 0.01455131\n",
            "Iteration 530, loss = 0.01449328\n",
            "Iteration 531, loss = 0.01439143\n",
            "Iteration 532, loss = 0.01430390\n",
            "Iteration 533, loss = 0.01419828\n",
            "Iteration 534, loss = 0.01412449\n",
            "Iteration 535, loss = 0.01403454\n",
            "Iteration 536, loss = 0.01394745\n",
            "Iteration 537, loss = 0.01389748\n",
            "Iteration 538, loss = 0.01382560\n",
            "Iteration 539, loss = 0.01378473\n",
            "Iteration 540, loss = 0.01365192\n",
            "Iteration 541, loss = 0.01358600\n",
            "Iteration 542, loss = 0.01352509\n",
            "Iteration 543, loss = 0.01344025\n",
            "Iteration 544, loss = 0.01339073\n",
            "Iteration 545, loss = 0.01329520\n",
            "Iteration 546, loss = 0.01323338\n",
            "Iteration 547, loss = 0.01314506\n",
            "Iteration 548, loss = 0.01304596\n",
            "Iteration 549, loss = 0.01298568\n",
            "Iteration 550, loss = 0.01293652\n",
            "Iteration 551, loss = 0.01283320\n",
            "Iteration 552, loss = 0.01275694\n",
            "Iteration 553, loss = 0.01265048\n",
            "Iteration 554, loss = 0.01261847\n",
            "Iteration 555, loss = 0.01258091\n",
            "Iteration 556, loss = 0.01251826\n",
            "Iteration 557, loss = 0.01241846\n",
            "Iteration 558, loss = 0.01243911\n",
            "Iteration 559, loss = 0.01227556\n",
            "Iteration 560, loss = 0.01226333\n",
            "Iteration 561, loss = 0.01212714\n",
            "Iteration 562, loss = 0.01202994\n",
            "Iteration 563, loss = 0.01198474\n",
            "Iteration 564, loss = 0.01192520\n",
            "Iteration 565, loss = 0.01184261\n",
            "Iteration 566, loss = 0.01180379\n",
            "Iteration 567, loss = 0.01176276\n",
            "Iteration 568, loss = 0.01163433\n",
            "Iteration 569, loss = 0.01171863\n",
            "Iteration 570, loss = 0.01161334\n",
            "Iteration 571, loss = 0.01153704\n",
            "Iteration 572, loss = 0.01145135\n",
            "Iteration 573, loss = 0.01134552\n",
            "Iteration 574, loss = 0.01127292\n",
            "Iteration 575, loss = 0.01125388\n",
            "Iteration 576, loss = 0.01116802\n",
            "Iteration 577, loss = 0.01112463\n",
            "Iteration 578, loss = 0.01103939\n",
            "Iteration 579, loss = 0.01094260\n",
            "Iteration 580, loss = 0.01094319\n",
            "Iteration 581, loss = 0.01090689\n",
            "Iteration 582, loss = 0.01075547\n",
            "Iteration 583, loss = 0.01077368\n",
            "Iteration 584, loss = 0.01065725\n",
            "Iteration 585, loss = 0.01065181\n",
            "Iteration 586, loss = 0.01054626\n",
            "Iteration 587, loss = 0.01047942\n",
            "Iteration 588, loss = 0.01044244\n",
            "Iteration 589, loss = 0.01037979\n",
            "Iteration 590, loss = 0.01032220\n",
            "Iteration 591, loss = 0.01031900\n",
            "Iteration 592, loss = 0.01025791\n",
            "Iteration 593, loss = 0.01018682\n",
            "Iteration 594, loss = 0.01015348\n",
            "Iteration 595, loss = 0.01011551\n",
            "Iteration 596, loss = 0.00998622\n",
            "Iteration 597, loss = 0.00998035\n",
            "Iteration 598, loss = 0.00989645\n",
            "Iteration 599, loss = 0.00982790\n",
            "Iteration 600, loss = 0.00975979\n",
            "Iteration 601, loss = 0.00972883\n",
            "Iteration 602, loss = 0.00965956\n",
            "Iteration 603, loss = 0.00963545\n",
            "Iteration 604, loss = 0.00956062\n",
            "Iteration 605, loss = 0.00952305\n",
            "Iteration 606, loss = 0.00945303\n",
            "Iteration 607, loss = 0.00944305\n",
            "Iteration 608, loss = 0.00934658\n",
            "Iteration 609, loss = 0.00933504\n",
            "Iteration 610, loss = 0.00928714\n",
            "Iteration 611, loss = 0.00920105\n",
            "Iteration 612, loss = 0.00915565\n",
            "Iteration 613, loss = 0.00912651\n",
            "Iteration 614, loss = 0.00905363\n",
            "Iteration 615, loss = 0.00899487\n",
            "Iteration 616, loss = 0.00900773\n",
            "Iteration 617, loss = 0.00892069\n",
            "Iteration 618, loss = 0.00887059\n",
            "Iteration 619, loss = 0.00882754\n",
            "Iteration 620, loss = 0.00881679\n",
            "Iteration 621, loss = 0.00870655\n",
            "Iteration 622, loss = 0.00869752\n",
            "Iteration 623, loss = 0.00866965\n",
            "Iteration 624, loss = 0.00859997\n",
            "Iteration 625, loss = 0.00856487\n",
            "Iteration 626, loss = 0.00852765\n",
            "Iteration 627, loss = 0.00848376\n",
            "Iteration 628, loss = 0.00842403\n",
            "Iteration 629, loss = 0.00838269\n",
            "Iteration 630, loss = 0.00835580\n",
            "Iteration 631, loss = 0.00825910\n",
            "Iteration 632, loss = 0.00824643\n",
            "Iteration 633, loss = 0.00820644\n",
            "Iteration 634, loss = 0.00817327\n",
            "Iteration 635, loss = 0.00812118\n",
            "Iteration 636, loss = 0.00806791\n",
            "Iteration 637, loss = 0.00803431\n",
            "Iteration 638, loss = 0.00804015\n",
            "Iteration 639, loss = 0.00794910\n",
            "Iteration 640, loss = 0.00793151\n",
            "Iteration 641, loss = 0.00787016\n",
            "Iteration 642, loss = 0.00782060\n",
            "Iteration 643, loss = 0.00778322\n",
            "Iteration 644, loss = 0.00775384\n",
            "Iteration 645, loss = 0.00771923\n",
            "Iteration 646, loss = 0.00770010\n",
            "Iteration 647, loss = 0.00765900\n",
            "Iteration 648, loss = 0.00761689\n",
            "Iteration 649, loss = 0.00754995\n",
            "Iteration 650, loss = 0.00751918\n",
            "Iteration 651, loss = 0.00748489\n",
            "Iteration 652, loss = 0.00742730\n",
            "Iteration 653, loss = 0.00738859\n",
            "Iteration 654, loss = 0.00733489\n",
            "Iteration 655, loss = 0.00731032\n",
            "Iteration 656, loss = 0.00726640\n",
            "Iteration 657, loss = 0.00723782\n",
            "Iteration 658, loss = 0.00719749\n",
            "Iteration 659, loss = 0.00719575\n",
            "Iteration 660, loss = 0.00715828\n",
            "Iteration 661, loss = 0.00708784\n",
            "Iteration 662, loss = 0.00706485\n",
            "Iteration 663, loss = 0.00700050\n",
            "Iteration 664, loss = 0.00698728\n",
            "Iteration 665, loss = 0.00695673\n",
            "Iteration 666, loss = 0.00691640\n",
            "Iteration 667, loss = 0.00686888\n",
            "Iteration 668, loss = 0.00684119\n",
            "Iteration 669, loss = 0.00681957\n",
            "Iteration 670, loss = 0.00676631\n",
            "Iteration 671, loss = 0.00675592\n",
            "Iteration 672, loss = 0.00671473\n",
            "Iteration 673, loss = 0.00666502\n",
            "Iteration 674, loss = 0.00664348\n",
            "Iteration 675, loss = 0.00662095\n",
            "Iteration 676, loss = 0.00661483\n",
            "Iteration 677, loss = 0.00656169\n",
            "Iteration 678, loss = 0.00654460\n",
            "Iteration 679, loss = 0.00648895\n",
            "Iteration 680, loss = 0.00646072\n",
            "Iteration 681, loss = 0.00640398\n",
            "Iteration 682, loss = 0.00637019\n",
            "Iteration 683, loss = 0.00634335\n",
            "Iteration 684, loss = 0.00634052\n",
            "Iteration 685, loss = 0.00627260\n",
            "Iteration 686, loss = 0.00628587\n",
            "Iteration 687, loss = 0.00627670\n",
            "Iteration 688, loss = 0.00619740\n",
            "Iteration 689, loss = 0.00616528\n",
            "Iteration 690, loss = 0.00615847\n",
            "Iteration 691, loss = 0.00611535\n",
            "Iteration 692, loss = 0.00606250\n",
            "Iteration 693, loss = 0.00606403\n",
            "Iteration 694, loss = 0.00603031\n",
            "Iteration 695, loss = 0.00598802\n",
            "Iteration 696, loss = 0.00594768\n",
            "Iteration 697, loss = 0.00593739\n",
            "Iteration 698, loss = 0.00592151\n",
            "Iteration 699, loss = 0.00586869\n",
            "Iteration 700, loss = 0.00585524\n",
            "Iteration 701, loss = 0.00587798\n",
            "Iteration 702, loss = 0.00581563\n",
            "Iteration 703, loss = 0.00576295\n",
            "Iteration 704, loss = 0.00570897\n",
            "Iteration 705, loss = 0.00569861\n",
            "Iteration 706, loss = 0.00568754\n",
            "Iteration 707, loss = 0.00567688\n",
            "Iteration 708, loss = 0.00562206\n",
            "Iteration 709, loss = 0.00560705\n",
            "Iteration 710, loss = 0.00558607\n",
            "Iteration 711, loss = 0.00552980\n",
            "Iteration 712, loss = 0.00549800\n",
            "Iteration 713, loss = 0.00547885\n",
            "Iteration 714, loss = 0.00546935\n",
            "Iteration 715, loss = 0.00543185\n",
            "Iteration 716, loss = 0.00538479\n",
            "Iteration 717, loss = 0.00536922\n",
            "Iteration 718, loss = 0.00534147\n",
            "Iteration 719, loss = 0.00531871\n",
            "Iteration 720, loss = 0.00529702\n",
            "Iteration 721, loss = 0.00525628\n",
            "Iteration 722, loss = 0.00524941\n",
            "Iteration 723, loss = 0.00520040\n",
            "Iteration 724, loss = 0.00521100\n",
            "Iteration 725, loss = 0.00520825\n",
            "Iteration 726, loss = 0.00515033\n",
            "Iteration 727, loss = 0.00514055\n",
            "Iteration 728, loss = 0.00508037\n",
            "Iteration 729, loss = 0.00507420\n",
            "Iteration 730, loss = 0.00504045\n",
            "Iteration 731, loss = 0.00502293\n",
            "Iteration 732, loss = 0.00499959\n",
            "Iteration 733, loss = 0.00498123\n",
            "Iteration 734, loss = 0.00494779\n",
            "Iteration 735, loss = 0.00492761\n",
            "Iteration 736, loss = 0.00493251\n",
            "Iteration 737, loss = 0.00488590\n",
            "Iteration 738, loss = 0.00487607\n",
            "Iteration 739, loss = 0.00484538\n",
            "Iteration 740, loss = 0.00483237\n",
            "Iteration 741, loss = 0.00480027\n",
            "Iteration 742, loss = 0.00475750\n",
            "Iteration 743, loss = 0.00474286\n",
            "Iteration 744, loss = 0.00473188\n",
            "Iteration 745, loss = 0.00470369\n",
            "Iteration 746, loss = 0.00467644\n",
            "Iteration 747, loss = 0.00465983\n",
            "Iteration 748, loss = 0.00463862\n",
            "Iteration 749, loss = 0.00463806\n",
            "Iteration 750, loss = 0.00458660\n",
            "Iteration 751, loss = 0.00458509\n",
            "Iteration 752, loss = 0.00453994\n",
            "Iteration 753, loss = 0.00453154\n",
            "Iteration 754, loss = 0.00451074\n",
            "Iteration 755, loss = 0.00450989\n",
            "Iteration 756, loss = 0.00448330\n",
            "Iteration 757, loss = 0.00443964\n",
            "Iteration 758, loss = 0.00441731\n",
            "Iteration 759, loss = 0.00439436\n",
            "Iteration 760, loss = 0.00437362\n",
            "Iteration 761, loss = 0.00435481\n",
            "Iteration 762, loss = 0.00432890\n",
            "Iteration 763, loss = 0.00431677\n",
            "Iteration 764, loss = 0.00429716\n",
            "Iteration 765, loss = 0.00427095\n",
            "Iteration 766, loss = 0.00425067\n",
            "Iteration 767, loss = 0.00423170\n",
            "Iteration 768, loss = 0.00421535\n",
            "Iteration 769, loss = 0.00419000\n",
            "Iteration 770, loss = 0.00417415\n",
            "Iteration 771, loss = 0.00416511\n",
            "Iteration 772, loss = 0.00417319\n",
            "Iteration 773, loss = 0.00414454\n",
            "Iteration 774, loss = 0.00409339\n",
            "Iteration 775, loss = 0.00409375\n",
            "Iteration 776, loss = 0.00405946\n",
            "Iteration 777, loss = 0.00403447\n",
            "Iteration 778, loss = 0.00401766\n",
            "Iteration 779, loss = 0.00400273\n",
            "Iteration 780, loss = 0.00398289\n",
            "Iteration 781, loss = 0.00396889\n",
            "Iteration 782, loss = 0.00394937\n",
            "Iteration 783, loss = 0.00392523\n",
            "Iteration 784, loss = 0.00390549\n",
            "Iteration 785, loss = 0.00388903\n",
            "Iteration 786, loss = 0.00387195\n",
            "Iteration 787, loss = 0.00385245\n",
            "Iteration 788, loss = 0.00383376\n",
            "Iteration 789, loss = 0.00382376\n",
            "Iteration 790, loss = 0.00380056\n",
            "Iteration 791, loss = 0.00378858\n",
            "Iteration 792, loss = 0.00376913\n",
            "Iteration 793, loss = 0.00374094\n",
            "Iteration 794, loss = 0.00372522\n",
            "Iteration 795, loss = 0.00370975\n",
            "Iteration 796, loss = 0.00369672\n",
            "Iteration 797, loss = 0.00368770\n",
            "Iteration 798, loss = 0.00365833\n",
            "Iteration 799, loss = 0.00364072\n",
            "Iteration 800, loss = 0.00362572\n",
            "Iteration 801, loss = 0.00360902\n",
            "Iteration 802, loss = 0.00358750\n",
            "Iteration 803, loss = 0.00358814\n",
            "Iteration 804, loss = 0.00356764\n",
            "Iteration 805, loss = 0.00354085\n",
            "Iteration 806, loss = 0.00354701\n",
            "Iteration 807, loss = 0.00350914\n",
            "Iteration 808, loss = 0.00350165\n",
            "Iteration 809, loss = 0.00349007\n",
            "Iteration 810, loss = 0.00346935\n",
            "Iteration 811, loss = 0.00345264\n",
            "Iteration 812, loss = 0.00343378\n",
            "Iteration 813, loss = 0.00343120\n",
            "Iteration 814, loss = 0.00340504\n",
            "Iteration 815, loss = 0.00338678\n",
            "Iteration 816, loss = 0.00337009\n",
            "Iteration 817, loss = 0.00335619\n",
            "Iteration 818, loss = 0.00334127\n",
            "Iteration 819, loss = 0.00332759\n",
            "Iteration 820, loss = 0.00331447\n",
            "Iteration 821, loss = 0.00330185\n",
            "Iteration 822, loss = 0.00330447\n",
            "Iteration 823, loss = 0.00327548\n",
            "Iteration 824, loss = 0.00325695\n",
            "Iteration 825, loss = 0.00324225\n",
            "Iteration 826, loss = 0.00322995\n",
            "Iteration 827, loss = 0.00320931\n",
            "Iteration 828, loss = 0.00319152\n",
            "Iteration 829, loss = 0.00318108\n",
            "Iteration 830, loss = 0.00317500\n",
            "Iteration 831, loss = 0.00315572\n",
            "Iteration 832, loss = 0.00314071\n",
            "Iteration 833, loss = 0.00312616\n",
            "Iteration 834, loss = 0.00312457\n",
            "Iteration 835, loss = 0.00310110\n",
            "Iteration 836, loss = 0.00308813\n",
            "Iteration 837, loss = 0.00308163\n",
            "Iteration 838, loss = 0.00308618\n",
            "Iteration 839, loss = 0.00305078\n",
            "Iteration 840, loss = 0.00305358\n",
            "Iteration 841, loss = 0.00301678\n",
            "Iteration 842, loss = 0.00301491\n",
            "Iteration 843, loss = 0.00298982\n",
            "Iteration 844, loss = 0.00302872\n",
            "Iteration 845, loss = 0.00296988\n",
            "Iteration 846, loss = 0.00296471\n",
            "Iteration 847, loss = 0.00294197\n",
            "Iteration 848, loss = 0.00291991\n",
            "Iteration 849, loss = 0.00290707\n",
            "Iteration 850, loss = 0.00290425\n",
            "Iteration 851, loss = 0.00288229\n",
            "Iteration 852, loss = 0.00288045\n",
            "Iteration 853, loss = 0.00286129\n",
            "Iteration 854, loss = 0.00284239\n",
            "Iteration 855, loss = 0.00284721\n",
            "Iteration 856, loss = 0.00283068\n",
            "Iteration 857, loss = 0.00281901\n",
            "Iteration 858, loss = 0.00279970\n",
            "Iteration 859, loss = 0.00279928\n",
            "Iteration 860, loss = 0.00277807\n",
            "Iteration 861, loss = 0.00276234\n",
            "Iteration 862, loss = 0.00276676\n",
            "Iteration 863, loss = 0.00273777\n",
            "Iteration 864, loss = 0.00272961\n",
            "Iteration 865, loss = 0.00270914\n",
            "Iteration 866, loss = 0.00271116\n",
            "Iteration 867, loss = 0.00269321\n",
            "Iteration 868, loss = 0.00267281\n",
            "Iteration 869, loss = 0.00266976\n",
            "Iteration 870, loss = 0.00265547\n",
            "Iteration 871, loss = 0.00264181\n",
            "Iteration 872, loss = 0.00263339\n",
            "Iteration 873, loss = 0.00261647\n",
            "Iteration 874, loss = 0.00260683\n",
            "Iteration 875, loss = 0.00259992\n",
            "Iteration 876, loss = 0.00258809\n",
            "Iteration 877, loss = 0.00257548\n",
            "Iteration 878, loss = 0.00256726\n",
            "Iteration 879, loss = 0.00255510\n",
            "Iteration 880, loss = 0.00254820\n",
            "Iteration 881, loss = 0.00253561\n",
            "Iteration 882, loss = 0.00251537\n",
            "Iteration 883, loss = 0.00250992\n",
            "Iteration 884, loss = 0.00249547\n",
            "Iteration 885, loss = 0.00248333\n",
            "Iteration 886, loss = 0.00247299\n",
            "Iteration 887, loss = 0.00247336\n",
            "Iteration 888, loss = 0.00245087\n",
            "Iteration 889, loss = 0.00244625\n",
            "Iteration 890, loss = 0.00243045\n",
            "Iteration 891, loss = 0.00242337\n",
            "Iteration 892, loss = 0.00241322\n",
            "Iteration 893, loss = 0.00240692\n",
            "Iteration 894, loss = 0.00239528\n",
            "Iteration 895, loss = 0.00238863\n",
            "Iteration 896, loss = 0.00237877\n",
            "Iteration 897, loss = 0.00236294\n",
            "Iteration 898, loss = 0.00235556\n",
            "Iteration 899, loss = 0.00234651\n",
            "Iteration 900, loss = 0.00233601\n",
            "Iteration 901, loss = 0.00232148\n",
            "Iteration 902, loss = 0.00232163\n",
            "Iteration 903, loss = 0.00230546\n",
            "Iteration 904, loss = 0.00229449\n",
            "Iteration 905, loss = 0.00228077\n",
            "Iteration 906, loss = 0.00227459\n",
            "Iteration 907, loss = 0.00227191\n",
            "Iteration 908, loss = 0.00225326\n",
            "Iteration 909, loss = 0.00224527\n",
            "Iteration 910, loss = 0.00223741\n",
            "Iteration 911, loss = 0.00222380\n",
            "Iteration 912, loss = 0.00221899\n",
            "Iteration 913, loss = 0.00223861\n",
            "Iteration 914, loss = 0.00221037\n",
            "Iteration 915, loss = 0.00219684\n",
            "Iteration 916, loss = 0.00218665\n",
            "Iteration 917, loss = 0.00218145\n",
            "Iteration 918, loss = 0.00216253\n",
            "Iteration 919, loss = 0.00215691\n",
            "Iteration 920, loss = 0.00214006\n",
            "Iteration 921, loss = 0.00214003\n",
            "Iteration 922, loss = 0.00213605\n",
            "Iteration 923, loss = 0.00211181\n",
            "Iteration 924, loss = 0.00211520\n",
            "Iteration 925, loss = 0.00209945\n",
            "Iteration 926, loss = 0.00208900\n",
            "Iteration 927, loss = 0.00208696\n",
            "Iteration 928, loss = 0.00206904\n",
            "Iteration 929, loss = 0.00206694\n",
            "Iteration 930, loss = 0.00204742\n",
            "Iteration 931, loss = 0.00204936\n",
            "Iteration 932, loss = 0.00203420\n",
            "Iteration 933, loss = 0.00203223\n",
            "Iteration 934, loss = 0.00202195\n",
            "Iteration 935, loss = 0.00200884\n",
            "Iteration 936, loss = 0.00200276\n",
            "Iteration 937, loss = 0.00199640\n",
            "Iteration 938, loss = 0.00199276\n",
            "Iteration 939, loss = 0.00198519\n",
            "Iteration 940, loss = 0.00197502\n",
            "Iteration 941, loss = 0.00197035\n",
            "Iteration 942, loss = 0.00195033\n",
            "Iteration 943, loss = 0.00195182\n",
            "Iteration 944, loss = 0.00193929\n",
            "Iteration 945, loss = 0.00193386\n",
            "Iteration 946, loss = 0.00192115\n",
            "Iteration 947, loss = 0.00191233\n",
            "Iteration 948, loss = 0.00190684\n",
            "Iteration 949, loss = 0.00189773\n",
            "Iteration 950, loss = 0.00189474\n",
            "Iteration 951, loss = 0.00188946\n",
            "Iteration 952, loss = 0.00187573\n",
            "Iteration 953, loss = 0.00186869\n",
            "Iteration 954, loss = 0.00185942\n",
            "Iteration 955, loss = 0.00185436\n",
            "Iteration 956, loss = 0.00184895\n",
            "Iteration 957, loss = 0.00184455\n",
            "Iteration 958, loss = 0.00183012\n",
            "Iteration 959, loss = 0.00182233\n",
            "Iteration 960, loss = 0.00181941\n",
            "Iteration 961, loss = 0.00181155\n",
            "Iteration 962, loss = 0.00180375\n",
            "Iteration 963, loss = 0.00179306\n",
            "Iteration 964, loss = 0.00178590\n",
            "Iteration 965, loss = 0.00177636\n",
            "Iteration 966, loss = 0.00177262\n",
            "Iteration 967, loss = 0.00176440\n",
            "Iteration 968, loss = 0.00175470\n",
            "Iteration 969, loss = 0.00175200\n",
            "Iteration 970, loss = 0.00173947\n",
            "Iteration 971, loss = 0.00173607\n",
            "Iteration 972, loss = 0.00172778\n",
            "Iteration 973, loss = 0.00172103\n",
            "Iteration 974, loss = 0.00172275\n",
            "Iteration 975, loss = 0.00171192\n",
            "Iteration 976, loss = 0.00170455\n",
            "Iteration 977, loss = 0.00169875\n",
            "Iteration 978, loss = 0.00168706\n",
            "Iteration 979, loss = 0.00169498\n",
            "Iteration 980, loss = 0.00167558\n",
            "Iteration 981, loss = 0.00167201\n",
            "Iteration 982, loss = 0.00166188\n",
            "Iteration 983, loss = 0.00165416\n",
            "Iteration 984, loss = 0.00164491\n",
            "Iteration 985, loss = 0.00164372\n",
            "Iteration 986, loss = 0.00163258\n",
            "Iteration 987, loss = 0.00162771\n",
            "Iteration 988, loss = 0.00161750\n",
            "Iteration 989, loss = 0.00161617\n",
            "Iteration 990, loss = 0.00160562\n",
            "Iteration 991, loss = 0.00160252\n",
            "Iteration 992, loss = 0.00159150\n",
            "Iteration 993, loss = 0.00158971\n",
            "Iteration 994, loss = 0.00158055\n",
            "Iteration 995, loss = 0.00159114\n",
            "Iteration 996, loss = 0.00157674\n",
            "Iteration 997, loss = 0.00156861\n",
            "Iteration 998, loss = 0.00155566\n",
            "Iteration 999, loss = 0.00155503\n",
            "Iteration 1000, loss = 0.00154679\n",
            "Iteration 1001, loss = 0.00153668\n",
            "Iteration 1002, loss = 0.00153214\n",
            "Iteration 1003, loss = 0.00152479\n",
            "Iteration 1004, loss = 0.00152258\n",
            "Iteration 1005, loss = 0.00151272\n",
            "Iteration 1006, loss = 0.00150967\n",
            "Iteration 1007, loss = 0.00150582\n",
            "Iteration 1008, loss = 0.00150141\n",
            "Iteration 1009, loss = 0.00149683\n",
            "Iteration 1010, loss = 0.00148385\n",
            "Iteration 1011, loss = 0.00147836\n",
            "Iteration 1012, loss = 0.00147468\n",
            "Iteration 1013, loss = 0.00146524\n",
            "Iteration 1014, loss = 0.00146728\n",
            "Iteration 1015, loss = 0.00145653\n",
            "Iteration 1016, loss = 0.00144970\n",
            "Iteration 1017, loss = 0.00145137\n",
            "Iteration 1018, loss = 0.00144149\n",
            "Iteration 1019, loss = 0.00143257\n",
            "Iteration 1020, loss = 0.00142485\n",
            "Iteration 1021, loss = 0.00142150\n",
            "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.66185205\n",
            "Iteration 2, loss = 0.55613527\n",
            "Iteration 3, loss = 0.48864235\n",
            "Iteration 4, loss = 0.44757225\n",
            "Iteration 5, loss = 0.42091566\n",
            "Iteration 6, loss = 0.40171821\n",
            "Iteration 7, loss = 0.38837806\n",
            "Iteration 8, loss = 0.37802770\n",
            "Iteration 9, loss = 0.36936684\n",
            "Iteration 10, loss = 0.36219707\n",
            "Iteration 11, loss = 0.35576061\n",
            "Iteration 12, loss = 0.35022031\n",
            "Iteration 13, loss = 0.34518018\n",
            "Iteration 14, loss = 0.34096864\n",
            "Iteration 15, loss = 0.33693599\n",
            "Iteration 16, loss = 0.33315968\n",
            "Iteration 17, loss = 0.32964217\n",
            "Iteration 18, loss = 0.32637170\n",
            "Iteration 19, loss = 0.32315953\n",
            "Iteration 20, loss = 0.32013935\n",
            "Iteration 21, loss = 0.31728349\n",
            "Iteration 22, loss = 0.31463016\n",
            "Iteration 23, loss = 0.31199529\n",
            "Iteration 24, loss = 0.30945270\n",
            "Iteration 25, loss = 0.30702943\n",
            "Iteration 26, loss = 0.30473696\n",
            "Iteration 27, loss = 0.30243155\n",
            "Iteration 28, loss = 0.30057078\n",
            "Iteration 29, loss = 0.29812732\n",
            "Iteration 30, loss = 0.29599011\n",
            "Iteration 31, loss = 0.29421618\n",
            "Iteration 32, loss = 0.29200451\n",
            "Iteration 33, loss = 0.29000029\n",
            "Iteration 34, loss = 0.28801452\n",
            "Iteration 35, loss = 0.28621785\n",
            "Iteration 36, loss = 0.28441475\n",
            "Iteration 37, loss = 0.28253514\n",
            "Iteration 38, loss = 0.28067570\n",
            "Iteration 39, loss = 0.27866028\n",
            "Iteration 40, loss = 0.27698485\n",
            "Iteration 41, loss = 0.27520709\n",
            "Iteration 42, loss = 0.27348680\n",
            "Iteration 43, loss = 0.27182540\n",
            "Iteration 44, loss = 0.27004632\n",
            "Iteration 45, loss = 0.26836538\n",
            "Iteration 46, loss = 0.26678394\n",
            "Iteration 47, loss = 0.26496211\n",
            "Iteration 48, loss = 0.26334494\n",
            "Iteration 49, loss = 0.26167148\n",
            "Iteration 50, loss = 0.26005643\n",
            "Iteration 51, loss = 0.25861395\n",
            "Iteration 52, loss = 0.25722307\n",
            "Iteration 53, loss = 0.25534341\n",
            "Iteration 54, loss = 0.25358979\n",
            "Iteration 55, loss = 0.25221953\n",
            "Iteration 56, loss = 0.25039831\n",
            "Iteration 57, loss = 0.24907760\n",
            "Iteration 58, loss = 0.24754274\n",
            "Iteration 59, loss = 0.24586545\n",
            "Iteration 60, loss = 0.24445045\n",
            "Iteration 61, loss = 0.24321707\n",
            "Iteration 62, loss = 0.24145525\n",
            "Iteration 63, loss = 0.23980016\n",
            "Iteration 64, loss = 0.23825214\n",
            "Iteration 65, loss = 0.23679930\n",
            "Iteration 66, loss = 0.23556593\n",
            "Iteration 67, loss = 0.23403406\n",
            "Iteration 68, loss = 0.23262310\n",
            "Iteration 69, loss = 0.23139495\n",
            "Iteration 70, loss = 0.22990206\n",
            "Iteration 71, loss = 0.22850465\n",
            "Iteration 72, loss = 0.22708943\n",
            "Iteration 73, loss = 0.22579461\n",
            "Iteration 74, loss = 0.22420702\n",
            "Iteration 75, loss = 0.22334015\n",
            "Iteration 76, loss = 0.22174836\n",
            "Iteration 77, loss = 0.22016224\n",
            "Iteration 78, loss = 0.21890166\n",
            "Iteration 79, loss = 0.21790917\n",
            "Iteration 80, loss = 0.21608301\n",
            "Iteration 81, loss = 0.21514175\n",
            "Iteration 82, loss = 0.21344872\n",
            "Iteration 83, loss = 0.21223147\n",
            "Iteration 84, loss = 0.21103212\n",
            "Iteration 85, loss = 0.20949829\n",
            "Iteration 86, loss = 0.20833370\n",
            "Iteration 87, loss = 0.20715758\n",
            "Iteration 88, loss = 0.20553818\n",
            "Iteration 89, loss = 0.20433924\n",
            "Iteration 90, loss = 0.20303934\n",
            "Iteration 91, loss = 0.20198819\n",
            "Iteration 92, loss = 0.20100753\n",
            "Iteration 93, loss = 0.19973507\n",
            "Iteration 94, loss = 0.19818812\n",
            "Iteration 95, loss = 0.19705310\n",
            "Iteration 96, loss = 0.19580128\n",
            "Iteration 97, loss = 0.19440049\n",
            "Iteration 98, loss = 0.19383302\n",
            "Iteration 99, loss = 0.19319424\n",
            "Iteration 100, loss = 0.19117956\n",
            "Iteration 101, loss = 0.18999553\n",
            "Iteration 102, loss = 0.18907776\n",
            "Iteration 103, loss = 0.18736631\n",
            "Iteration 104, loss = 0.18646874\n",
            "Iteration 105, loss = 0.18534013\n",
            "Iteration 106, loss = 0.18463356\n",
            "Iteration 107, loss = 0.18317741\n",
            "Iteration 108, loss = 0.18180094\n",
            "Iteration 109, loss = 0.18076256\n",
            "Iteration 110, loss = 0.17951055\n",
            "Iteration 111, loss = 0.17851587\n",
            "Iteration 112, loss = 0.17745251\n",
            "Iteration 113, loss = 0.17639328\n",
            "Iteration 114, loss = 0.17520887\n",
            "Iteration 115, loss = 0.17424559\n",
            "Iteration 116, loss = 0.17326020\n",
            "Iteration 117, loss = 0.17205344\n",
            "Iteration 118, loss = 0.17095118\n",
            "Iteration 119, loss = 0.17004935\n",
            "Iteration 120, loss = 0.16882298\n",
            "Iteration 121, loss = 0.16805790\n",
            "Iteration 122, loss = 0.16699187\n",
            "Iteration 123, loss = 0.16598200\n",
            "Iteration 124, loss = 0.16495312\n",
            "Iteration 125, loss = 0.16436542\n",
            "Iteration 126, loss = 0.16305176\n",
            "Iteration 127, loss = 0.16202911\n",
            "Iteration 128, loss = 0.16115801\n",
            "Iteration 129, loss = 0.16026415\n",
            "Iteration 130, loss = 0.15905186\n",
            "Iteration 131, loss = 0.15784362\n",
            "Iteration 132, loss = 0.15726210\n",
            "Iteration 133, loss = 0.15671400\n",
            "Iteration 134, loss = 0.15532651\n",
            "Iteration 135, loss = 0.15431374\n",
            "Iteration 136, loss = 0.15331640\n",
            "Iteration 137, loss = 0.15221917\n",
            "Iteration 138, loss = 0.15135422\n",
            "Iteration 139, loss = 0.15047897\n",
            "Iteration 140, loss = 0.14963065\n",
            "Iteration 141, loss = 0.14874430\n",
            "Iteration 142, loss = 0.14773765\n",
            "Iteration 143, loss = 0.14702683\n",
            "Iteration 144, loss = 0.14682412\n",
            "Iteration 145, loss = 0.14532837\n",
            "Iteration 146, loss = 0.14417989\n",
            "Iteration 147, loss = 0.14328842\n",
            "Iteration 148, loss = 0.14308415\n",
            "Iteration 149, loss = 0.14201711\n",
            "Iteration 150, loss = 0.14096087\n",
            "Iteration 151, loss = 0.13999833\n",
            "Iteration 152, loss = 0.13908154\n",
            "Iteration 153, loss = 0.13802039\n",
            "Iteration 154, loss = 0.13736534\n",
            "Iteration 155, loss = 0.13631611\n",
            "Iteration 156, loss = 0.13568661\n",
            "Iteration 157, loss = 0.13475060\n",
            "Iteration 158, loss = 0.13402669\n",
            "Iteration 159, loss = 0.13299811\n",
            "Iteration 160, loss = 0.13230498\n",
            "Iteration 161, loss = 0.13140956\n",
            "Iteration 162, loss = 0.13068011\n",
            "Iteration 163, loss = 0.12984118\n",
            "Iteration 164, loss = 0.12919432\n",
            "Iteration 165, loss = 0.12821916\n",
            "Iteration 166, loss = 0.12745080\n",
            "Iteration 167, loss = 0.12663605\n",
            "Iteration 168, loss = 0.12610760\n",
            "Iteration 169, loss = 0.12510917\n",
            "Iteration 170, loss = 0.12434500\n",
            "Iteration 171, loss = 0.12363155\n",
            "Iteration 172, loss = 0.12332510\n",
            "Iteration 173, loss = 0.12259744\n",
            "Iteration 174, loss = 0.12164006\n",
            "Iteration 175, loss = 0.12077466\n",
            "Iteration 176, loss = 0.12029508\n",
            "Iteration 177, loss = 0.11911485\n",
            "Iteration 178, loss = 0.11860912\n",
            "Iteration 179, loss = 0.11789899\n",
            "Iteration 180, loss = 0.11704710\n",
            "Iteration 181, loss = 0.11653048\n",
            "Iteration 182, loss = 0.11539886\n",
            "Iteration 183, loss = 0.11479363\n",
            "Iteration 184, loss = 0.11416053\n",
            "Iteration 185, loss = 0.11359747\n",
            "Iteration 186, loss = 0.11269161\n",
            "Iteration 187, loss = 0.11174591\n",
            "Iteration 188, loss = 0.11132719\n",
            "Iteration 189, loss = 0.11200285\n",
            "Iteration 190, loss = 0.11088710\n",
            "Iteration 191, loss = 0.10939296\n",
            "Iteration 192, loss = 0.10873483\n",
            "Iteration 193, loss = 0.10792759\n",
            "Iteration 194, loss = 0.10699941\n",
            "Iteration 195, loss = 0.10632321\n",
            "Iteration 196, loss = 0.10589269\n",
            "Iteration 197, loss = 0.10513413\n",
            "Iteration 198, loss = 0.10485386\n",
            "Iteration 199, loss = 0.10367077\n",
            "Iteration 200, loss = 0.10301341\n",
            "Iteration 201, loss = 0.10235775\n",
            "Iteration 202, loss = 0.10199758\n",
            "Iteration 203, loss = 0.10095852\n",
            "Iteration 204, loss = 0.10030815\n",
            "Iteration 205, loss = 0.09969747\n",
            "Iteration 206, loss = 0.09919740\n",
            "Iteration 207, loss = 0.09871297\n",
            "Iteration 208, loss = 0.09790831\n",
            "Iteration 209, loss = 0.09743031\n",
            "Iteration 210, loss = 0.09717260\n",
            "Iteration 211, loss = 0.09646009\n",
            "Iteration 212, loss = 0.09535984\n",
            "Iteration 213, loss = 0.09473012\n",
            "Iteration 214, loss = 0.09398723\n",
            "Iteration 215, loss = 0.09375781\n",
            "Iteration 216, loss = 0.09284151\n",
            "Iteration 217, loss = 0.09227935\n",
            "Iteration 218, loss = 0.09196319\n",
            "Iteration 219, loss = 0.09110066\n",
            "Iteration 220, loss = 0.09107571\n",
            "Iteration 221, loss = 0.08991062\n",
            "Iteration 222, loss = 0.08978459\n",
            "Iteration 223, loss = 0.08884658\n",
            "Iteration 224, loss = 0.08828703\n",
            "Iteration 225, loss = 0.08771985\n",
            "Iteration 226, loss = 0.08711930\n",
            "Iteration 227, loss = 0.08687372\n",
            "Iteration 228, loss = 0.08681341\n",
            "Iteration 229, loss = 0.08536087\n",
            "Iteration 230, loss = 0.08520122\n",
            "Iteration 231, loss = 0.08449057\n",
            "Iteration 232, loss = 0.08386478\n",
            "Iteration 233, loss = 0.08316561\n",
            "Iteration 234, loss = 0.08267037\n",
            "Iteration 235, loss = 0.08225006\n",
            "Iteration 236, loss = 0.08167435\n",
            "Iteration 237, loss = 0.08118993\n",
            "Iteration 238, loss = 0.08082580\n",
            "Iteration 239, loss = 0.08036439\n",
            "Iteration 240, loss = 0.07962354\n",
            "Iteration 241, loss = 0.07951040\n",
            "Iteration 242, loss = 0.07838689\n",
            "Iteration 243, loss = 0.07812749\n",
            "Iteration 244, loss = 0.07762728\n",
            "Iteration 245, loss = 0.07694341\n",
            "Iteration 246, loss = 0.07648949\n",
            "Iteration 247, loss = 0.07611887\n",
            "Iteration 248, loss = 0.07566247\n",
            "Iteration 249, loss = 0.07517130\n",
            "Iteration 250, loss = 0.07447140\n",
            "Iteration 251, loss = 0.07405344\n",
            "Iteration 252, loss = 0.07375630\n",
            "Iteration 253, loss = 0.07325649\n",
            "Iteration 254, loss = 0.07267440\n",
            "Iteration 255, loss = 0.07204274\n",
            "Iteration 256, loss = 0.07179135\n",
            "Iteration 257, loss = 0.07106787\n",
            "Iteration 258, loss = 0.07065046\n",
            "Iteration 259, loss = 0.07064292\n",
            "Iteration 260, loss = 0.06952369\n",
            "Iteration 261, loss = 0.06962299\n",
            "Iteration 262, loss = 0.06888727\n",
            "Iteration 263, loss = 0.06838658\n",
            "Iteration 264, loss = 0.06784201\n",
            "Iteration 265, loss = 0.06748557\n",
            "Iteration 266, loss = 0.06691701\n",
            "Iteration 267, loss = 0.06668782\n",
            "Iteration 268, loss = 0.06642075\n",
            "Iteration 269, loss = 0.06589951\n",
            "Iteration 270, loss = 0.06533005\n",
            "Iteration 271, loss = 0.06497411\n",
            "Iteration 272, loss = 0.06424083\n",
            "Iteration 273, loss = 0.06398482\n",
            "Iteration 274, loss = 0.06361835\n",
            "Iteration 275, loss = 0.06300641\n",
            "Iteration 276, loss = 0.06280989\n",
            "Iteration 277, loss = 0.06226261\n",
            "Iteration 278, loss = 0.06189109\n",
            "Iteration 279, loss = 0.06140423\n",
            "Iteration 280, loss = 0.06106886\n",
            "Iteration 281, loss = 0.06055402\n",
            "Iteration 282, loss = 0.06040508\n",
            "Iteration 283, loss = 0.06001635\n",
            "Iteration 284, loss = 0.05941936\n",
            "Iteration 285, loss = 0.05902314\n",
            "Iteration 286, loss = 0.05880289\n",
            "Iteration 287, loss = 0.05857852\n",
            "Iteration 288, loss = 0.05803823\n",
            "Iteration 289, loss = 0.05759956\n",
            "Iteration 290, loss = 0.05746896\n",
            "Iteration 291, loss = 0.05748706\n",
            "Iteration 292, loss = 0.05694027\n",
            "Iteration 293, loss = 0.05636067\n",
            "Iteration 294, loss = 0.05587568\n",
            "Iteration 295, loss = 0.05535759\n",
            "Iteration 296, loss = 0.05492725\n",
            "Iteration 297, loss = 0.05464244\n",
            "Iteration 298, loss = 0.05423516\n",
            "Iteration 299, loss = 0.05408955\n",
            "Iteration 300, loss = 0.05374808\n",
            "Iteration 301, loss = 0.05332338\n",
            "Iteration 302, loss = 0.05274411\n",
            "Iteration 303, loss = 0.05309874\n",
            "Iteration 304, loss = 0.05235044\n",
            "Iteration 305, loss = 0.05203110\n",
            "Iteration 306, loss = 0.05171733\n",
            "Iteration 307, loss = 0.05122796\n",
            "Iteration 308, loss = 0.05098286\n",
            "Iteration 309, loss = 0.05055580\n",
            "Iteration 310, loss = 0.05028210\n",
            "Iteration 311, loss = 0.04999014\n",
            "Iteration 312, loss = 0.04966477\n",
            "Iteration 313, loss = 0.04923748\n",
            "Iteration 314, loss = 0.04907354\n",
            "Iteration 315, loss = 0.04861884\n",
            "Iteration 316, loss = 0.04837532\n",
            "Iteration 317, loss = 0.04794457\n",
            "Iteration 318, loss = 0.04780722\n",
            "Iteration 319, loss = 0.04747626\n",
            "Iteration 320, loss = 0.04716533\n",
            "Iteration 321, loss = 0.04665009\n",
            "Iteration 322, loss = 0.04638611\n",
            "Iteration 323, loss = 0.04622552\n",
            "Iteration 324, loss = 0.04587545\n",
            "Iteration 325, loss = 0.04551566\n",
            "Iteration 326, loss = 0.04536221\n",
            "Iteration 327, loss = 0.04487920\n",
            "Iteration 328, loss = 0.04472771\n",
            "Iteration 329, loss = 0.04465218\n",
            "Iteration 330, loss = 0.04441639\n",
            "Iteration 331, loss = 0.04380634\n",
            "Iteration 332, loss = 0.04375333\n",
            "Iteration 333, loss = 0.04348176\n",
            "Iteration 334, loss = 0.04307422\n",
            "Iteration 335, loss = 0.04311870\n",
            "Iteration 336, loss = 0.04261992\n",
            "Iteration 337, loss = 0.04227904\n",
            "Iteration 338, loss = 0.04173590\n",
            "Iteration 339, loss = 0.04159510\n",
            "Iteration 340, loss = 0.04140701\n",
            "Iteration 341, loss = 0.04121952\n",
            "Iteration 342, loss = 0.04109416\n",
            "Iteration 343, loss = 0.04051763\n",
            "Iteration 344, loss = 0.04029932\n",
            "Iteration 345, loss = 0.04005659\n",
            "Iteration 346, loss = 0.04006291\n",
            "Iteration 347, loss = 0.03946754\n",
            "Iteration 348, loss = 0.03930629\n",
            "Iteration 349, loss = 0.03937079\n",
            "Iteration 350, loss = 0.03892948\n",
            "Iteration 351, loss = 0.03854732\n",
            "Iteration 352, loss = 0.03833598\n",
            "Iteration 353, loss = 0.03788153\n",
            "Iteration 354, loss = 0.03796384\n",
            "Iteration 355, loss = 0.03769482\n",
            "Iteration 356, loss = 0.03716191\n",
            "Iteration 357, loss = 0.03730993\n",
            "Iteration 358, loss = 0.03679480\n",
            "Iteration 359, loss = 0.03674027\n",
            "Iteration 360, loss = 0.03635650\n",
            "Iteration 361, loss = 0.03602519\n",
            "Iteration 362, loss = 0.03584236\n",
            "Iteration 363, loss = 0.03545822\n",
            "Iteration 364, loss = 0.03533906\n",
            "Iteration 365, loss = 0.03508687\n",
            "Iteration 366, loss = 0.03497707\n",
            "Iteration 367, loss = 0.03462458\n",
            "Iteration 368, loss = 0.03452852\n",
            "Iteration 369, loss = 0.03417132\n",
            "Iteration 370, loss = 0.03394734\n",
            "Iteration 371, loss = 0.03376993\n",
            "Iteration 372, loss = 0.03356933\n",
            "Iteration 373, loss = 0.03339011\n",
            "Iteration 374, loss = 0.03313748\n",
            "Iteration 375, loss = 0.03290642\n",
            "Iteration 376, loss = 0.03291605\n",
            "Iteration 377, loss = 0.03251297\n",
            "Iteration 378, loss = 0.03231581\n",
            "Iteration 379, loss = 0.03201374\n",
            "Iteration 380, loss = 0.03181396\n",
            "Iteration 381, loss = 0.03166792\n",
            "Iteration 382, loss = 0.03133749\n",
            "Iteration 383, loss = 0.03138226\n",
            "Iteration 384, loss = 0.03104198\n",
            "Iteration 385, loss = 0.03094459\n",
            "Iteration 386, loss = 0.03061146\n",
            "Iteration 387, loss = 0.03053717\n",
            "Iteration 388, loss = 0.03032292\n",
            "Iteration 389, loss = 0.03008131\n",
            "Iteration 390, loss = 0.02985280\n",
            "Iteration 391, loss = 0.02979243\n",
            "Iteration 392, loss = 0.02957909\n",
            "Iteration 393, loss = 0.02927598\n",
            "Iteration 394, loss = 0.02902490\n",
            "Iteration 395, loss = 0.02891670\n",
            "Iteration 396, loss = 0.02870911\n",
            "Iteration 397, loss = 0.02856163\n",
            "Iteration 398, loss = 0.02833289\n",
            "Iteration 399, loss = 0.02820022\n",
            "Iteration 400, loss = 0.02804542\n",
            "Iteration 401, loss = 0.02779503\n",
            "Iteration 402, loss = 0.02774299\n",
            "Iteration 403, loss = 0.02763703\n",
            "Iteration 404, loss = 0.02736580\n",
            "Iteration 405, loss = 0.02727072\n",
            "Iteration 406, loss = 0.02689271\n",
            "Iteration 407, loss = 0.02671075\n",
            "Iteration 408, loss = 0.02662054\n",
            "Iteration 409, loss = 0.02635185\n",
            "Iteration 410, loss = 0.02627281\n",
            "Iteration 411, loss = 0.02604656\n",
            "Iteration 412, loss = 0.02588547\n",
            "Iteration 413, loss = 0.02574575\n",
            "Iteration 414, loss = 0.02555771\n",
            "Iteration 415, loss = 0.02541994\n",
            "Iteration 416, loss = 0.02524216\n",
            "Iteration 417, loss = 0.02506877\n",
            "Iteration 418, loss = 0.02505880\n",
            "Iteration 419, loss = 0.02474016\n",
            "Iteration 420, loss = 0.02474890\n",
            "Iteration 421, loss = 0.02442926\n",
            "Iteration 422, loss = 0.02436019\n",
            "Iteration 423, loss = 0.02414151\n",
            "Iteration 424, loss = 0.02400207\n",
            "Iteration 425, loss = 0.02387876\n",
            "Iteration 426, loss = 0.02369703\n",
            "Iteration 427, loss = 0.02370774\n",
            "Iteration 428, loss = 0.02356618\n",
            "Iteration 429, loss = 0.02341394\n",
            "Iteration 430, loss = 0.02310294\n",
            "Iteration 431, loss = 0.02301934\n",
            "Iteration 432, loss = 0.02277365\n",
            "Iteration 433, loss = 0.02270592\n",
            "Iteration 434, loss = 0.02268251\n",
            "Iteration 435, loss = 0.02231449\n",
            "Iteration 436, loss = 0.02236158\n",
            "Iteration 437, loss = 0.02203964\n",
            "Iteration 438, loss = 0.02204527\n",
            "Iteration 439, loss = 0.02189469\n",
            "Iteration 440, loss = 0.02171286\n",
            "Iteration 441, loss = 0.02158357\n",
            "Iteration 442, loss = 0.02151752\n",
            "Iteration 443, loss = 0.02143945\n",
            "Iteration 444, loss = 0.02123204\n",
            "Iteration 445, loss = 0.02106722\n",
            "Iteration 446, loss = 0.02096114\n",
            "Iteration 447, loss = 0.02072267\n",
            "Iteration 448, loss = 0.02063586\n",
            "Iteration 449, loss = 0.02053829\n",
            "Iteration 450, loss = 0.02040002\n",
            "Iteration 451, loss = 0.02028863\n",
            "Iteration 452, loss = 0.02019414\n",
            "Iteration 453, loss = 0.02008186\n",
            "Iteration 454, loss = 0.01987769\n",
            "Iteration 455, loss = 0.01987542\n",
            "Iteration 456, loss = 0.01960433\n",
            "Iteration 457, loss = 0.01952056\n",
            "Iteration 458, loss = 0.01934480\n",
            "Iteration 459, loss = 0.01928149\n",
            "Iteration 460, loss = 0.01918843\n",
            "Iteration 461, loss = 0.01902990\n",
            "Iteration 462, loss = 0.01894726\n",
            "Iteration 463, loss = 0.01889348\n",
            "Iteration 464, loss = 0.01873230\n",
            "Iteration 465, loss = 0.01869013\n",
            "Iteration 466, loss = 0.01848365\n",
            "Iteration 467, loss = 0.01836582\n",
            "Iteration 468, loss = 0.01825721\n",
            "Iteration 469, loss = 0.01814859\n",
            "Iteration 470, loss = 0.01804405\n",
            "Iteration 471, loss = 0.01791844\n",
            "Iteration 472, loss = 0.01782092\n",
            "Iteration 473, loss = 0.01795291\n",
            "Iteration 474, loss = 0.01768585\n",
            "Iteration 475, loss = 0.01750035\n",
            "Iteration 476, loss = 0.01743829\n",
            "Iteration 477, loss = 0.01727804\n",
            "Iteration 478, loss = 0.01720957\n",
            "Iteration 479, loss = 0.01711242\n",
            "Iteration 480, loss = 0.01698712\n",
            "Iteration 481, loss = 0.01696283\n",
            "Iteration 482, loss = 0.01677704\n",
            "Iteration 483, loss = 0.01667858\n",
            "Iteration 484, loss = 0.01660660\n",
            "Iteration 485, loss = 0.01652956\n",
            "Iteration 486, loss = 0.01639621\n",
            "Iteration 487, loss = 0.01631304\n",
            "Iteration 488, loss = 0.01629596\n",
            "Iteration 489, loss = 0.01623356\n",
            "Iteration 490, loss = 0.01606400\n",
            "Iteration 491, loss = 0.01591005\n",
            "Iteration 492, loss = 0.01581994\n",
            "Iteration 493, loss = 0.01575865\n",
            "Iteration 494, loss = 0.01561849\n",
            "Iteration 495, loss = 0.01555004\n",
            "Iteration 496, loss = 0.01550633\n",
            "Iteration 497, loss = 0.01533669\n",
            "Iteration 498, loss = 0.01534843\n",
            "Iteration 499, loss = 0.01518792\n",
            "Iteration 500, loss = 0.01516967\n",
            "Iteration 501, loss = 0.01506471\n",
            "Iteration 502, loss = 0.01495730\n",
            "Iteration 503, loss = 0.01487766\n",
            "Iteration 504, loss = 0.01480015\n",
            "Iteration 505, loss = 0.01472401\n",
            "Iteration 506, loss = 0.01455695\n",
            "Iteration 507, loss = 0.01454346\n",
            "Iteration 508, loss = 0.01449700\n",
            "Iteration 509, loss = 0.01442419\n",
            "Iteration 510, loss = 0.01420902\n",
            "Iteration 511, loss = 0.01421992\n",
            "Iteration 512, loss = 0.01406070\n",
            "Iteration 513, loss = 0.01397306\n",
            "Iteration 514, loss = 0.01390487\n",
            "Iteration 515, loss = 0.01386736\n",
            "Iteration 516, loss = 0.01373441\n",
            "Iteration 517, loss = 0.01370513\n",
            "Iteration 518, loss = 0.01369478\n",
            "Iteration 519, loss = 0.01348917\n",
            "Iteration 520, loss = 0.01342129\n",
            "Iteration 521, loss = 0.01334735\n",
            "Iteration 522, loss = 0.01328078\n",
            "Iteration 523, loss = 0.01322477\n",
            "Iteration 524, loss = 0.01309930\n",
            "Iteration 525, loss = 0.01320743\n",
            "Iteration 526, loss = 0.01292454\n",
            "Iteration 527, loss = 0.01295816\n",
            "Iteration 528, loss = 0.01282674\n",
            "Iteration 529, loss = 0.01273862\n",
            "Iteration 530, loss = 0.01266612\n",
            "Iteration 531, loss = 0.01261115\n",
            "Iteration 532, loss = 0.01250368\n",
            "Iteration 533, loss = 0.01244383\n",
            "Iteration 534, loss = 0.01240295\n",
            "Iteration 535, loss = 0.01230559\n",
            "Iteration 536, loss = 0.01223619\n",
            "Iteration 537, loss = 0.01216200\n",
            "Iteration 538, loss = 0.01209818\n",
            "Iteration 539, loss = 0.01202273\n",
            "Iteration 540, loss = 0.01198162\n",
            "Iteration 541, loss = 0.01193736\n",
            "Iteration 542, loss = 0.01182309\n",
            "Iteration 543, loss = 0.01179761\n",
            "Iteration 544, loss = 0.01171921\n",
            "Iteration 545, loss = 0.01161143\n",
            "Iteration 546, loss = 0.01163268\n",
            "Iteration 547, loss = 0.01150929\n",
            "Iteration 548, loss = 0.01144109\n",
            "Iteration 549, loss = 0.01136785\n",
            "Iteration 550, loss = 0.01132756\n",
            "Iteration 551, loss = 0.01129608\n",
            "Iteration 552, loss = 0.01121655\n",
            "Iteration 553, loss = 0.01111959\n",
            "Iteration 554, loss = 0.01109993\n",
            "Iteration 555, loss = 0.01099986\n",
            "Iteration 556, loss = 0.01094560\n",
            "Iteration 557, loss = 0.01087398\n",
            "Iteration 558, loss = 0.01080365\n",
            "Iteration 559, loss = 0.01076235\n",
            "Iteration 560, loss = 0.01074476\n",
            "Iteration 561, loss = 0.01071114\n",
            "Iteration 562, loss = 0.01060491\n",
            "Iteration 563, loss = 0.01052721\n",
            "Iteration 564, loss = 0.01043851\n",
            "Iteration 565, loss = 0.01039741\n",
            "Iteration 566, loss = 0.01033442\n",
            "Iteration 567, loss = 0.01029149\n",
            "Iteration 568, loss = 0.01019741\n",
            "Iteration 569, loss = 0.01016899\n",
            "Iteration 570, loss = 0.01011097\n",
            "Iteration 571, loss = 0.01005447\n",
            "Iteration 572, loss = 0.00996824\n",
            "Iteration 573, loss = 0.00993509\n",
            "Iteration 574, loss = 0.00988583\n",
            "Iteration 575, loss = 0.00986482\n",
            "Iteration 576, loss = 0.00976668\n",
            "Iteration 577, loss = 0.00971266\n",
            "Iteration 578, loss = 0.00968014\n",
            "Iteration 579, loss = 0.00957767\n",
            "Iteration 580, loss = 0.00955109\n",
            "Iteration 581, loss = 0.00951139\n",
            "Iteration 582, loss = 0.00943986\n",
            "Iteration 583, loss = 0.00943560\n",
            "Iteration 584, loss = 0.00937096\n",
            "Iteration 585, loss = 0.00926793\n",
            "Iteration 586, loss = 0.00925324\n",
            "Iteration 587, loss = 0.00919183\n",
            "Iteration 588, loss = 0.00913242\n",
            "Iteration 589, loss = 0.00909120\n",
            "Iteration 590, loss = 0.00903814\n",
            "Iteration 591, loss = 0.00900811\n",
            "Iteration 592, loss = 0.00898239\n",
            "Iteration 593, loss = 0.00888925\n",
            "Iteration 594, loss = 0.00884755\n",
            "Iteration 595, loss = 0.00879063\n",
            "Iteration 596, loss = 0.00876668\n",
            "Iteration 597, loss = 0.00871118\n",
            "Iteration 598, loss = 0.00864047\n",
            "Iteration 599, loss = 0.00862580\n",
            "Iteration 600, loss = 0.00855986\n",
            "Iteration 601, loss = 0.00852110\n",
            "Iteration 602, loss = 0.00854283\n",
            "Iteration 603, loss = 0.00841333\n",
            "Iteration 604, loss = 0.00842355\n",
            "Iteration 605, loss = 0.00830710\n",
            "Iteration 606, loss = 0.00827612\n",
            "Iteration 607, loss = 0.00824374\n",
            "Iteration 608, loss = 0.00818452\n",
            "Iteration 609, loss = 0.00814292\n",
            "Iteration 610, loss = 0.00809837\n",
            "Iteration 611, loss = 0.00804511\n",
            "Iteration 612, loss = 0.00804495\n",
            "Iteration 613, loss = 0.00797079\n",
            "Iteration 614, loss = 0.00791884\n",
            "Iteration 615, loss = 0.00786833\n",
            "Iteration 616, loss = 0.00783513\n",
            "Iteration 617, loss = 0.00782324\n",
            "Iteration 618, loss = 0.00776105\n",
            "Iteration 619, loss = 0.00773097\n",
            "Iteration 620, loss = 0.00769371\n",
            "Iteration 621, loss = 0.00762875\n",
            "Iteration 622, loss = 0.00760168\n",
            "Iteration 623, loss = 0.00754261\n",
            "Iteration 624, loss = 0.00751463\n",
            "Iteration 625, loss = 0.00746536\n",
            "Iteration 626, loss = 0.00743615\n",
            "Iteration 627, loss = 0.00740106\n",
            "Iteration 628, loss = 0.00736252\n",
            "Iteration 629, loss = 0.00730137\n",
            "Iteration 630, loss = 0.00730137\n",
            "Iteration 631, loss = 0.00722657\n",
            "Iteration 632, loss = 0.00721064\n",
            "Iteration 633, loss = 0.00715159\n",
            "Iteration 634, loss = 0.00710646\n",
            "Iteration 635, loss = 0.00709309\n",
            "Iteration 636, loss = 0.00706413\n",
            "Iteration 637, loss = 0.00702429\n",
            "Iteration 638, loss = 0.00696015\n",
            "Iteration 639, loss = 0.00692468\n",
            "Iteration 640, loss = 0.00689229\n",
            "Iteration 641, loss = 0.00685681\n",
            "Iteration 642, loss = 0.00685374\n",
            "Iteration 643, loss = 0.00684657\n",
            "Iteration 644, loss = 0.00678764\n",
            "Iteration 645, loss = 0.00671389\n",
            "Iteration 646, loss = 0.00666969\n",
            "Iteration 647, loss = 0.00666194\n",
            "Iteration 648, loss = 0.00660479\n",
            "Iteration 649, loss = 0.00657891\n",
            "Iteration 650, loss = 0.00653542\n",
            "Iteration 651, loss = 0.00652560\n",
            "Iteration 652, loss = 0.00645835\n",
            "Iteration 653, loss = 0.00653220\n",
            "Iteration 654, loss = 0.00639952\n",
            "Iteration 655, loss = 0.00643992\n",
            "Iteration 656, loss = 0.00635437\n",
            "Iteration 657, loss = 0.00633803\n",
            "Iteration 658, loss = 0.00626248\n",
            "Iteration 659, loss = 0.00625427\n",
            "Iteration 660, loss = 0.00623032\n",
            "Iteration 661, loss = 0.00617919\n",
            "Iteration 662, loss = 0.00616355\n",
            "Iteration 663, loss = 0.00614144\n",
            "Iteration 664, loss = 0.00609530\n",
            "Iteration 665, loss = 0.00605293\n",
            "Iteration 666, loss = 0.00602523\n",
            "Iteration 667, loss = 0.00598091\n",
            "Iteration 668, loss = 0.00598881\n",
            "Iteration 669, loss = 0.00593212\n",
            "Iteration 670, loss = 0.00590594\n",
            "Iteration 671, loss = 0.00588373\n",
            "Iteration 672, loss = 0.00584229\n",
            "Iteration 673, loss = 0.00580455\n",
            "Iteration 674, loss = 0.00578803\n",
            "Iteration 675, loss = 0.00574886\n",
            "Iteration 676, loss = 0.00574076\n",
            "Iteration 677, loss = 0.00570494\n",
            "Iteration 678, loss = 0.00566289\n",
            "Iteration 679, loss = 0.00563777\n",
            "Iteration 680, loss = 0.00561804\n",
            "Iteration 681, loss = 0.00558970\n",
            "Iteration 682, loss = 0.00554672\n",
            "Iteration 683, loss = 0.00553931\n",
            "Iteration 684, loss = 0.00549299\n",
            "Iteration 685, loss = 0.00548333\n",
            "Iteration 686, loss = 0.00546766\n",
            "Iteration 687, loss = 0.00542074\n",
            "Iteration 688, loss = 0.00540249\n",
            "Iteration 689, loss = 0.00536861\n",
            "Iteration 690, loss = 0.00535573\n",
            "Iteration 691, loss = 0.00530708\n",
            "Iteration 692, loss = 0.00529766\n",
            "Iteration 693, loss = 0.00526118\n",
            "Iteration 694, loss = 0.00523240\n",
            "Iteration 695, loss = 0.00520921\n",
            "Iteration 696, loss = 0.00517258\n",
            "Iteration 697, loss = 0.00517218\n",
            "Iteration 698, loss = 0.00514831\n",
            "Iteration 699, loss = 0.00511877\n",
            "Iteration 700, loss = 0.00507581\n",
            "Iteration 701, loss = 0.00508140\n",
            "Iteration 702, loss = 0.00501997\n",
            "Iteration 703, loss = 0.00501060\n",
            "Iteration 704, loss = 0.00500660\n",
            "Iteration 705, loss = 0.00496505\n",
            "Iteration 706, loss = 0.00494490\n",
            "Iteration 707, loss = 0.00490913\n",
            "Iteration 708, loss = 0.00487621\n",
            "Iteration 709, loss = 0.00484836\n",
            "Iteration 710, loss = 0.00482374\n",
            "Iteration 711, loss = 0.00481484\n",
            "Iteration 712, loss = 0.00479089\n",
            "Iteration 713, loss = 0.00476696\n",
            "Iteration 714, loss = 0.00474570\n",
            "Iteration 715, loss = 0.00471273\n",
            "Iteration 716, loss = 0.00470755\n",
            "Iteration 717, loss = 0.00472606\n",
            "Iteration 718, loss = 0.00467834\n",
            "Iteration 719, loss = 0.00462713\n",
            "Iteration 720, loss = 0.00461302\n",
            "Iteration 721, loss = 0.00458883\n",
            "Iteration 722, loss = 0.00457393\n",
            "Iteration 723, loss = 0.00453027\n",
            "Iteration 724, loss = 0.00450595\n",
            "Iteration 725, loss = 0.00450967\n",
            "Iteration 726, loss = 0.00447107\n",
            "Iteration 727, loss = 0.00446768\n",
            "Iteration 728, loss = 0.00443846\n",
            "Iteration 729, loss = 0.00441787\n",
            "Iteration 730, loss = 0.00442196\n",
            "Iteration 731, loss = 0.00437054\n",
            "Iteration 732, loss = 0.00434721\n",
            "Iteration 733, loss = 0.00431082\n",
            "Iteration 734, loss = 0.00430852\n",
            "Iteration 735, loss = 0.00427718\n",
            "Iteration 736, loss = 0.00427217\n",
            "Iteration 737, loss = 0.00425398\n",
            "Iteration 738, loss = 0.00422313\n",
            "Iteration 739, loss = 0.00420254\n",
            "Iteration 740, loss = 0.00417792\n",
            "Iteration 741, loss = 0.00416044\n",
            "Iteration 742, loss = 0.00414713\n",
            "Iteration 743, loss = 0.00411890\n",
            "Iteration 744, loss = 0.00409319\n",
            "Iteration 745, loss = 0.00409857\n",
            "Iteration 746, loss = 0.00406487\n",
            "Iteration 747, loss = 0.00406875\n",
            "Iteration 748, loss = 0.00402944\n",
            "Iteration 749, loss = 0.00401706\n",
            "Iteration 750, loss = 0.00398560\n",
            "Iteration 751, loss = 0.00396518\n",
            "Iteration 752, loss = 0.00395521\n",
            "Iteration 753, loss = 0.00399413\n",
            "Iteration 754, loss = 0.00390212\n",
            "Iteration 755, loss = 0.00391912\n",
            "Iteration 756, loss = 0.00388960\n",
            "Iteration 757, loss = 0.00386038\n",
            "Iteration 758, loss = 0.00384859\n",
            "Iteration 759, loss = 0.00381920\n",
            "Iteration 760, loss = 0.00380734\n",
            "Iteration 761, loss = 0.00379374\n",
            "Iteration 762, loss = 0.00376505\n",
            "Iteration 763, loss = 0.00374503\n",
            "Iteration 764, loss = 0.00373353\n",
            "Iteration 765, loss = 0.00372853\n",
            "Iteration 766, loss = 0.00369612\n",
            "Iteration 767, loss = 0.00369351\n",
            "Iteration 768, loss = 0.00367209\n",
            "Iteration 769, loss = 0.00365352\n",
            "Iteration 770, loss = 0.00363417\n",
            "Iteration 771, loss = 0.00361755\n",
            "Iteration 772, loss = 0.00359491\n",
            "Iteration 773, loss = 0.00358881\n",
            "Iteration 774, loss = 0.00356148\n",
            "Iteration 775, loss = 0.00355488\n",
            "Iteration 776, loss = 0.00353045\n",
            "Iteration 777, loss = 0.00352166\n",
            "Iteration 778, loss = 0.00349505\n",
            "Iteration 779, loss = 0.00348293\n",
            "Iteration 780, loss = 0.00347139\n",
            "Iteration 781, loss = 0.00346898\n",
            "Iteration 782, loss = 0.00344065\n",
            "Iteration 783, loss = 0.00342167\n",
            "Iteration 784, loss = 0.00340303\n",
            "Iteration 785, loss = 0.00338895\n",
            "Iteration 786, loss = 0.00338685\n",
            "Iteration 787, loss = 0.00335816\n",
            "Iteration 788, loss = 0.00334809\n",
            "Iteration 789, loss = 0.00332296\n",
            "Iteration 790, loss = 0.00331112\n",
            "Iteration 791, loss = 0.00330504\n",
            "Iteration 792, loss = 0.00328452\n",
            "Iteration 793, loss = 0.00326998\n",
            "Iteration 794, loss = 0.00325590\n",
            "Iteration 795, loss = 0.00324329\n",
            "Iteration 796, loss = 0.00321854\n",
            "Iteration 797, loss = 0.00320512\n",
            "Iteration 798, loss = 0.00318873\n",
            "Iteration 799, loss = 0.00318559\n",
            "Iteration 800, loss = 0.00316446\n",
            "Iteration 801, loss = 0.00315460\n",
            "Iteration 802, loss = 0.00313121\n",
            "Iteration 803, loss = 0.00312342\n",
            "Iteration 804, loss = 0.00311517\n",
            "Iteration 805, loss = 0.00309405\n",
            "Iteration 806, loss = 0.00308006\n",
            "Iteration 807, loss = 0.00306774\n",
            "Iteration 808, loss = 0.00304883\n",
            "Iteration 809, loss = 0.00303306\n",
            "Iteration 810, loss = 0.00302241\n",
            "Iteration 811, loss = 0.00301258\n",
            "Iteration 812, loss = 0.00299614\n",
            "Iteration 813, loss = 0.00297877\n",
            "Iteration 814, loss = 0.00297262\n",
            "Iteration 815, loss = 0.00294915\n",
            "Iteration 816, loss = 0.00294890\n",
            "Iteration 817, loss = 0.00294345\n",
            "Iteration 818, loss = 0.00291480\n",
            "Iteration 819, loss = 0.00290692\n",
            "Iteration 820, loss = 0.00288980\n",
            "Iteration 821, loss = 0.00287482\n",
            "Iteration 822, loss = 0.00286373\n",
            "Iteration 823, loss = 0.00285053\n",
            "Iteration 824, loss = 0.00283088\n",
            "Iteration 825, loss = 0.00283067\n",
            "Iteration 826, loss = 0.00282797\n",
            "Iteration 827, loss = 0.00281704\n",
            "Iteration 828, loss = 0.00280785\n",
            "Iteration 829, loss = 0.00277749\n",
            "Iteration 830, loss = 0.00277018\n",
            "Iteration 831, loss = 0.00275185\n",
            "Iteration 832, loss = 0.00274243\n",
            "Iteration 833, loss = 0.00272556\n",
            "Iteration 834, loss = 0.00271742\n",
            "Iteration 835, loss = 0.00269840\n",
            "Iteration 836, loss = 0.00268739\n",
            "Iteration 837, loss = 0.00267761\n",
            "Iteration 838, loss = 0.00266885\n",
            "Iteration 839, loss = 0.00265563\n",
            "Iteration 840, loss = 0.00264766\n",
            "Iteration 841, loss = 0.00263022\n",
            "Iteration 842, loss = 0.00262326\n",
            "Iteration 843, loss = 0.00260557\n",
            "Iteration 844, loss = 0.00259723\n",
            "Iteration 845, loss = 0.00258287\n",
            "Iteration 846, loss = 0.00256654\n",
            "Iteration 847, loss = 0.00256238\n",
            "Iteration 848, loss = 0.00254912\n",
            "Iteration 849, loss = 0.00254183\n",
            "Iteration 850, loss = 0.00253415\n",
            "Iteration 851, loss = 0.00252313\n",
            "Iteration 852, loss = 0.00251040\n",
            "Iteration 853, loss = 0.00249491\n",
            "Iteration 854, loss = 0.00249162\n",
            "Iteration 855, loss = 0.00248088\n",
            "Iteration 856, loss = 0.00246539\n",
            "Iteration 857, loss = 0.00245197\n",
            "Iteration 858, loss = 0.00244410\n",
            "Iteration 859, loss = 0.00242840\n",
            "Iteration 860, loss = 0.00242672\n",
            "Iteration 861, loss = 0.00241644\n",
            "Iteration 862, loss = 0.00238836\n",
            "Iteration 863, loss = 0.00241217\n",
            "Iteration 864, loss = 0.00238117\n",
            "Iteration 865, loss = 0.00237487\n",
            "Iteration 866, loss = 0.00235789\n",
            "Iteration 867, loss = 0.00235161\n",
            "Iteration 868, loss = 0.00233413\n",
            "Iteration 869, loss = 0.00232859\n",
            "Iteration 870, loss = 0.00232884\n",
            "Iteration 871, loss = 0.00230562\n",
            "Iteration 872, loss = 0.00229865\n",
            "Iteration 873, loss = 0.00229280\n",
            "Iteration 874, loss = 0.00227908\n",
            "Iteration 875, loss = 0.00226688\n",
            "Iteration 876, loss = 0.00225911\n",
            "Iteration 877, loss = 0.00225853\n",
            "Iteration 878, loss = 0.00223183\n",
            "Iteration 879, loss = 0.00223271\n",
            "Iteration 880, loss = 0.00221783\n",
            "Iteration 881, loss = 0.00221020\n",
            "Iteration 882, loss = 0.00221141\n",
            "Iteration 883, loss = 0.00220054\n",
            "Iteration 884, loss = 0.00218763\n",
            "Iteration 885, loss = 0.00216931\n",
            "Iteration 886, loss = 0.00216205\n",
            "Iteration 887, loss = 0.00215198\n",
            "Iteration 888, loss = 0.00214879\n",
            "Iteration 889, loss = 0.00213760\n",
            "Iteration 890, loss = 0.00212177\n",
            "Iteration 891, loss = 0.00212508\n",
            "Iteration 892, loss = 0.00210424\n",
            "Iteration 893, loss = 0.00211051\n",
            "Iteration 894, loss = 0.00208812\n",
            "Iteration 895, loss = 0.00207836\n",
            "Iteration 896, loss = 0.00206818\n",
            "Iteration 897, loss = 0.00206912\n",
            "Iteration 898, loss = 0.00205131\n",
            "Iteration 899, loss = 0.00204676\n",
            "Iteration 900, loss = 0.00203067\n",
            "Iteration 901, loss = 0.00202222\n",
            "Iteration 902, loss = 0.00201324\n",
            "Iteration 903, loss = 0.00200320\n",
            "Iteration 904, loss = 0.00200502\n",
            "Iteration 905, loss = 0.00199353\n",
            "Iteration 906, loss = 0.00199039\n",
            "Iteration 907, loss = 0.00197333\n",
            "Iteration 908, loss = 0.00196796\n",
            "Iteration 909, loss = 0.00195460\n",
            "Iteration 910, loss = 0.00194840\n",
            "Iteration 911, loss = 0.00194057\n",
            "Iteration 912, loss = 0.00193237\n",
            "Iteration 913, loss = 0.00192839\n",
            "Iteration 914, loss = 0.00192005\n",
            "Iteration 915, loss = 0.00191261\n",
            "Iteration 916, loss = 0.00190618\n",
            "Iteration 917, loss = 0.00189382\n",
            "Iteration 918, loss = 0.00188499\n",
            "Iteration 919, loss = 0.00187393\n",
            "Iteration 920, loss = 0.00187458\n",
            "Iteration 921, loss = 0.00186044\n",
            "Iteration 922, loss = 0.00185479\n",
            "Iteration 923, loss = 0.00184500\n",
            "Iteration 924, loss = 0.00183951\n",
            "Iteration 925, loss = 0.00183135\n",
            "Iteration 926, loss = 0.00182120\n",
            "Iteration 927, loss = 0.00181447\n",
            "Iteration 928, loss = 0.00180657\n",
            "Iteration 929, loss = 0.00179881\n",
            "Iteration 930, loss = 0.00179398\n",
            "Iteration 931, loss = 0.00178276\n",
            "Iteration 932, loss = 0.00177530\n",
            "Iteration 933, loss = 0.00176918\n",
            "Iteration 934, loss = 0.00175947\n",
            "Iteration 935, loss = 0.00175259\n",
            "Iteration 936, loss = 0.00174681\n",
            "Iteration 937, loss = 0.00174557\n",
            "Iteration 938, loss = 0.00173239\n",
            "Iteration 939, loss = 0.00172543\n",
            "Iteration 940, loss = 0.00171664\n",
            "Iteration 941, loss = 0.00170711\n",
            "Iteration 942, loss = 0.00170622\n",
            "Iteration 943, loss = 0.00169615\n",
            "Iteration 944, loss = 0.00169027\n",
            "Iteration 945, loss = 0.00168144\n",
            "Iteration 946, loss = 0.00167784\n",
            "Iteration 947, loss = 0.00167084\n",
            "Iteration 948, loss = 0.00166187\n",
            "Iteration 949, loss = 0.00165604\n",
            "Iteration 950, loss = 0.00164680\n",
            "Iteration 951, loss = 0.00164039\n",
            "Iteration 952, loss = 0.00163487\n",
            "Iteration 953, loss = 0.00162656\n",
            "Iteration 954, loss = 0.00162299\n",
            "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.67115180\n",
            "Iteration 2, loss = 0.53207824\n",
            "Iteration 3, loss = 0.45629228\n",
            "Iteration 4, loss = 0.41904427\n",
            "Iteration 5, loss = 0.39828287\n",
            "Iteration 6, loss = 0.38487343\n",
            "Iteration 7, loss = 0.37527007\n",
            "Iteration 8, loss = 0.36696515\n",
            "Iteration 9, loss = 0.36057240\n",
            "Iteration 10, loss = 0.35465645\n",
            "Iteration 11, loss = 0.34996680\n",
            "Iteration 12, loss = 0.34556369\n",
            "Iteration 13, loss = 0.34126880\n",
            "Iteration 14, loss = 0.33761414\n",
            "Iteration 15, loss = 0.33385082\n",
            "Iteration 16, loss = 0.33044726\n",
            "Iteration 17, loss = 0.32763499\n",
            "Iteration 18, loss = 0.32457393\n",
            "Iteration 19, loss = 0.32190435\n",
            "Iteration 20, loss = 0.31916354\n",
            "Iteration 21, loss = 0.31643416\n",
            "Iteration 22, loss = 0.31401813\n",
            "Iteration 23, loss = 0.31154368\n",
            "Iteration 24, loss = 0.30886033\n",
            "Iteration 25, loss = 0.30609108\n",
            "Iteration 26, loss = 0.30379318\n",
            "Iteration 27, loss = 0.30198874\n",
            "Iteration 28, loss = 0.29961181\n",
            "Iteration 29, loss = 0.29675506\n",
            "Iteration 30, loss = 0.29487854\n",
            "Iteration 31, loss = 0.29230900\n",
            "Iteration 32, loss = 0.29069621\n",
            "Iteration 33, loss = 0.28823202\n",
            "Iteration 34, loss = 0.28662220\n",
            "Iteration 35, loss = 0.28358054\n",
            "Iteration 36, loss = 0.28246384\n",
            "Iteration 37, loss = 0.28078443\n",
            "Iteration 38, loss = 0.27790346\n",
            "Iteration 39, loss = 0.27599575\n",
            "Iteration 40, loss = 0.27443038\n",
            "Iteration 41, loss = 0.27183500\n",
            "Iteration 42, loss = 0.27031260\n",
            "Iteration 43, loss = 0.26812429\n",
            "Iteration 44, loss = 0.26606522\n",
            "Iteration 45, loss = 0.26447859\n",
            "Iteration 46, loss = 0.26256047\n",
            "Iteration 47, loss = 0.26045698\n",
            "Iteration 48, loss = 0.25883451\n",
            "Iteration 49, loss = 0.25687015\n",
            "Iteration 50, loss = 0.25568294\n",
            "Iteration 51, loss = 0.25324887\n",
            "Iteration 52, loss = 0.25114975\n",
            "Iteration 53, loss = 0.24953877\n",
            "Iteration 54, loss = 0.24803153\n",
            "Iteration 55, loss = 0.24591420\n",
            "Iteration 56, loss = 0.24468003\n",
            "Iteration 57, loss = 0.24318515\n",
            "Iteration 58, loss = 0.24132678\n",
            "Iteration 59, loss = 0.23964042\n",
            "Iteration 60, loss = 0.23824078\n",
            "Iteration 61, loss = 0.23676857\n",
            "Iteration 62, loss = 0.23523262\n",
            "Iteration 63, loss = 0.23306034\n",
            "Iteration 64, loss = 0.23168184\n",
            "Iteration 65, loss = 0.23071573\n",
            "Iteration 66, loss = 0.22938981\n",
            "Iteration 67, loss = 0.22708076\n",
            "Iteration 68, loss = 0.22572491\n",
            "Iteration 69, loss = 0.22462512\n",
            "Iteration 70, loss = 0.22318713\n",
            "Iteration 71, loss = 0.22089984\n",
            "Iteration 72, loss = 0.21961792\n",
            "Iteration 73, loss = 0.21848172\n",
            "Iteration 74, loss = 0.21699934\n",
            "Iteration 75, loss = 0.21552497\n",
            "Iteration 76, loss = 0.21410618\n",
            "Iteration 77, loss = 0.21289300\n",
            "Iteration 78, loss = 0.21134787\n",
            "Iteration 79, loss = 0.20983992\n",
            "Iteration 80, loss = 0.20854286\n",
            "Iteration 81, loss = 0.20729285\n",
            "Iteration 82, loss = 0.20589482\n",
            "Iteration 83, loss = 0.20486801\n",
            "Iteration 84, loss = 0.20374022\n",
            "Iteration 85, loss = 0.20175057\n",
            "Iteration 86, loss = 0.20099935\n",
            "Iteration 87, loss = 0.19974198\n",
            "Iteration 88, loss = 0.19857624\n",
            "Iteration 89, loss = 0.19741495\n",
            "Iteration 90, loss = 0.19701602\n",
            "Iteration 91, loss = 0.19559258\n",
            "Iteration 92, loss = 0.19422004\n",
            "Iteration 93, loss = 0.19227144\n",
            "Iteration 94, loss = 0.19098625\n",
            "Iteration 95, loss = 0.18988693\n",
            "Iteration 96, loss = 0.18927192\n",
            "Iteration 97, loss = 0.18791936\n",
            "Iteration 98, loss = 0.18668432\n",
            "Iteration 99, loss = 0.18544652\n",
            "Iteration 100, loss = 0.18492376\n",
            "Iteration 101, loss = 0.18341452\n",
            "Iteration 102, loss = 0.18284770\n",
            "Iteration 103, loss = 0.18093980\n",
            "Iteration 104, loss = 0.18002463\n",
            "Iteration 105, loss = 0.17875834\n",
            "Iteration 106, loss = 0.17737084\n",
            "Iteration 107, loss = 0.17688272\n",
            "Iteration 108, loss = 0.17591812\n",
            "Iteration 109, loss = 0.17527884\n",
            "Iteration 110, loss = 0.17251205\n",
            "Iteration 111, loss = 0.17210189\n",
            "Iteration 112, loss = 0.17065804\n",
            "Iteration 113, loss = 0.16968257\n",
            "Iteration 114, loss = 0.16831300\n",
            "Iteration 115, loss = 0.16744989\n",
            "Iteration 116, loss = 0.16623201\n",
            "Iteration 117, loss = 0.16513362\n",
            "Iteration 118, loss = 0.16452787\n",
            "Iteration 119, loss = 0.16345748\n",
            "Iteration 120, loss = 0.16220339\n",
            "Iteration 121, loss = 0.16084954\n",
            "Iteration 122, loss = 0.16086446\n",
            "Iteration 123, loss = 0.15898863\n",
            "Iteration 124, loss = 0.15805183\n",
            "Iteration 125, loss = 0.15774745\n",
            "Iteration 126, loss = 0.15653151\n",
            "Iteration 127, loss = 0.15557723\n",
            "Iteration 128, loss = 0.15429982\n",
            "Iteration 129, loss = 0.15325970\n",
            "Iteration 130, loss = 0.15280850\n",
            "Iteration 131, loss = 0.15216947\n",
            "Iteration 132, loss = 0.15011250\n",
            "Iteration 133, loss = 0.14924060\n",
            "Iteration 134, loss = 0.14863391\n",
            "Iteration 135, loss = 0.14767406\n",
            "Iteration 136, loss = 0.14646808\n",
            "Iteration 137, loss = 0.14619657\n",
            "Iteration 138, loss = 0.14497761\n",
            "Iteration 139, loss = 0.14404957\n",
            "Iteration 140, loss = 0.14326865\n",
            "Iteration 141, loss = 0.14194948\n",
            "Iteration 142, loss = 0.14110836\n",
            "Iteration 143, loss = 0.14050342\n",
            "Iteration 144, loss = 0.13923342\n",
            "Iteration 145, loss = 0.13819562\n",
            "Iteration 146, loss = 0.13784395\n",
            "Iteration 147, loss = 0.13650144\n",
            "Iteration 148, loss = 0.13601541\n",
            "Iteration 149, loss = 0.13445887\n",
            "Iteration 150, loss = 0.13454070\n",
            "Iteration 151, loss = 0.13479385\n",
            "Iteration 152, loss = 0.13225407\n",
            "Iteration 153, loss = 0.13209050\n",
            "Iteration 154, loss = 0.13052918\n",
            "Iteration 155, loss = 0.12994787\n",
            "Iteration 156, loss = 0.12930581\n",
            "Iteration 157, loss = 0.12782355\n",
            "Iteration 158, loss = 0.12740889\n",
            "Iteration 159, loss = 0.12696157\n",
            "Iteration 160, loss = 0.12567956\n",
            "Iteration 161, loss = 0.12477648\n",
            "Iteration 162, loss = 0.12344083\n",
            "Iteration 163, loss = 0.12306814\n",
            "Iteration 164, loss = 0.12257846\n",
            "Iteration 165, loss = 0.12169595\n",
            "Iteration 166, loss = 0.12051126\n",
            "Iteration 167, loss = 0.12012573\n",
            "Iteration 168, loss = 0.11902280\n",
            "Iteration 169, loss = 0.11861311\n",
            "Iteration 170, loss = 0.11768806\n",
            "Iteration 171, loss = 0.11749498\n",
            "Iteration 172, loss = 0.11607041\n",
            "Iteration 173, loss = 0.11540590\n",
            "Iteration 174, loss = 0.11472532\n",
            "Iteration 175, loss = 0.11401130\n",
            "Iteration 176, loss = 0.11328123\n",
            "Iteration 177, loss = 0.11266899\n",
            "Iteration 178, loss = 0.11148353\n",
            "Iteration 179, loss = 0.11133388\n",
            "Iteration 180, loss = 0.11041098\n",
            "Iteration 181, loss = 0.10956855\n",
            "Iteration 182, loss = 0.10883590\n",
            "Iteration 183, loss = 0.10790954\n",
            "Iteration 184, loss = 0.10735191\n",
            "Iteration 185, loss = 0.10655543\n",
            "Iteration 186, loss = 0.10637655\n",
            "Iteration 187, loss = 0.10527859\n",
            "Iteration 188, loss = 0.10522607\n",
            "Iteration 189, loss = 0.10412819\n",
            "Iteration 190, loss = 0.10353892\n",
            "Iteration 191, loss = 0.10336400\n",
            "Iteration 192, loss = 0.10158590\n",
            "Iteration 193, loss = 0.10145306\n",
            "Iteration 194, loss = 0.10022019\n",
            "Iteration 195, loss = 0.09966794\n",
            "Iteration 196, loss = 0.09988244\n",
            "Iteration 197, loss = 0.09881009\n",
            "Iteration 198, loss = 0.09745234\n",
            "Iteration 199, loss = 0.09731379\n",
            "Iteration 200, loss = 0.09729143\n",
            "Iteration 201, loss = 0.09553321\n",
            "Iteration 202, loss = 0.09498797\n",
            "Iteration 203, loss = 0.09462572\n",
            "Iteration 204, loss = 0.09424742\n",
            "Iteration 205, loss = 0.09327736\n",
            "Iteration 206, loss = 0.09251728\n",
            "Iteration 207, loss = 0.09196161\n",
            "Iteration 208, loss = 0.09168417\n",
            "Iteration 209, loss = 0.09098229\n",
            "Iteration 210, loss = 0.09094538\n",
            "Iteration 211, loss = 0.08969272\n",
            "Iteration 212, loss = 0.08888379\n",
            "Iteration 213, loss = 0.08846782\n",
            "Iteration 214, loss = 0.08758373\n",
            "Iteration 215, loss = 0.08689028\n",
            "Iteration 216, loss = 0.08789282\n",
            "Iteration 217, loss = 0.08583437\n",
            "Iteration 218, loss = 0.08494352\n",
            "Iteration 219, loss = 0.08462528\n",
            "Iteration 220, loss = 0.08379139\n",
            "Iteration 221, loss = 0.08345352\n",
            "Iteration 222, loss = 0.08274744\n",
            "Iteration 223, loss = 0.08245187\n",
            "Iteration 224, loss = 0.08199840\n",
            "Iteration 225, loss = 0.08162729\n",
            "Iteration 226, loss = 0.08142103\n",
            "Iteration 227, loss = 0.08156100\n",
            "Iteration 228, loss = 0.07908400\n",
            "Iteration 229, loss = 0.07908587\n",
            "Iteration 230, loss = 0.07837036\n",
            "Iteration 231, loss = 0.07810028\n",
            "Iteration 232, loss = 0.07793310\n",
            "Iteration 233, loss = 0.07713965\n",
            "Iteration 234, loss = 0.07583436\n",
            "Iteration 235, loss = 0.07566920\n",
            "Iteration 236, loss = 0.07505990\n",
            "Iteration 237, loss = 0.07437976\n",
            "Iteration 238, loss = 0.07409515\n",
            "Iteration 239, loss = 0.07369586\n",
            "Iteration 240, loss = 0.07315572\n",
            "Iteration 241, loss = 0.07335038\n",
            "Iteration 242, loss = 0.07236425\n",
            "Iteration 243, loss = 0.07230657\n",
            "Iteration 244, loss = 0.07119813\n",
            "Iteration 245, loss = 0.07001478\n",
            "Iteration 246, loss = 0.07004846\n",
            "Iteration 247, loss = 0.06932942\n",
            "Iteration 248, loss = 0.06901429\n",
            "Iteration 249, loss = 0.06867714\n",
            "Iteration 250, loss = 0.06829778\n",
            "Iteration 251, loss = 0.06783612\n",
            "Iteration 252, loss = 0.06749613\n",
            "Iteration 253, loss = 0.06689117\n",
            "Iteration 254, loss = 0.06645591\n",
            "Iteration 255, loss = 0.06560573\n",
            "Iteration 256, loss = 0.06526954\n",
            "Iteration 257, loss = 0.06540398\n",
            "Iteration 258, loss = 0.06454091\n",
            "Iteration 259, loss = 0.06363210\n",
            "Iteration 260, loss = 0.06340554\n",
            "Iteration 261, loss = 0.06318362\n",
            "Iteration 262, loss = 0.06258818\n",
            "Iteration 263, loss = 0.06244094\n",
            "Iteration 264, loss = 0.06194386\n",
            "Iteration 265, loss = 0.06146447\n",
            "Iteration 266, loss = 0.06084948\n",
            "Iteration 267, loss = 0.06038551\n",
            "Iteration 268, loss = 0.06022692\n",
            "Iteration 269, loss = 0.05971521\n",
            "Iteration 270, loss = 0.05926231\n",
            "Iteration 271, loss = 0.05876242\n",
            "Iteration 272, loss = 0.05840446\n",
            "Iteration 273, loss = 0.05818518\n",
            "Iteration 274, loss = 0.05754093\n",
            "Iteration 275, loss = 0.05717122\n",
            "Iteration 276, loss = 0.05689518\n",
            "Iteration 277, loss = 0.05624592\n",
            "Iteration 278, loss = 0.05592081\n",
            "Iteration 279, loss = 0.05559427\n",
            "Iteration 280, loss = 0.05575238\n",
            "Iteration 281, loss = 0.05530352\n",
            "Iteration 282, loss = 0.05453569\n",
            "Iteration 283, loss = 0.05415804\n",
            "Iteration 284, loss = 0.05512579\n",
            "Iteration 285, loss = 0.05362476\n",
            "Iteration 286, loss = 0.05300766\n",
            "Iteration 287, loss = 0.05292851\n",
            "Iteration 288, loss = 0.05235464\n",
            "Iteration 289, loss = 0.05228174\n",
            "Iteration 290, loss = 0.05209198\n",
            "Iteration 291, loss = 0.05156993\n",
            "Iteration 292, loss = 0.05137979\n",
            "Iteration 293, loss = 0.05090919\n",
            "Iteration 294, loss = 0.05071375\n",
            "Iteration 295, loss = 0.05004483\n",
            "Iteration 296, loss = 0.04973959\n",
            "Iteration 297, loss = 0.04907342\n",
            "Iteration 298, loss = 0.04860574\n",
            "Iteration 299, loss = 0.04872398\n",
            "Iteration 300, loss = 0.04826275\n",
            "Iteration 301, loss = 0.04768178\n",
            "Iteration 302, loss = 0.04817244\n",
            "Iteration 303, loss = 0.04771257\n",
            "Iteration 304, loss = 0.04787951\n",
            "Iteration 305, loss = 0.04680838\n",
            "Iteration 306, loss = 0.04603801\n",
            "Iteration 307, loss = 0.04611490\n",
            "Iteration 308, loss = 0.04568058\n",
            "Iteration 309, loss = 0.04552348\n",
            "Iteration 310, loss = 0.04505357\n",
            "Iteration 311, loss = 0.04464761\n",
            "Iteration 312, loss = 0.04427833\n",
            "Iteration 313, loss = 0.04416573\n",
            "Iteration 314, loss = 0.04404094\n",
            "Iteration 315, loss = 0.04363482\n",
            "Iteration 316, loss = 0.04338414\n",
            "Iteration 317, loss = 0.04275696\n",
            "Iteration 318, loss = 0.04263092\n",
            "Iteration 319, loss = 0.04255270\n",
            "Iteration 320, loss = 0.04208688\n",
            "Iteration 321, loss = 0.04188957\n",
            "Iteration 322, loss = 0.04143624\n",
            "Iteration 323, loss = 0.04137557\n",
            "Iteration 324, loss = 0.04175694\n",
            "Iteration 325, loss = 0.04073420\n",
            "Iteration 326, loss = 0.04031319\n",
            "Iteration 327, loss = 0.04029932\n",
            "Iteration 328, loss = 0.03968064\n",
            "Iteration 329, loss = 0.03975565\n",
            "Iteration 330, loss = 0.03925021\n",
            "Iteration 331, loss = 0.03927846\n",
            "Iteration 332, loss = 0.03880108\n",
            "Iteration 333, loss = 0.03857184\n",
            "Iteration 334, loss = 0.03830919\n",
            "Iteration 335, loss = 0.03795198\n",
            "Iteration 336, loss = 0.03768586\n",
            "Iteration 337, loss = 0.03806458\n",
            "Iteration 338, loss = 0.03736128\n",
            "Iteration 339, loss = 0.03693739\n",
            "Iteration 340, loss = 0.03653664\n",
            "Iteration 341, loss = 0.03638700\n",
            "Iteration 342, loss = 0.03605370\n",
            "Iteration 343, loss = 0.03612139\n",
            "Iteration 344, loss = 0.03615858\n",
            "Iteration 345, loss = 0.03532307\n",
            "Iteration 346, loss = 0.03520460\n",
            "Iteration 347, loss = 0.03496392\n",
            "Iteration 348, loss = 0.03460850\n",
            "Iteration 349, loss = 0.03464401\n",
            "Iteration 350, loss = 0.03432848\n",
            "Iteration 351, loss = 0.03398374\n",
            "Iteration 352, loss = 0.03393270\n",
            "Iteration 353, loss = 0.03332662\n",
            "Iteration 354, loss = 0.03357839\n",
            "Iteration 355, loss = 0.03299868\n",
            "Iteration 356, loss = 0.03282008\n",
            "Iteration 357, loss = 0.03271420\n",
            "Iteration 358, loss = 0.03235848\n",
            "Iteration 359, loss = 0.03258084\n",
            "Iteration 360, loss = 0.03248599\n",
            "Iteration 361, loss = 0.03215804\n",
            "Iteration 362, loss = 0.03183659\n",
            "Iteration 363, loss = 0.03098849\n",
            "Iteration 364, loss = 0.03089644\n",
            "Iteration 365, loss = 0.03064912\n",
            "Iteration 366, loss = 0.03060322\n",
            "Iteration 367, loss = 0.03035252\n",
            "Iteration 368, loss = 0.03004326\n",
            "Iteration 369, loss = 0.03022768\n",
            "Iteration 370, loss = 0.02985126\n",
            "Iteration 371, loss = 0.02952660\n",
            "Iteration 372, loss = 0.02945493\n",
            "Iteration 373, loss = 0.02927279\n",
            "Iteration 374, loss = 0.02905578\n",
            "Iteration 375, loss = 0.02858022\n",
            "Iteration 376, loss = 0.02842558\n",
            "Iteration 377, loss = 0.02820927\n",
            "Iteration 378, loss = 0.02801115\n",
            "Iteration 379, loss = 0.02803761\n",
            "Iteration 380, loss = 0.02753501\n",
            "Iteration 381, loss = 0.02743844\n",
            "Iteration 382, loss = 0.02710417\n",
            "Iteration 383, loss = 0.02700038\n",
            "Iteration 384, loss = 0.02696400\n",
            "Iteration 385, loss = 0.02663492\n",
            "Iteration 386, loss = 0.02645294\n",
            "Iteration 387, loss = 0.02638644\n",
            "Iteration 388, loss = 0.02614733\n",
            "Iteration 389, loss = 0.02610930\n",
            "Iteration 390, loss = 0.02563351\n",
            "Iteration 391, loss = 0.02566353\n",
            "Iteration 392, loss = 0.02532479\n",
            "Iteration 393, loss = 0.02524347\n",
            "Iteration 394, loss = 0.02522344\n",
            "Iteration 395, loss = 0.02493266\n",
            "Iteration 396, loss = 0.02473698\n",
            "Iteration 397, loss = 0.02451268\n",
            "Iteration 398, loss = 0.02442146\n",
            "Iteration 399, loss = 0.02419666\n",
            "Iteration 400, loss = 0.02418385\n",
            "Iteration 401, loss = 0.02387657\n",
            "Iteration 402, loss = 0.02382630\n",
            "Iteration 403, loss = 0.02351288\n",
            "Iteration 404, loss = 0.02325031\n",
            "Iteration 405, loss = 0.02323858\n",
            "Iteration 406, loss = 0.02308612\n",
            "Iteration 407, loss = 0.02284606\n",
            "Iteration 408, loss = 0.02269237\n",
            "Iteration 409, loss = 0.02268684\n",
            "Iteration 410, loss = 0.02241947\n",
            "Iteration 411, loss = 0.02229490\n",
            "Iteration 412, loss = 0.02205692\n",
            "Iteration 413, loss = 0.02198252\n",
            "Iteration 414, loss = 0.02199562\n",
            "Iteration 415, loss = 0.02211126\n",
            "Iteration 416, loss = 0.02156473\n",
            "Iteration 417, loss = 0.02147583\n",
            "Iteration 418, loss = 0.02124497\n",
            "Iteration 419, loss = 0.02111298\n",
            "Iteration 420, loss = 0.02094463\n",
            "Iteration 421, loss = 0.02095515\n",
            "Iteration 422, loss = 0.02094396\n",
            "Iteration 423, loss = 0.02048086\n",
            "Iteration 424, loss = 0.02021104\n",
            "Iteration 425, loss = 0.02021471\n",
            "Iteration 426, loss = 0.02001334\n",
            "Iteration 427, loss = 0.02006912\n",
            "Iteration 428, loss = 0.01982737\n",
            "Iteration 429, loss = 0.01966372\n",
            "Iteration 430, loss = 0.01970563\n",
            "Iteration 431, loss = 0.01944932\n",
            "Iteration 432, loss = 0.01935797\n",
            "Iteration 433, loss = 0.01922251\n",
            "Iteration 434, loss = 0.01901679\n",
            "Iteration 435, loss = 0.01934153\n",
            "Iteration 436, loss = 0.01897466\n",
            "Iteration 437, loss = 0.01865489\n",
            "Iteration 438, loss = 0.01850654\n",
            "Iteration 439, loss = 0.01837674\n",
            "Iteration 440, loss = 0.01807689\n",
            "Iteration 441, loss = 0.01825183\n",
            "Iteration 442, loss = 0.01815468\n",
            "Iteration 443, loss = 0.01793965\n",
            "Iteration 444, loss = 0.01779400\n",
            "Iteration 445, loss = 0.01784392\n",
            "Iteration 446, loss = 0.01741217\n",
            "Iteration 447, loss = 0.01737935\n",
            "Iteration 448, loss = 0.01718134\n",
            "Iteration 449, loss = 0.01723432\n",
            "Iteration 450, loss = 0.01739106\n",
            "Iteration 451, loss = 0.01731817\n",
            "Iteration 452, loss = 0.01672854\n",
            "Iteration 453, loss = 0.01678864\n",
            "Iteration 454, loss = 0.01670629\n",
            "Iteration 455, loss = 0.01646858\n",
            "Iteration 456, loss = 0.01627160\n",
            "Iteration 457, loss = 0.01630083\n",
            "Iteration 458, loss = 0.01608157\n",
            "Iteration 459, loss = 0.01594177\n",
            "Iteration 460, loss = 0.01585901\n",
            "Iteration 461, loss = 0.01573596\n",
            "Iteration 462, loss = 0.01580177\n",
            "Iteration 463, loss = 0.01562141\n",
            "Iteration 464, loss = 0.01547731\n",
            "Iteration 465, loss = 0.01531301\n",
            "Iteration 466, loss = 0.01525975\n",
            "Iteration 467, loss = 0.01522324\n",
            "Iteration 468, loss = 0.01525936\n",
            "Iteration 469, loss = 0.01506194\n",
            "Iteration 470, loss = 0.01496182\n",
            "Iteration 471, loss = 0.01479967\n",
            "Iteration 472, loss = 0.01457376\n",
            "Iteration 473, loss = 0.01451233\n",
            "Iteration 474, loss = 0.01445303\n",
            "Iteration 475, loss = 0.01457231\n",
            "Iteration 476, loss = 0.01446623\n",
            "Iteration 477, loss = 0.01410199\n",
            "Iteration 478, loss = 0.01402454\n",
            "Iteration 479, loss = 0.01390112\n",
            "Iteration 480, loss = 0.01382432\n",
            "Iteration 481, loss = 0.01375107\n",
            "Iteration 482, loss = 0.01374343\n",
            "Iteration 483, loss = 0.01369447\n",
            "Iteration 484, loss = 0.01344757\n",
            "Iteration 485, loss = 0.01337263\n",
            "Iteration 486, loss = 0.01325716\n",
            "Iteration 487, loss = 0.01323580\n",
            "Iteration 488, loss = 0.01309997\n",
            "Iteration 489, loss = 0.01314080\n",
            "Iteration 490, loss = 0.01308496\n",
            "Iteration 491, loss = 0.01294830\n",
            "Iteration 492, loss = 0.01278548\n",
            "Iteration 493, loss = 0.01278816\n",
            "Iteration 494, loss = 0.01262054\n",
            "Iteration 495, loss = 0.01280488\n",
            "Iteration 496, loss = 0.01247966\n",
            "Iteration 497, loss = 0.01244102\n",
            "Iteration 498, loss = 0.01233122\n",
            "Iteration 499, loss = 0.01219798\n",
            "Iteration 500, loss = 0.01216850\n",
            "Iteration 501, loss = 0.01210412\n",
            "Iteration 502, loss = 0.01203851\n",
            "Iteration 503, loss = 0.01198281\n",
            "Iteration 504, loss = 0.01190074\n",
            "Iteration 505, loss = 0.01184844\n",
            "Iteration 506, loss = 0.01162882\n",
            "Iteration 507, loss = 0.01161064\n",
            "Iteration 508, loss = 0.01150862\n",
            "Iteration 509, loss = 0.01144905\n",
            "Iteration 510, loss = 0.01133771\n",
            "Iteration 511, loss = 0.01124829\n",
            "Iteration 512, loss = 0.01118412\n",
            "Iteration 513, loss = 0.01115989\n",
            "Iteration 514, loss = 0.01102822\n",
            "Iteration 515, loss = 0.01100691\n",
            "Iteration 516, loss = 0.01097666\n",
            "Iteration 517, loss = 0.01091142\n",
            "Iteration 518, loss = 0.01096918\n",
            "Iteration 519, loss = 0.01116148\n",
            "Iteration 520, loss = 0.01081123\n",
            "Iteration 521, loss = 0.01060819\n",
            "Iteration 522, loss = 0.01054450\n",
            "Iteration 523, loss = 0.01044305\n",
            "Iteration 524, loss = 0.01033895\n",
            "Iteration 525, loss = 0.01034328\n",
            "Iteration 526, loss = 0.01027854\n",
            "Iteration 527, loss = 0.01022781\n",
            "Iteration 528, loss = 0.01013026\n",
            "Iteration 529, loss = 0.01005891\n",
            "Iteration 530, loss = 0.01004764\n",
            "Iteration 531, loss = 0.00998026\n",
            "Iteration 532, loss = 0.00980696\n",
            "Iteration 533, loss = 0.00978734\n",
            "Iteration 534, loss = 0.00971128\n",
            "Iteration 535, loss = 0.00972794\n",
            "Iteration 536, loss = 0.00957711\n",
            "Iteration 537, loss = 0.00956731\n",
            "Iteration 538, loss = 0.00947653\n",
            "Iteration 539, loss = 0.00939199\n",
            "Iteration 540, loss = 0.00934475\n",
            "Iteration 541, loss = 0.00926273\n",
            "Iteration 542, loss = 0.00921547\n",
            "Iteration 543, loss = 0.00921098\n",
            "Iteration 544, loss = 0.00905259\n",
            "Iteration 545, loss = 0.00907036\n",
            "Iteration 546, loss = 0.00904232\n",
            "Iteration 547, loss = 0.00897764\n",
            "Iteration 548, loss = 0.00889234\n",
            "Iteration 549, loss = 0.00887207\n",
            "Iteration 550, loss = 0.00877709\n",
            "Iteration 551, loss = 0.00870458\n",
            "Iteration 552, loss = 0.00867372\n",
            "Iteration 553, loss = 0.00867875\n",
            "Iteration 554, loss = 0.00855062\n",
            "Iteration 555, loss = 0.00850644\n",
            "Iteration 556, loss = 0.00844307\n",
            "Iteration 557, loss = 0.00838176\n",
            "Iteration 558, loss = 0.00835961\n",
            "Iteration 559, loss = 0.00832438\n",
            "Iteration 560, loss = 0.00821790\n",
            "Iteration 561, loss = 0.00817946\n",
            "Iteration 562, loss = 0.00816120\n",
            "Iteration 563, loss = 0.00808049\n",
            "Iteration 564, loss = 0.00812392\n",
            "Iteration 565, loss = 0.00807682\n",
            "Iteration 566, loss = 0.00793620\n",
            "Iteration 567, loss = 0.00789443\n",
            "Iteration 568, loss = 0.00780956\n",
            "Iteration 569, loss = 0.00779167\n",
            "Iteration 570, loss = 0.00769061\n",
            "Iteration 571, loss = 0.00764051\n",
            "Iteration 572, loss = 0.00761043\n",
            "Iteration 573, loss = 0.00759641\n",
            "Iteration 574, loss = 0.00753960\n",
            "Iteration 575, loss = 0.00753063\n",
            "Iteration 576, loss = 0.00743744\n",
            "Iteration 577, loss = 0.00740853\n",
            "Iteration 578, loss = 0.00738732\n",
            "Iteration 579, loss = 0.00733526\n",
            "Iteration 580, loss = 0.00737034\n",
            "Iteration 581, loss = 0.00729152\n",
            "Iteration 582, loss = 0.00725483\n",
            "Iteration 583, loss = 0.00713221\n",
            "Iteration 584, loss = 0.00709632\n",
            "Iteration 585, loss = 0.00705184\n",
            "Iteration 586, loss = 0.00701480\n",
            "Iteration 587, loss = 0.00694868\n",
            "Iteration 588, loss = 0.00695041\n",
            "Iteration 589, loss = 0.00696329\n",
            "Iteration 590, loss = 0.00686396\n",
            "Iteration 591, loss = 0.00678256\n",
            "Iteration 592, loss = 0.00680116\n",
            "Iteration 593, loss = 0.00670060\n",
            "Iteration 594, loss = 0.00666557\n",
            "Iteration 595, loss = 0.00662180\n",
            "Iteration 596, loss = 0.00659640\n",
            "Iteration 597, loss = 0.00654054\n",
            "Iteration 598, loss = 0.00653762\n",
            "Iteration 599, loss = 0.00646857\n",
            "Iteration 600, loss = 0.00642449\n",
            "Iteration 601, loss = 0.00637754\n",
            "Iteration 602, loss = 0.00631858\n",
            "Iteration 603, loss = 0.00631544\n",
            "Iteration 604, loss = 0.00644365\n",
            "Iteration 605, loss = 0.00626439\n",
            "Iteration 606, loss = 0.00618464\n",
            "Iteration 607, loss = 0.00623005\n",
            "Iteration 608, loss = 0.00619951\n",
            "Iteration 609, loss = 0.00607677\n",
            "Iteration 610, loss = 0.00606626\n",
            "Iteration 611, loss = 0.00601138\n",
            "Iteration 612, loss = 0.00600608\n",
            "Iteration 613, loss = 0.00589603\n",
            "Iteration 614, loss = 0.00590399\n",
            "Iteration 615, loss = 0.00587736\n",
            "Iteration 616, loss = 0.00588705\n",
            "Iteration 617, loss = 0.00586981\n",
            "Iteration 618, loss = 0.00583292\n",
            "Iteration 619, loss = 0.00569580\n",
            "Iteration 620, loss = 0.00573507\n",
            "Iteration 621, loss = 0.00575354\n",
            "Iteration 622, loss = 0.00568022\n",
            "Iteration 623, loss = 0.00554253\n",
            "Iteration 624, loss = 0.00551474\n",
            "Iteration 625, loss = 0.00550742\n",
            "Iteration 626, loss = 0.00548699\n",
            "Iteration 627, loss = 0.00545764\n",
            "Iteration 628, loss = 0.00552730\n",
            "Iteration 629, loss = 0.00535743\n",
            "Iteration 630, loss = 0.00538410\n",
            "Iteration 631, loss = 0.00536470\n",
            "Iteration 632, loss = 0.00531427\n",
            "Iteration 633, loss = 0.00524987\n",
            "Iteration 634, loss = 0.00524834\n",
            "Iteration 635, loss = 0.00522878\n",
            "Iteration 636, loss = 0.00514397\n",
            "Iteration 637, loss = 0.00510906\n",
            "Iteration 638, loss = 0.00509382\n",
            "Iteration 639, loss = 0.00503704\n",
            "Iteration 640, loss = 0.00503406\n",
            "Iteration 641, loss = 0.00500481\n",
            "Iteration 642, loss = 0.00503806\n",
            "Iteration 643, loss = 0.00496369\n",
            "Iteration 644, loss = 0.00501272\n",
            "Iteration 645, loss = 0.00493882\n",
            "Iteration 646, loss = 0.00483172\n",
            "Iteration 647, loss = 0.00479764\n",
            "Iteration 648, loss = 0.00480131\n",
            "Iteration 649, loss = 0.00477180\n",
            "Iteration 650, loss = 0.00474036\n",
            "Iteration 651, loss = 0.00473900\n",
            "Iteration 652, loss = 0.00467936\n",
            "Iteration 653, loss = 0.00464251\n",
            "Iteration 654, loss = 0.00461653\n",
            "Iteration 655, loss = 0.00458784\n",
            "Iteration 656, loss = 0.00455767\n",
            "Iteration 657, loss = 0.00456576\n",
            "Iteration 658, loss = 0.00452196\n",
            "Iteration 659, loss = 0.00448805\n",
            "Iteration 660, loss = 0.00449452\n",
            "Iteration 661, loss = 0.00445813\n",
            "Iteration 662, loss = 0.00442804\n",
            "Iteration 663, loss = 0.00447478\n",
            "Iteration 664, loss = 0.00442798\n",
            "Iteration 665, loss = 0.00431237\n",
            "Iteration 666, loss = 0.00435747\n",
            "Iteration 667, loss = 0.00429586\n",
            "Iteration 668, loss = 0.00424558\n",
            "Iteration 669, loss = 0.00423712\n",
            "Iteration 670, loss = 0.00422173\n",
            "Iteration 671, loss = 0.00418872\n",
            "Iteration 672, loss = 0.00413436\n",
            "Iteration 673, loss = 0.00411366\n",
            "Iteration 674, loss = 0.00410053\n",
            "Iteration 675, loss = 0.00409902\n",
            "Iteration 676, loss = 0.00402929\n",
            "Iteration 677, loss = 0.00401606\n",
            "Iteration 678, loss = 0.00401323\n",
            "Iteration 679, loss = 0.00397229\n",
            "Iteration 680, loss = 0.00395471\n",
            "Iteration 681, loss = 0.00393267\n",
            "Iteration 682, loss = 0.00393209\n",
            "Iteration 683, loss = 0.00388043\n",
            "Iteration 684, loss = 0.00384490\n",
            "Iteration 685, loss = 0.00382451\n",
            "Iteration 686, loss = 0.00386332\n",
            "Iteration 687, loss = 0.00382999\n",
            "Iteration 688, loss = 0.00378990\n",
            "Iteration 689, loss = 0.00375746\n",
            "Iteration 690, loss = 0.00372955\n",
            "Iteration 691, loss = 0.00369268\n",
            "Iteration 692, loss = 0.00368396\n",
            "Iteration 693, loss = 0.00369766\n",
            "Iteration 694, loss = 0.00367739\n",
            "Iteration 695, loss = 0.00365172\n",
            "Iteration 696, loss = 0.00363522\n",
            "Iteration 697, loss = 0.00357743\n",
            "Iteration 698, loss = 0.00356951\n",
            "Iteration 699, loss = 0.00353162\n",
            "Iteration 700, loss = 0.00354203\n",
            "Iteration 701, loss = 0.00352787\n",
            "Iteration 702, loss = 0.00348951\n",
            "Iteration 703, loss = 0.00344410\n",
            "Iteration 704, loss = 0.00345419\n",
            "Iteration 705, loss = 0.00341418\n",
            "Iteration 706, loss = 0.00342149\n",
            "Iteration 707, loss = 0.00344044\n",
            "Iteration 708, loss = 0.00337488\n",
            "Iteration 709, loss = 0.00333825\n",
            "Iteration 710, loss = 0.00330230\n",
            "Iteration 711, loss = 0.00330481\n",
            "Iteration 712, loss = 0.00330384\n",
            "Iteration 713, loss = 0.00326011\n",
            "Iteration 714, loss = 0.00324552\n",
            "Iteration 715, loss = 0.00322651\n",
            "Iteration 716, loss = 0.00319604\n",
            "Iteration 717, loss = 0.00317338\n",
            "Iteration 718, loss = 0.00315300\n",
            "Iteration 719, loss = 0.00312650\n",
            "Iteration 720, loss = 0.00311993\n",
            "Iteration 721, loss = 0.00310383\n",
            "Iteration 722, loss = 0.00311069\n",
            "Iteration 723, loss = 0.00308394\n",
            "Iteration 724, loss = 0.00312854\n",
            "Iteration 725, loss = 0.00311975\n",
            "Iteration 726, loss = 0.00304413\n",
            "Iteration 727, loss = 0.00301763\n",
            "Iteration 728, loss = 0.00299442\n",
            "Iteration 729, loss = 0.00297343\n",
            "Iteration 730, loss = 0.00295438\n",
            "Iteration 731, loss = 0.00296788\n",
            "Iteration 732, loss = 0.00293612\n",
            "Iteration 733, loss = 0.00290142\n",
            "Iteration 734, loss = 0.00288517\n",
            "Iteration 735, loss = 0.00285863\n",
            "Iteration 736, loss = 0.00283957\n",
            "Iteration 737, loss = 0.00283588\n",
            "Iteration 738, loss = 0.00282574\n",
            "Iteration 739, loss = 0.00284683\n",
            "Iteration 740, loss = 0.00280396\n",
            "Iteration 741, loss = 0.00278167\n",
            "Iteration 742, loss = 0.00277371\n",
            "Iteration 743, loss = 0.00275479\n",
            "Iteration 744, loss = 0.00274026\n",
            "Iteration 745, loss = 0.00272071\n",
            "Iteration 746, loss = 0.00268683\n",
            "Iteration 747, loss = 0.00270567\n",
            "Iteration 748, loss = 0.00271060\n",
            "Iteration 749, loss = 0.00264856\n",
            "Iteration 750, loss = 0.00264276\n",
            "Iteration 751, loss = 0.00262243\n",
            "Iteration 752, loss = 0.00259372\n",
            "Iteration 753, loss = 0.00258569\n",
            "Iteration 754, loss = 0.00257283\n",
            "Iteration 755, loss = 0.00257400\n",
            "Iteration 756, loss = 0.00254666\n",
            "Iteration 757, loss = 0.00255347\n",
            "Iteration 758, loss = 0.00252346\n",
            "Iteration 759, loss = 0.00250769\n",
            "Iteration 760, loss = 0.00250283\n",
            "Iteration 761, loss = 0.00248966\n",
            "Iteration 762, loss = 0.00247464\n",
            "Iteration 763, loss = 0.00244106\n",
            "Iteration 764, loss = 0.00244103\n",
            "Iteration 765, loss = 0.00247419\n",
            "Iteration 766, loss = 0.00241306\n",
            "Iteration 767, loss = 0.00240886\n",
            "Iteration 768, loss = 0.00239087\n",
            "Iteration 769, loss = 0.00237997\n",
            "Iteration 770, loss = 0.00237579\n",
            "Iteration 771, loss = 0.00235992\n",
            "Iteration 772, loss = 0.00233987\n",
            "Iteration 773, loss = 0.00232948\n",
            "Iteration 774, loss = 0.00230547\n",
            "Iteration 775, loss = 0.00228261\n",
            "Iteration 776, loss = 0.00227157\n",
            "Iteration 777, loss = 0.00225811\n",
            "Iteration 778, loss = 0.00224735\n",
            "Iteration 779, loss = 0.00224937\n",
            "Iteration 780, loss = 0.00222675\n",
            "Iteration 781, loss = 0.00220271\n",
            "Iteration 782, loss = 0.00221258\n",
            "Iteration 783, loss = 0.00220992\n",
            "Iteration 784, loss = 0.00219736\n",
            "Iteration 785, loss = 0.00216908\n",
            "Iteration 786, loss = 0.00214446\n",
            "Iteration 787, loss = 0.00213472\n",
            "Iteration 788, loss = 0.00213964\n",
            "Iteration 789, loss = 0.00211767\n",
            "Iteration 790, loss = 0.00210335\n",
            "Iteration 791, loss = 0.00209889\n",
            "Iteration 792, loss = 0.00211657\n",
            "Iteration 793, loss = 0.00210026\n",
            "Iteration 794, loss = 0.00205534\n",
            "Iteration 795, loss = 0.00206505\n",
            "Iteration 796, loss = 0.00205839\n",
            "Iteration 797, loss = 0.00202959\n",
            "Iteration 798, loss = 0.00200691\n",
            "Iteration 799, loss = 0.00199894\n",
            "Iteration 800, loss = 0.00200472\n",
            "Iteration 801, loss = 0.00198772\n",
            "Iteration 802, loss = 0.00198101\n",
            "Iteration 803, loss = 0.00196989\n",
            "Iteration 804, loss = 0.00195568\n",
            "Iteration 805, loss = 0.00193771\n",
            "Iteration 806, loss = 0.00193161\n",
            "Iteration 807, loss = 0.00191364\n",
            "Iteration 808, loss = 0.00191466\n",
            "Iteration 809, loss = 0.00190574\n",
            "Iteration 810, loss = 0.00188878\n",
            "Iteration 811, loss = 0.00187566\n",
            "Iteration 812, loss = 0.00188064\n",
            "Iteration 813, loss = 0.00188301\n",
            "Iteration 814, loss = 0.00184840\n",
            "Iteration 815, loss = 0.00184930\n",
            "Iteration 816, loss = 0.00182306\n",
            "Iteration 817, loss = 0.00181448\n",
            "Iteration 818, loss = 0.00179877\n",
            "Iteration 819, loss = 0.00179237\n",
            "Iteration 820, loss = 0.00177754\n",
            "Iteration 821, loss = 0.00177199\n",
            "Iteration 822, loss = 0.00177034\n",
            "Iteration 823, loss = 0.00175029\n",
            "Iteration 824, loss = 0.00174869\n",
            "Iteration 825, loss = 0.00173731\n",
            "Iteration 826, loss = 0.00173558\n",
            "Iteration 827, loss = 0.00171854\n",
            "Iteration 828, loss = 0.00171303\n",
            "Iteration 829, loss = 0.00171259\n",
            "Iteration 830, loss = 0.00170695\n",
            "Iteration 831, loss = 0.00170830\n",
            "Iteration 832, loss = 0.00167865\n",
            "Iteration 833, loss = 0.00167249\n",
            "Iteration 834, loss = 0.00166306\n",
            "Iteration 835, loss = 0.00164961\n",
            "Iteration 836, loss = 0.00165139\n",
            "Iteration 837, loss = 0.00163907\n",
            "Iteration 838, loss = 0.00162283\n",
            "Iteration 839, loss = 0.00162257\n",
            "Iteration 840, loss = 0.00160933\n",
            "Iteration 841, loss = 0.00159082\n",
            "Iteration 842, loss = 0.00158772\n",
            "Iteration 843, loss = 0.00157614\n",
            "Iteration 844, loss = 0.00156898\n",
            "Iteration 845, loss = 0.00156205\n",
            "Iteration 846, loss = 0.00154833\n",
            "Iteration 847, loss = 0.00154625\n",
            "Iteration 848, loss = 0.00156597\n",
            "Iteration 849, loss = 0.00154009\n",
            "Iteration 850, loss = 0.00153961\n",
            "Iteration 851, loss = 0.00151550\n",
            "Iteration 852, loss = 0.00152236\n",
            "Iteration 853, loss = 0.00151455\n",
            "Iteration 854, loss = 0.00150182\n",
            "Iteration 855, loss = 0.00147581\n",
            "Iteration 856, loss = 0.00146337\n",
            "Iteration 857, loss = 0.00146212\n",
            "Iteration 858, loss = 0.00146158\n",
            "Iteration 859, loss = 0.00144796\n",
            "Iteration 860, loss = 0.00146871\n",
            "Iteration 861, loss = 0.00145470\n",
            "Iteration 862, loss = 0.00143884\n",
            "Iteration 863, loss = 0.00142520\n",
            "Iteration 864, loss = 0.00141083\n",
            "Iteration 865, loss = 0.00140440\n",
            "Iteration 866, loss = 0.00139411\n",
            "Iteration 867, loss = 0.00139069\n",
            "Iteration 868, loss = 0.00137932\n",
            "Iteration 869, loss = 0.00137188\n",
            "Iteration 870, loss = 0.00136173\n",
            "Iteration 871, loss = 0.00135983\n",
            "Iteration 872, loss = 0.00135690\n",
            "Iteration 873, loss = 0.00135858\n",
            "Iteration 874, loss = 0.00134650\n",
            "Iteration 875, loss = 0.00134078\n",
            "Iteration 876, loss = 0.00131936\n",
            "Iteration 877, loss = 0.00132654\n",
            "Iteration 878, loss = 0.00131366\n",
            "Iteration 879, loss = 0.00130440\n",
            "Iteration 880, loss = 0.00130657\n",
            "Iteration 881, loss = 0.00129806\n",
            "Iteration 882, loss = 0.00128708\n",
            "Iteration 883, loss = 0.00128800\n",
            "Iteration 884, loss = 0.00127230\n",
            "Iteration 885, loss = 0.00126217\n",
            "Iteration 886, loss = 0.00126357\n",
            "Iteration 887, loss = 0.00127466\n",
            "Iteration 888, loss = 0.00125609\n",
            "Iteration 889, loss = 0.00124425\n",
            "Iteration 890, loss = 0.00123283\n",
            "Iteration 891, loss = 0.00122407\n",
            "Iteration 892, loss = 0.00122150\n",
            "Iteration 893, loss = 0.00121712\n",
            "Iteration 894, loss = 0.00120797\n",
            "Iteration 895, loss = 0.00119864\n",
            "Iteration 896, loss = 0.00120180\n",
            "Iteration 897, loss = 0.00120465\n",
            "Iteration 898, loss = 0.00118464\n",
            "Iteration 899, loss = 0.00117107\n",
            "Iteration 900, loss = 0.00118230\n",
            "Iteration 901, loss = 0.00117292\n",
            "Iteration 902, loss = 0.00116285\n",
            "Iteration 903, loss = 0.00115417\n",
            "Iteration 904, loss = 0.00115095\n",
            "Iteration 905, loss = 0.00114616\n",
            "Iteration 906, loss = 0.00113330\n",
            "Iteration 907, loss = 0.00113110\n",
            "Iteration 908, loss = 0.00112928\n",
            "Iteration 909, loss = 0.00112399\n",
            "Iteration 910, loss = 0.00111388\n",
            "Iteration 911, loss = 0.00111257\n",
            "Iteration 912, loss = 0.00110350\n",
            "Iteration 913, loss = 0.00109858\n",
            "Iteration 914, loss = 0.00108950\n",
            "Iteration 915, loss = 0.00108270\n",
            "Iteration 916, loss = 0.00108397\n",
            "Iteration 917, loss = 0.00109227\n",
            "Iteration 918, loss = 0.00107900\n",
            "Iteration 919, loss = 0.00109632\n",
            "Iteration 920, loss = 0.00106033\n",
            "Iteration 921, loss = 0.00105648\n",
            "Iteration 922, loss = 0.00104737\n",
            "Iteration 923, loss = 0.00104514\n",
            "Iteration 924, loss = 0.00104754\n",
            "Iteration 925, loss = 0.00103539\n",
            "Iteration 926, loss = 0.00102833\n",
            "Iteration 927, loss = 0.00102520\n",
            "Iteration 928, loss = 0.00101669\n",
            "Iteration 929, loss = 0.00101505\n",
            "Iteration 930, loss = 0.00101186\n",
            "Iteration 931, loss = 0.00100924\n",
            "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                     batch_size='auto', beta_1=0.9,\n",
              "                                     beta_2=0.999, early_stopping=False,\n",
              "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
              "                                     learning_rate='constant',\n",
              "                                     learning_rate_init=0.001, max_fun=15000,\n",
              "                                     max_iter=200, momentum=0.9,\n",
              "                                     n_iter_no_change=10,\n",
              "                                     nesterovs_momentum=True, power_t=0.5,\n",
              "                                     random_state=None, shuffle=True,\n",
              "                                     solver='adam', tol=0.0001,\n",
              "                                     validation_fraction=0.1, verbose=False,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'activation': ['relu'],\n",
              "                         'hidden_layer_sizes': [100, 100, 100],\n",
              "                         'max_iter': [10000], 'solver': ['adam'],\n",
              "                         'tol': [1e-05], 'verbose': [True]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c21e80e7-de0c-4d4e-89a3-96ee88db5a59",
        "outputId": "63522bfa-a6ec-43e9-c039-a327144ffa0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nn_gs.best_params_"
      ],
      "id": "c21e80e7-de0c-4d4e-89a3-96ee88db5a59",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'hidden_layer_sizes': 100,\n",
              " 'max_iter': 10000,\n",
              " 'solver': 'adam',\n",
              " 'tol': 1e-05,\n",
              " 'verbose': True}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99e19d49-b55f-42d4-98e3-a923bd789dc0"
      },
      "source": [
        "best_nn = nn_gs.best_estimator_"
      ],
      "id": "99e19d49-b55f-42d4-98e3-a923bd789dc0",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77b3aeef-6596-4a30-8d2a-981898b7e80a"
      },
      "source": [
        "ytrain_predict = best_nn.predict(X_train_s)\n",
        "ytest_predict = best_nn.predict(X_test_s)"
      ],
      "id": "77b3aeef-6596-4a30-8d2a-981898b7e80a",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d01f35e-9ee5-41ca-ad11-d02135257d05",
        "outputId": "665e24c4-e0e8-4b00-f728-3206cd5e45dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Train data Confusion Matrix\n",
        "print(confusion_matrix(train_labels, ytrain_predict))\n",
        "#Train Data Accuracy\n",
        "print(best_rf.score(X_train,train_labels) )\n",
        "print(classification_report(train_labels, ytrain_predict))"
      ],
      "id": "1d01f35e-9ee5-41ca-ad11-d02135257d05",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1737    0]\n",
            " [   0  321]]\n",
            "0.8620019436345967\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1737\n",
            "           1       1.00      1.00      1.00       321\n",
            "\n",
            "    accuracy                           1.00      2058\n",
            "   macro avg       1.00      1.00      1.00      2058\n",
            "weighted avg       1.00      1.00      1.00      2058\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b2e9642-d9c3-4b06-ae5e-d6c2f5ee44fd",
        "outputId": "ca2129cc-2556-428a-e7be-dcd211d12a06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Test data Confusion Matrix\n",
        "print(confusion_matrix(test_labels, ytest_predict))\n",
        "#Test Data Accuracy\n",
        "print(best_rf.score(X_test,test_labels) )\n",
        "print(classification_report(test_labels, ytest_predict))"
      ],
      "id": "1b2e9642-d9c3-4b06-ae5e-d6c2f5ee44fd",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[709  20]\n",
            " [ 34 119]]\n",
            "0.8412698412698413\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       729\n",
            "           1       0.86      0.78      0.82       153\n",
            "\n",
            "    accuracy                           0.94       882\n",
            "   macro avg       0.91      0.88      0.89       882\n",
            "weighted avg       0.94      0.94      0.94       882\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11480103-be84-40a4-b0b7-95a7362371c9",
        "outputId": "1041701a-1ba8-4ca6-9427-160d72224720",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "probs = best_rf.predict_proba(X_train)[:,1]\n",
        "auc_dev = roc_auc_score(train_labels, probs)\n",
        "print(auc_dev)\n",
        "fpr, tpr, thresholds = roc_curve(train_labels, probs)"
      ],
      "id": "11480103-be84-40a4-b0b7-95a7362371c9",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9173262168274516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3476a36a-1f78-4393-970b-a596d3741311",
        "outputId": "223ddc7c-0d4a-415f-9ba8-fd20ba56233d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# calculate the g-mean for each threshold\n",
        "gmeans = np.sqrt(tpr * (1-fpr))\n",
        "# locate the index of the largest g-mean\n",
        "ix = np.argmax(gmeans)\n",
        "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))"
      ],
      "id": "3476a36a-1f78-4393-970b-a596d3741311",
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold=0.180213, G-Mean=0.846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b168f271-2f01-4846-b8a4-7ea498177bbb",
        "outputId": "7a94bad5-22d5-4f39-8fd2-525627b0c047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# plot the roc curve for the model\n",
        "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
        "plt.plot(fpr, tpr, marker='.', label='Logistic')\n",
        "plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
        "# axis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "id": "b168f271-2f01-4846-b8a4-7ea498177bbb",
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL71iVXHfVDv"
      },
      "source": [
        ""
      ],
      "id": "OL71iVXHfVDv",
      "execution_count": null,
      "outputs": []
    }
  ]
}